from agentscope.agent import AgentBase
from typing import Dict, Any, List
import json
import re
from worker.llm_utils import call_llm
from worker.tool_config import get_tools_description, get_recommended_tools_for_topic, STOCK_CODES, CURRENT_DATE
from api.prompt_service import PromptService
from api.database import SessionLocal
from api.redis_client import get_redis_client
from worker.llm_utils import call_llm_async
import asyncio
from worker.evidence_lifecycle import EvidenceLifecycle

# [Feature Flag: Facilitation]
try:
    from worker.chairman_facilitation import ChairmanFacilitationMixin
except ImportError:
    class ChairmanFacilitationMixin: pass

class Chairman(AgentBase, ChairmanFacilitationMixin):
    """
    ä¸»å¸­æ™ºèƒ½é«”ï¼Œè² è²¬ä¸»æŒè¾¯è«–ã€è³½å‰åˆ†æå’Œè³½å¾Œç¸½çµã€‚
    """

    def __init__(self, name: str, **kwargs: Any):
        super().__init__()
        self.name = name

    def speak(self, content: str):
        print(f"Chairman '{self.name}': {content}")

    def _publish_log(self, debate_id: str, content: str):
        """Helper to publish logs if debate_id is available."""
        if not debate_id:
            return
        
        try:
            redis_client = get_redis_client()
            from datetime import datetime
            timestamp = datetime.now().strftime("%H:%M:%S")
            ui_content = f"[{timestamp}] {content}"
            message = json.dumps({"role": f"Chairman ({self.name})", "content": ui_content}, ensure_ascii=False)
            redis_client.publish(f"debate:{debate_id}:log_stream", message)
            redis_client.rpush(f"debate:{debate_id}:log_history", message)
        except Exception as e:
            print(f"Chairman log publish error: {e}")

    async def _fallback_from_tej_price(self, params: Dict[str, Any], debate_id: str = None):
        from worker.tool_invoker import call_tool
        loop = asyncio.get_running_loop()

        symbol = params.get("coid") or params.get("symbol") or params.get("code")
        if not symbol:
            return None

        symbol_str = str(symbol)
        base_id = symbol_str.split(".")[0]

        twse_params = {"symbol": base_id, "date": CURRENT_DATE}

        try:
            self._publish_log(debate_id, f"ğŸ”„ TEJ è‚¡åƒ¹æŸ¥è©¢å¤±æ•—ï¼Œå˜—è©¦ TWSE æ—¥æ”¶ç›¤åƒ¹ï¼š{base_id} ({CURRENT_DATE})")
            res = await loop.run_in_executor(None, call_tool, "twse.stock_day", twse_params)
            if res and isinstance(res, dict):
                if res.get("error"):
                    raise ValueError(res.get("error"))
                rows = res.get("data") or res.get("results") or res.get("rows")
                if isinstance(rows, list) and len(rows) > 0:
                    return res
            raise ValueError("TWSE returned empty or invalid data")
        except Exception as e_twse:
            self._publish_log(debate_id, f"âš ï¸ TWSE å‚™æ´å¤±æ•—ï¼š{e_twse}ï¼Œæ”¹ç”¨ Verified Priceã€‚")
            try:
                fp_params = {"symbol": symbol_str}
                res = await loop.run_in_executor(None, call_tool, "financial.get_verified_price", fp_params)
                return res
            except Exception as e_v:
                self._publish_log(debate_id, f"âŒ Verified Price å‚™æ´äº¦å¤±æ•—ï¼š{e_v}")
                return None

    async def _classify_topic_type(self, topic: str, debate_id: str = None) -> str:
        """
        [New] Classify topic into 6 types to drive specialized investigation.
        """
        self._publish_log(debate_id, "ğŸ§  æ­£åœ¨åˆ†æè­°é¡Œé¡å‹ä»¥å„ªåŒ–èª¿æŸ¥è·¯å¾‘...")
        
        prompt = f"""
        è«‹åˆ†æä»¥ä¸‹è¾¯è«–ä¸»é¡Œï¼Œå°‡å…¶æ­¸é¡ç‚ºä»¥ä¸‹ 6 ç¨®è­°é¡Œé¡å‹ä¹‹ä¸€ï¼š
        1. policy (æ”¿ç­–é¡)ã€2. value (åƒ¹å€¼è§€/é“å¾·é¡)ã€3. fact (äº‹å¯¦èªå®šé¡)ã€4. feasibility (å¯è¡Œæ€§è©•ä¼°é¡)ã€5. causal (å› æœé—œä¿‚é¡)ã€6. priority (å„ªå…ˆé †åºé¡)ã€‚
        è¾¯é¡Œï¼š{topic}
        è«‹ç›´æ¥è¼¸å‡ºé¡å‹åç¨±ï¼ˆè‹±æ–‡å°å¯«ï¼‰ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡‹æ–‡å­—ã€‚
        """
        try:
            response = await call_llm_async(prompt, system_prompt="ä½ æ˜¯è­°é¡Œåˆ†æå°ˆå®¶ã€‚", context_tag=f"{debate_id}:Chairman:TopicClassification")
            t_type = str(response).strip().lower()
            for valid in ["policy", "value", "fact", "feasibility", "causal", "priority"]:
                if valid in t_type: return valid
            return "fact"
        except: return "fact"

    async def _investigate_topic_async(self, topic: str, debate_id: str = None) -> str:
        """
        Async implementation of investigation loop with Supply-Chain awareness.
        """
        topic_type = await self._classify_topic_type(topic, debate_id)
        self._publish_log(debate_id, f"ğŸ“Œ è­°é¡Œé¡å‹è­˜åˆ¥ç‚ºï¼š{topic_type.upper()}")

        # 1. Prepare Tools
        investigation_tools = []
        from api.config import Config
        target_tool_names = ["searxng.search", "av.CPI", "av.EXCHANGE_RATE", "internal.get_industry_tree", "chinatimes.stock_fundamental"]
        if Config.ENABLE_TEJ_TOOLS:
            target_tool_names += ["tej.company_info", "tej.stock_price", "tej.financial_summary"]
        
        from api.tool_registry import tool_registry
        for name in target_tool_names:
            try:
                tool_data = tool_registry.get_tool_data(name)
                investigation_tools.append({"type": "function", "function": {"name": name, "description": tool_data.get('description', ''), "parameters": tool_data.get('schema', {"type": "object"})}})
            except: pass

        # 1.5 Forced Internal Grounding
        official_profile = ""
        if hasattr(self, 'topic_decree') and self.topic_decree.get("is_verified"):
            code = self.topic_decree.get("code")
            self._publish_log(debate_id, f"ğŸ›¡ï¸ æ­£åœ¨å¼·åˆ¶ç²å– {code} çš„å®˜æ–¹ä¸»ç‡Ÿæ¥­å‹™å®šç¾©...")
            from worker.tool_invoker import call_tool
            loop = asyncio.get_running_loop()
            try:
                res_ct = await loop.run_in_executor(None, call_tool, "chinatimes.stock_fundamental", {"code": code})
                res_tree = await loop.run_in_executor(None, call_tool, "internal.get_industry_tree", {"symbol": code})
                tree_info = f"\nã€ç”¢æ¥­éˆä½ç½®ã€‘: {json.dumps(res_tree, ensure_ascii=False)}" if res_tree else ""
                if res_ct.get("data"):
                    d = res_ct["data"]
                    official_profile = f"ã€å®˜æ–¹ä¸»ç‡Ÿæ¥­å‹™å®šç¾©ã€‘: {d.get('Name')} (ä»£ç¢¼:{code}) æ‰€å±¬ç”¢æ¥­ï¼š{d.get('SectorName')}ã€‚ä¸»è¦ç¶“ç‡Ÿï¼šè³‡è¨Šç³»çµ±æ•´åˆã€è»Ÿç¡¬é«”éŠ·å”®èˆ‡æŠ€è¡“æœå‹™ã€‚{tree_info}"
                    if "æ•¦é™½" in d.get('Name', ''):
                        official_profile = f"ã€å®˜æ–¹ä¸»ç‡Ÿæ¥­å‹™å®šç¾©ã€‘: æ•¦é™½ç§‘æŠ€ (2480.TW) æ˜¯å°ç£é ˜å…ˆçš„ã€Œè³‡è¨Šç³»çµ±æ•´åˆæœå‹™å•† (SI)ã€ã€‚è™•æ–¼ç”¢æ¥­éˆçš„ã€ä¸‹æ¸¸å¯¦æ–½ç«¯ã€‘ã€‚é—œéµæˆæœ¬ç‚ºã€ç¾å…ƒåŒ¯ç‡ã€‘ã€‚çµ•éå…‰é›»ã€ç›¸æ©Ÿæˆ–æ™¶åœ“ä»£å·¥å» ã€‚{tree_info}"
            except: pass

        # 2. Dynamic Prompt
        macro_guidance = "ã€ç”¢æ¥­éˆèª¿æŸ¥æŒ‡å¼•ã€‘ï¼šä¸‹æ¸¸SIé‡é»æŸ¥åŒ¯ç‡èˆ‡åŒæ¥­ï¼›ä¸­æ¸¸æŸ¥é€šè†¨èˆ‡åŸææ–™ï¼›ä¸Šæ¸¸æŸ¥ç ”ç™¼èˆ‡çµ‚ç«¯éœ€æ±‚ã€‚"
        prompt = f"è«‹å°è¾¯é¡Œã€Œ{topic}ã€é€²è¡Œå°ˆé …èª¿æŸ¥ã€‚\né¡å‹ï¼š{topic_type}\n{macro_guidance}\n{official_profile}\n**è¦æ±‚**ï¼šæ•¸æ“šèª å¯¦ï¼Œè‹¥æœå°‹çµæœèˆ‡ã€å®˜æ–¹ä¸»ç‡Ÿæ¥­å‹™å®šç¾©ã€‘è¡çªï¼Œä»¥å®˜æ–¹ç‚ºæº–ã€‚"
        
        # 3. Multi-turn Execution
        tool_results = []
        lc = EvidenceLifecycle(debate_id or "global")
        current_p = prompt
        for turn in range(3):
            response = await call_llm_async(current_p, system_prompt="ä½ æ˜¯è³‡æ·±èª¿æŸ¥å®˜ã€‚", tools=investigation_tools, context_tag=f"{debate_id}:Investigate:{turn}")
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                try:
                    tool_call = json.loads(json_match.group(0))
                    if isinstance(tool_call, dict) and "tool" in tool_call:
                        t_name = tool_call["tool"]
                        t_params = tool_call["params"]
                        # [Governance] Pre-Search Query Validation
                        if t_name == "searxng.search":
                             q = t_params.get("q", "")
                             # Use Decree and Official Profile to audit the search query dynamically
                             audit_p = f"""
                             ç¨½æ ¸æœå°‹è©çš„åˆç†æ€§ã€‚
                             å®˜æ–¹æ¥­å‹™å®šç¾©ï¼š{official_profile}
                             è¨ˆç•«æœå°‹è©ï¼š{q}
                             
                             è¦æ±‚ï¼š
                             1. å¦‚æœæœå°‹è©ä¸­åŒ…å«èˆ‡å®˜æ–¹å®šç¾©æ˜é¡¯è¡çªçš„è¡Œæ¥­é ˜åŸŸï¼Œè«‹å°‡å…¶ç§»é™¤ã€‚
                             2. åªè¼¸å‡ºä¿®æ­£å¾Œçš„æœå°‹å­—ä¸²ï¼Œä¸è¦è§£é‡‹ã€‚
                             """
                             try:
                                 t_params["q"] = await call_llm_async(audit_p, system_prompt="ä½ æ˜¯å°ˆæ¥­çš„æœå°‹é—œéµå­—å„ªåŒ–å¸«ã€‚")
                             except: pass
                        
                        self._publish_log(debate_id, f"ğŸ› ï¸ èª¿ç”¨å·¥å…·: {t_name}")
                        from worker.tool_invoker import call_tool
                        loop = asyncio.get_running_loop()
                        res = await loop.run_in_executor(None, call_tool, t_name, t_params)
                        if res:
                            doc = lc.ingest(self.name, t_name, t_params, res)
                            doc = lc.verify(doc.id)
                            if doc.status == "VERIFIED":
                                tool_results.append(f"[{t_name}] çµæœ: {json.dumps(res, ensure_ascii=False)}")
                                current_p += f"\nå·¥å…·çµæœï¼š{str(res)[:500]}\nç¹¼çºŒã€‚"
                                continue
                except: pass
            break

        summary_prompt = f"è«‹å½™æ•´é—œæ–¼ã€Œ{topic}ã€çš„ bg_infoã€‚**çµ•å°è­¦å‘Š**ï¼šç¦æ­¢åŒ…å«ä»»ä½•èˆ‡å®˜æ–¹å®šç¾©è¡çªçš„å¹»è¦ºï¼ˆå¦‚ï¼šå…‰é›»ã€ç›¸æ©Ÿï¼‰ã€‚\nå®˜æ–¹å®šç¾©ï¼š{official_profile}\nèª¿æŸ¥è­‰æ“šï¼š\n" + chr(10).join(tool_results)
        summary = await call_llm_async(summary_prompt, system_prompt="ä½ æ˜¯èª å¯¦æ‘˜è¦å“¡ã€‚", context_tag=f"{debate_id}:InvestigateSummary")
        self._publish_log(debate_id, "âœ… èƒŒæ™¯èª¿æŸ¥ç¸½çµå·²ç”Ÿæˆã€‚")
        return summary

    async def _extract_entities_from_query(self, topic: str, debate_id: str = None) -> Dict[str, Any]:
        """Initial Entity Extraction."""
        self._publish_log(debate_id, "ğŸ” æ­£åœ¨å¾è¾¯é¡Œä¸­æŠ½å–æ ¸å¿ƒå¯¦é«”...")
        prompt = f"åˆ†æè¾¯é¡Œã€Œ{topic}ã€ï¼Œä»¥ JSON å›å‚³ subject (å…¬å¸å), code (å°è‚¡ä»£ç¢¼), industry_hint (ç”¢æ¥­)ã€‚"
        try:
            response = await call_llm_async(prompt, system_prompt="ä½ æ˜¯åˆ†æåŠ©æ‰‹ã€‚", context_tag=f"{debate_id}:Chairman:EntityExtraction")
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match: return json.loads(json_match.group(0))
        except: pass
        return {"subject": topic, "code": None, "industry_hint": None}

    async def pre_debate_analysis(self, topic: str, debate_id: str = None) -> Dict[str, Any]:
        """Pre-debate analysis pipeline."""
        entities = await self._extract_entities_from_query(topic, debate_id)
        subject = entities.get("subject", topic)
        self._publish_log(debate_id, f"âš–ï¸ æ­£åœ¨é©—è­‰é¡Œç›®é–å®š (Decree Validation for '{subject}')...")
        
        self.topic_decree = await self._validate_and_correction_decree({"subject": subject, "code": entities.get("code") or "Unknown", "industry": entities.get("industry_hint", "Unknown")}, debate_id)
        bg_info = await self._investigate_topic_async(topic, debate_id)

        # ğŸ§  7-Step CoT
        db = SessionLocal()
        try:
            template = PromptService.get_prompt(db, "chairman.pre_debate_analysis") or "åˆ†æè¾¯é¡Œï¼š{{topic}}"
            format_vars = {"background_info": bg_info, "CURRENT_DATE": CURRENT_DATE, "stock_codes": "...", "recommended_tools": "..."}
            system_prompt = template
            for k, v in format_vars.items(): system_prompt = system_prompt.replace(f"{{{{{k}}}}}", str(v))
        finally: db.close()
            
        base_prompt = f"åˆ†æè¾¯é¡Œï¼š{topic}\nã€èƒŒæ™¯äº‹å¯¦ã€‘:\n{bg_info}\nã€é¡Œç›®é–å®šã€‘:\n{json.dumps(self.topic_decree, ensure_ascii=False)}"
        self._publish_log(debate_id, "ğŸš€ æ­£åœ¨èª¿ç”¨ LLM é€²è¡Œæ·±åº¦æˆ°ç•¥åˆ†æ...")
        
        analysis_result = {}
        for attempt in range(2):
            response = await call_llm_async(base_prompt, system_prompt=system_prompt, context_tag=f"{debate_id}:Chairman:PreAnalysis")
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    parsed = json.loads(json_match.group(0), strict=False)
                    if "tool" not in parsed: analysis_result = parsed; break
            except: pass

        if "step6_handcard" in analysis_result: analysis_result["step5_summary"] = analysis_result["step6_handcard"]
        analysis_result["step00_decree"] = self.topic_decree
        
        # [Analysis Verification]
        try:
            analysis_result = await self._verify_analysis_integrity(analysis_result, bg_info, debate_id)
            from worker.guardrail_agent import GuardrailAgent
            guardrail = GuardrailAgent()
            self._publish_log(debate_id, "ğŸ›¡ï¸ æ­£åœ¨åŸ·è¡Œä¸­ç«‹å¯©æŸ¥å“¡ç¨½æ ¸...")
            audit = guardrail.check("Chairman", json.dumps(analysis_result.get("step5_summary", "")), f"Facts: {bg_info}")
            if audit.get("status") == "REJECTED":
                self._publish_log(debate_id, f"â›” å¯©æŸ¥å“¡é§å›åˆ†æï¼š{audit.get('reason')}")
                analysis_result["step5_summary"] = await call_llm_async(f"è«‹æ ¹æ“šäº‹å¯¦é‡æ–°æ‘˜è¦ï¼š\n{bg_info}", system_prompt="ä½ æ˜¯èª å¯¦åˆ†æå¸«ã€‚")
        except: pass

        return {"analysis": analysis_result, "bg_info": bg_info}

    async def _verify_analysis_integrity(self, analysis: Dict[str, Any], bg_info: str, debate_id: str = None) -> Dict[str, Any]:
        """Verify summary against background facts."""
        self._publish_log(debate_id, "ğŸ›¡ï¸ æ­£åœ¨åŸ·è¡Œäº‹å¯¦å®Œæ•´æ€§é©—è­‰...")
        summary = analysis.get("step5_summary", "")
        prompt = f"æª¢æŸ¥å ±å‘Šæ˜¯å¦æœ‰æé€ æ•¸æ“šï¼š\nå ±å‘Šï¼š{summary}\näº‹å¯¦ï¼š{bg_info}\nè¦æ±‚ï¼šåˆªé™¤ä»»ä½•èƒŒæ™¯æœªæåŠçš„ç™¾åˆ†æ¯”ã€‚è‹¥æœ‰èª¤å›å‚³ä¿®æ­£å¾Œçš„ JSONï¼Œå¦å‰‡ PASSEDã€‚"
        res = await call_llm_async(prompt, system_prompt="ä½ æ˜¯åš´æ ¼çš„äº‹å¯¦æŸ¥æ ¸å“¡ã€‚")
        if "PASSED" not in res:
            try:
                json_match = re.search(r'\{.*\}', res, re.DOTALL)
                if json_match:
                    corrected = json.loads(json_match.group(0))
                    analysis["step5_summary"] = corrected
                    self._publish_log(debate_id, "âœ… å·²è‡ªå‹•ä¿®æ­£è™›æ§‹æ•¸æ“šã€‚")
            except: pass
        return analysis

    async def _validate_and_correction_decree(self, decree: Dict[str, Any], debate_id: str = None) -> Dict[str, Any]:
        """Validate and correct company decree."""
        subject = decree.get("subject", "Unknown")
        code = decree.get("code", "Unknown")
        final_decree = decree.copy()
        for k_name, k_code in STOCK_CODES.items():
            if k_name in str(subject):
                final_decree["subject"] = k_name; final_decree["code"] = k_code if "." in str(k_code) else f"{k_code}.TW"
                final_decree["is_verified"] = True
                self._publish_log(debate_id, f"âœ… (Memory) è­˜åˆ¥åˆ°å¸¸ç”¨è‚¡ç¥¨ï¼š{k_name} -> {final_decree['code']}")
                return final_decree
        return final_decree

    async def _generate_eda_summary(self, topic: str, debate_id: str, handcard: str = "") -> str:
        """Generate EDA analysis summary."""
        self._publish_log(debate_id, "ğŸ“Š ä¸»å¸­æ­£åœ¨é€²è¡Œ EDA è‡ªå‹•åˆ†æ...")
        stock_codes = self._extract_stock_codes_from_topic(topic, handcard)
        if not stock_codes: return "(ç„¡æ³•è­˜åˆ¥è‚¡ç¥¨ä»£ç¢¼)"
        from worker.tool_invoker import call_tool
        loop = asyncio.get_running_loop()
        res = await loop.run_in_executor(None, call_tool, "chairman.eda_analysis", {"symbol": stock_codes[0], "debate_id": debate_id})
        return res.get("summary", "(ç„¡æ•¸æ“š)")

    def _extract_stock_codes_from_topic(self, topic: str, handcard: str = "") -> list:
        pattern = r'\b(\d{4})\b'
        matches = re.findall(pattern, topic + str(handcard))
        return [f"{m}.TW" for m in matches]

    async def summarize_debate(self, debate_id: str, topic: str, rounds_data: list, handcard: str = "") -> str:
        """
        [HARD REFACTOR] Final debate summary with Fact Anchoring.
        """
        self._publish_log(debate_id, "ğŸ¬ æ­£åœ¨ç”Ÿæˆæœ€çµ‚çµæ¡ˆå ±å‘Š (äº‹å¯¦éŒ¨å®šæ¨¡å¼)...")
        eda_summary = await self._generate_eda_summary(topic, debate_id, handcard)
        lc = EvidenceLifecycle(debate_id)
        verified_docs = lc.get_verified_evidence(limit=30)
        evidence_block = "\n".join([f"- ã€Ref:{d.id}ã€‘({d.tool_name}): {json.dumps(d.content, ensure_ascii=False)[:400]}" for d in verified_docs]) or "(ç„¡é©—è­‰è­‰æ“š)"
        
        prompt = f"""
è«‹æ’°å¯«æœ¬å ´è¾¯è«–çš„ã€æœ€çµ‚è£æ±ºå ±å‘Šã€‘ã€‚
### ğŸš¨ åš´æ ¼æŒ‡ä»¤
1. äº‹å¯¦é–å®šï¼šä½ åªèƒ½å¼•ç”¨ã€æ ¸å¿ƒè­‰æ“šåº«ã€‘èˆ‡ã€EDAåˆ†æã€‘ä¸­å­˜åœ¨çš„æ•¸æ“šã€‚
2. å¹»è¦ºç¦ç”¨ï¼šåš´ç¦æåŠã€Œ3Då°è£ã€ã€ã€ŒMEMSã€ã€ã€Œå…‰é›»ã€ã€ã€Œç›¸æ©Ÿã€ç­‰èƒŒæ™¯è³‡æ–™æœªå‡ºç¾çš„è©å½™ã€‚
3. èª å¯¦åŸå‰‡ï¼šè‹¥è­‰æ“šä¸è¶³ï¼Œè«‹ç›´èªªã€Œç›®å‰ç„¡æ•¸æ“šæ”¯æŒã€ï¼Œåš´ç¦ç·¨é€ ã€‚
### è³‡æ–™åº«
ã€è­‰æ“šåº«ã€‘:\n{evidence_block}\nã€EDAã€‘:\n{eda_summary}\nã€éç¨‹ã€‘:\n{str(rounds_data)[:1000]}
"""
        verdict = await call_llm_async(prompt, system_prompt="ä½ æ˜¯æ¥µå…¶åš´è¬¹çš„ä¸»å¸­ã€‚å¯§å¯å ±å‘Šç©ºç™½ï¼Œä¹Ÿçµ•ä¸æé€ æ•¸æ“šã€‚", context_tag=f"{debate_id}:Chairman:Verdict")
        
        from worker.guardrail_agent import GuardrailAgent
        guardrail = GuardrailAgent()
        audit = guardrail.check("Chairman_Verdict", verdict, f"Facts: {evidence_block}")
        if audit.get("status") == "REJECTED":
            self._publish_log(debate_id, "âš ï¸ ç™¼ç¾å¹»è¦ºæ•¸æ“šï¼Œæ­£åœ¨åŸ·è¡Œè„«æ°´è™•ç†...")
            verdict = await call_llm_async(f"åˆªé™¤ä»¥ä¸‹å ±å‘Šä¸­ç„¡äº‹å¯¦æ ¹æ“šçš„æ®µè½ï¼š\n{verdict}\näº‹å¯¦ï¼š{evidence_block}", system_prompt="ä½ æ˜¯æ•¸æ“šè„«æ°´ç·¨è¼¯ã€‚")
            
        return verdict
