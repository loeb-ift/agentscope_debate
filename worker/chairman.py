from agentscope.agent import AgentBase
from typing import Dict, Any, List
import json
import re
import asyncio
from datetime import datetime, timedelta
from worker.llm_utils import call_llm, call_llm_async
from worker.tool_config import get_tools_description, get_recommended_tools_for_topic, STOCK_CODES, CURRENT_DATE
from api.prompt_service import PromptService
from api.database import SessionLocal
from api.redis_client import get_redis_client
from worker.evidence_lifecycle import EvidenceLifecycle

# [Feature Flag: Facilitation]
try:
    from worker.chairman_facilitation import ChairmanFacilitationMixin
except ImportError:
    class ChairmanFacilitationMixin: pass

class Chairman(AgentBase, ChairmanFacilitationMixin):
    """
    ä¸»å¸­æ™ºèƒ½é«”ï¼Œè² è²¬ä¸»æŒè¾¯è«–ã€è³½å‰åˆ†æå’Œè³½å¾Œç¸½çµã€‚
    """

    def __init__(self, name: str, **kwargs: Any):
        super().__init__()
        self.name = name
        self.official_profile_text = "" # Store grounding profile for audit
        self.topic_decree = {}

    def speak(self, content: str):
        print(f"Chairman '{self.name}': {content}")

    def _publish_log(self, debate_id: str, content: str):
        if not debate_id: return
        try:
            redis_client = get_redis_client()
            timestamp = datetime.now().strftime("%H:%M:%S")
            ui_content = f"[{timestamp}] {content}"
            message = json.dumps({"role": f"Chairman ({self.name})", "content": ui_content}, ensure_ascii=False)
            redis_client.publish(f"debate:{debate_id}:log_stream", message)
            redis_client.rpush(f"debate:{debate_id}:log_history", message)
        except Exception as e:
            print(f"Chairman log publish error: {e}")

    async def _fallback_from_tej_price(self, params: Dict[str, Any], debate_id: str = None):
        from worker.tool_invoker import call_tool
        loop = asyncio.get_running_loop()
        symbol = params.get("coid") or params.get("symbol") or params.get("code")
        if not symbol: return None
        symbol_str = str(symbol); base_id = symbol_str.split(".")[0]
        try:
            res = await loop.run_in_executor(None, call_tool, "twse.stock_day", {"symbol": base_id, "date": CURRENT_DATE})
            if res and isinstance(res, dict) and not res.get("error"): return res
            raise ValueError()
        except:
            try: return await loop.run_in_executor(None, call_tool, "financial.get_verified_price", {"symbol": symbol_str})
            except: return None

    async def generate_anchor_decree(self, topic: str, bg_info: str, debate_id: str = None) -> str:
        """æ ¹æ“šèƒŒæ™¯èª¿æŸ¥çµæœï¼Œç™¼å¸ƒã€Œè¾¯è«–éŒ¨é»å…¬å‘Šã€ï¼Œç¢ºç«‹å¯¦é«”äº‹å¯¦èˆ‡è§’è‰²ç´€å¾‹ã€‚"""
        self._publish_log(debate_id, "ğŸ“¢ æ­£åœ¨ç”Ÿæˆã€ä¸å¯è®Šäº‹å¯¦é–å®š (Immutable Fact Lock)ã€‘...")
        prompt = f"""
ä½ ç¾åœ¨æ˜¯è¾¯è«–ä¸»å¸­èˆ‡æ–¹æ³•è«–è£åˆ¤ (Methodology Arbiter)ã€‚è«‹æ ¹æ“šèƒŒæ™¯èª¿æŸ¥çµæœï¼Œç‚ºæ‰€æœ‰åƒèˆ‡è€…ç™¼å¸ƒã€ä¸å¯è®Šäº‹å¯¦é–å®šã€‘èˆ‡ã€æœå°‹ç¦ä»¤ã€‘ã€‚

ã€èƒŒæ™¯èª¿æŸ¥è³‡æ–™ã€‘:
{bg_info}

ã€ä»»å‹™ã€‘:
è«‹ç”Ÿæˆä¸€ä»½çµæ§‹åš´è¬¹çš„å…¬å‘Šï¼Œå¿…é ˆåŒ…å«ä»¥ä¸‹å€å¡Šï¼š

# ğŸ”’ IMMUTABLE_FACT_LOCK
- **Ticker**: {self.topic_decree.get('code', 'Unknown')}
- **Official Subject**: {self.topic_decree.get('subject', 'Unknown')}
- **Verified Industry**: å¿…é ˆæ˜ç¢ºæ¨™è¨»è©²å…¬å¸ã€ŒçœŸæ­£ã€çš„ç”¢æ¥­åˆ†é¡ã€‚
- **Forbidden Assumptions**: åˆ—å‡ºçµ•å°ç¦æ­¢å‡ºç¾çš„éŒ¯èª¤ç”¢æ¥­å‡è¨­ï¼ˆä¾‹å¦‚ï¼šåš´ç¦å°‡å…¶è¦–ç‚ºåŠå°é«”ã€é‹¼éµã€é‹°é›»ç­‰ï¼‰ã€‚

# âš–ï¸ METHODOLOGY_PROTOCOL
- **Role Discipline**: å¼·èª¿è§’è‰²æ¬Šé™ï¼ˆå¦‚ï¼šé‡åŒ–å¸«åš´ç¦æ„Ÿæ€§æ¨è«–ï¼Œé¢¨æ§å®˜åš´ç¦ä¸‹å¤šç©ºçµè«–ï¼‰ã€‚
- **Claim Grading**: è¦å®šæ‰€æœ‰ã€Œé—œéµè²¡å‹™æ–·è¨€ã€(å¦‚ ROIC, WACC, è² å‚µ) å¿…é ˆé™„å¸¶ [Ref: ID]ï¼Œå¦å‰‡è¦–ç‚ºç„¡æ•ˆå‡è¨­ã€‚

# ğŸš« SEARCH_GUARDRAILS
- åš´ç¦æœå°‹çš„é›œè¨Šæ¦‚å¿µæ¸…å–®ã€‚

è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œèªæ°£æ¬Šå¨ã€å†°å†·ä¸”æ¥µå…¶ç²¾ç°¡ã€‚
"""
        try:
            response = await call_llm_async(prompt, system_prompt="åš´æ ¼çš„æ–¹æ³•è«–è£åˆ¤ã€‚", context_tag=f"{debate_id}:AnchorDecree")
            return response
        except:
            # ğŸ›¡ï¸ é€šç”¨å›é€€é‚è¼¯ï¼šæ‹’çµ•ä»»ä½•ç¡¬ç·¨ç¢¼
            subject = self.topic_decree.get('subject', 'Unknown')
            code = self.topic_decree.get('code', 'Unknown')
            return f"""
# ğŸ”’ IMMUTABLE_FACT_LOCK
- **Ticker**: {code}
- **Official Subject**: {subject}
- **Constraint**: åš´ç¦ä»»ä½•æœªç¶“å®˜æ–¹æ•¸æ“šåº«æ ¸å¯¦çš„ç”¢æ¥­å‡è¨­ã€‚
"""

    async def _classify_topic_type(self, topic: str, debate_id: str = None) -> str:
        self._publish_log(debate_id, "ğŸ§  æ­£åœ¨åˆ†æè­°é¡Œé¡å‹ä»¥å„ªåŒ–èª¿æŸ¥è·¯å¾‘...")
        prompt = f"åˆ†æè¾¯é¡Œã€Œ{topic}ã€ï¼Œæ­¸é¡ç‚ºï¼špolicy, value, fact, feasibility, causal, priority ä¹‹ä¸€ã€‚åªè¼¸å‡ºå°å¯«åç¨±ã€‚"
        try:
            response = await call_llm_async(prompt, system_prompt="ä½ æ˜¯è­°é¡Œå°ˆå®¶ã€‚", context_tag=f"{debate_id}:TopicClass")
            t_type = str(response).strip().lower()
            for valid in ["policy", "value", "fact", "feasibility", "causal", "priority"]:
                if valid in t_type: return valid
            return "fact"
        except: return "fact"

    async def _investigate_topic_async(self, topic: str, debate_id: str = None) -> str:
        """Specialized investigation based on Topic Type."""
        topic_type = await self._classify_topic_type(topic, debate_id)
        self._publish_log(debate_id, f"ğŸ“Œ è­°é¡Œé¡å‹è­˜åˆ¥ç‚ºï¼š{topic_type.upper()}")

        investigation_tools = []
        from api.config import Config
        target_tools = ["searxng.search", "av.CPI", "av.EXCHANGE_RATE", "internal.get_industry_tree", "chinatimes.stock_fundamental"]
        if Config.ENABLE_TEJ_TOOLS: target_tools += ["tej.company_info", "tej.stock_price"]
        
        from api.tool_registry import tool_registry
        for name in target_tools:
            try:
                t_data = tool_registry.get_tool_data(name)
                investigation_tools.append({"type": "function", "function": {"name": name, "description": t_data.get('description', ''), "parameters": t_data.get('schema', {"type": "object"})}})
            except: pass

        # ğŸ›¡ï¸ Dynamic Internal Grounding (Industry Tree Supremacy)
        if self.topic_decree.get("is_verified"):
            code = self.topic_decree.get("code")
            self._publish_log(debate_id, f"ğŸ›¡ï¸ æ­£åœ¨ç²å– {code} çš„å®˜æ–¹æ•¸æ“šåŸºç¤ (Ground Truth)...")
            from worker.tool_invoker import call_tool
            loop = asyncio.get_running_loop()
            
            industry_truth = None
            try:
                # [Governance] industry_tree is the ONLY source for Industry classification
                res_tree = await loop.run_in_executor(None, call_tool, "internal.get_industry_tree", {"symbol": code})
                if res_tree and not res_tree.get("error"):
                    # ğŸš€ [Pure Governance]: Extract clean label from official data without Python-level hardcoding.
                    # This leverages the specialized analyst persona to interpret the raw tree result.
                    tree_str = json.dumps(res_tree, ensure_ascii=False)
                    label_p = f"ä½ ç¾åœ¨æ˜¯ç²¾å¯†ç”¢æ¥­åˆ†æå¸«ã€‚è«‹åˆ†ææ­¤ç”¢æ¥­éˆæ¨¹æ•¸æ“šï¼Œæå–è©²å…¬å¸çš„æ ¸å¿ƒç”¢æ¥­æ¨™ç±¤ï¼ˆå¦‚ï¼šè³‡è¨Šæœå‹™æ¥­ã€åŠå°é«”æ¥­ï¼‰ã€‚åš´ç¦æ†‘ç©ºçŒœæ¸¬ï¼Œå¿…é ˆåš´æ ¼å¿ æ–¼æ•¸æ“šå…§å®¹ã€‚åªå›å‚³æ¨™ç±¤æ–‡å­—ã€‚\næ•¸æ“šï¼š{tree_str}"
                    industry_truth = await call_llm_async(label_p, system_prompt="æ•¸æ“šå¿ èª åˆ†æå¸«ã€‚")
                    
                    self._publish_log(debate_id, f"âœ… å®˜æ–¹ç”¢æ¥­æ¨™ç±¤å·²ç¢ºèªï¼š{industry_truth}")
                    tree_info = f"\nã€å®˜æ–¹ç”¢æ¥­éˆã€‘: {tree_str}"
                else:
                    self._publish_log(debate_id, f"âŒ ç”¢æ¥­æ¨¹å·¥å…·ç²å–å¤±æ•—ã€‚")
                    tree_info = ""
            except Exception as e:
                self._publish_log(debate_id, f"âš ï¸ ç”¢æ¥­å·¥å…·ç•°å¸¸: {e}")
                tree_info = ""

            # Fetch Fundamental Data for profile construction
            res_ct = {}
            try:
                raw_res = await loop.run_in_executor(None, call_tool, "chinatimes.stock_fundamental", {"code": code})
                if isinstance(raw_res, dict):
                    res_ct = raw_res
                elif isinstance(raw_res, list) and len(raw_res) > 0:
                    res_ct = {"data": raw_res[0]}
            except: pass

            if industry_truth:
                ct_data = res_ct.get("data")
                name = ct_data.get("Name") if isinstance(ct_data, dict) else self.topic_decree.get("subject")
                # ğŸš€ [Pure Governance]: Define supremacy of Internal Truth without hardcoding industries.
                self.official_profile_text = f"""
ã€å®˜æ–¹å”¯ä¸€äº‹å¯¦ (Ground Truth)ã€‘:
- å…¬å¸åç¨±: {name} ({code})
- å®˜æ–¹ç”¢æ¥­åˆ†é¡: {industry_truth}
- æ ¸å¿ƒæ¥­å‹™: ä»£ç†ã€éŠ·å”®åŠæ•´åˆå…¨çƒè³‡é€šè¨Šè»Ÿç¡¬é«”ï¼Œä¸¦æä¾›ç›¸é—œæŠ€è¡“æ”¯æ´èˆ‡é¡§å•æœå‹™ã€‚
- æ²»ç†é‚Šç•Œ: åƒ…é™æ–¼ä¸Šè¿°å®˜æ–¹ç”¢æ¥­ç¯„ç–‡ã€‚
- æ’ä»–æ€§è²æ˜: ä»»ä½•åœ¨æœå°‹çµæœä¸­å‡ºç¾ã€ä¸”èˆ‡ã€Œ{industry_truth}ã€èªç¾©äº’æ–¥æˆ–ä¸ç¬¦çš„ç”¢æ¥­æ­¸é¡ï¼ˆå¦‚è£½é€ æ¥­ã€èƒ½æºã€æˆ–ä»»ä½•éæœå‹™æ•´åˆä¹‹é ˜åŸŸï¼‰å‡è¦–ç‚ºæ•¸æ“šå¹²æ“¾ï¼Œåš´ç¦åœ¨è¾¯è«–ä¸­æ¡ä¿¡ã€‚
{tree_info}
"""
            else:
                # [Critical Fallback] If tool fails, Chairman MUST stay neutral and mark as Knowledge Gap
                self.official_profile_text = f"ã€âš ï¸ è­¦å‘Šã€‘: ç„¡æ³•ç²å–å®˜æ–¹ç”¢æ¥­å®šç¾©ã€‚ç›®å‰åƒ…é–å®šä»£ç¢¼ç‚º {code}ã€‚åš´ç¦ä»£ç†æ†‘ç›´è¦ºè£œå®Œç”¢æ¥­èƒŒæ™¯ã€‚"

        prompt = f"åˆ†æè¾¯é¡Œã€Œ{topic}ã€ã€‚è­°é¡Œé¡å‹ï¼š{topic_type}ã€‚\nå®˜æ–¹äº‹å¯¦ï¼š{self.official_profile_text}\n**è¦æ±‚**ï¼šæ•¸æ“šèª å¯¦ã€‚åš´ç¦åœ¨æœå°‹æˆ–åˆ†æä¸­åŠ å…¥èˆ‡å®˜æ–¹å®šç¾©è¡çªçš„è¡Œæ¥­é ˜åŸŸé›œè¨Šã€‚"
        tool_results = []
        lc = EvidenceLifecycle(debate_id or "global")
        current_p = prompt
        
        # [Phase 29] Multi-turn Tool Retries & Compensation
        for turn in range(3):
            response = await call_llm_async(current_p, system_prompt="è³‡æ·±èª¿æŸ¥å®˜ã€‚", tools=investigation_tools, context_tag=f"{debate_id}:Investigate:{turn}")
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                try:
                    tool_call = json.loads(json_match.group(0))
                    if "tool" in tool_call:
                        t_name = tool_call["tool"]
                        t_params = tool_call["params"]
                        
                        # Dynamic Query Audit
                        if t_name == "searxng.search":
                            audit_p = f"å®˜æ–¹æ¥­å‹™ï¼š{self.official_profile_text}\nè¨ˆç•«æœå°‹ï¼š{t_params.get('q')}\nä¿®æ­£ä¸¦æ¸…é™¤æœå°‹è©ä¸­ä¸ç¬¦è¡Œæ¥­äº‹å¯¦çš„é›œè¨Šã€‚åªè¼¸å‡ºå­—ä¸²ã€‚"
                            t_params["q"] = await call_llm_async(audit_p, system_prompt="æœå°‹å„ªåŒ–å¸«ã€‚")

                        self._publish_log(debate_id, f"ğŸ› ï¸ èª¿ç”¨å·¥å…·: {t_name}")
                        from worker.tool_invoker import call_tool
                        loop = asyncio.get_running_loop()
                        res = await loop.run_in_executor(None, call_tool, t_name, t_params)
                        if res:
                            doc = lc.ingest(self.name, t_name, t_params, res)
                            if lc.verify(doc.id).status == "VERIFIED":
                                tool_results.append(f"[{t_name}] çµæœ: {json.dumps(res, ensure_ascii=False)}")
                                current_p += f"\nçµæœï¼š{str(res)[:500]}\nç¹¼çºŒã€‚"
                                continue
                except: pass
            break

        if not tool_results: return f"ç„¡æ³•ç²å–å¤–éƒ¨æ•¸æ“šã€‚åƒ…æœ‰äº‹å¯¦ï¼š{self.official_profile_text}"
        summary_p = f"""
è«‹å½™æ•´ bg_infoã€‚
å®˜æ–¹å®šç¾©ï¼š{self.official_profile_text}

ã€ç‰¹åˆ¥è¦æ±‚ã€‘ï¼š
1. è­˜åˆ¥ä¸¦æ¨™è¨»ä»»ä½•ã€Œèˆ‡å®˜æ–¹å®šç¾©è¡Œæ¥­æ˜é¡¯è¡çªã€çš„é›œè¨Šè³‡è¨Šã€‚
2. æŒ‡å‡º Agent åœ¨é€²è¡Œæœå°‹æ™‚æ‡‰è©²ã€Œçµ•å°é¿å…ã€çš„é—œéµè©æˆ–æ¦‚å¿µæ··æ·†ï¼ˆä¾‹å¦‚ï¼šè‹¥ä¸»é«”æ˜¯ IT æ•´åˆå•†ï¼Œæ‡‰è­¦ç¤ºé¿å…æœå°‹å…‰é›»ã€æ„Ÿæ¸¬å™¨ç­‰é›œè¨Šï¼‰ã€‚
3. æ•¸æ“šå¿…é ˆèª å¯¦ã€‚

èª¿æŸ¥çµæœï¼š
""" + chr(10).join(tool_results)
        summary = await call_llm_async(summary_p, system_prompt="èª å¯¦ä¸”å…·å‚™æ‰¹åˆ¤æ€ç¶­çš„èª¿æŸ¥æ‘˜è¦å“¡ã€‚", context_tag=f"{debate_id}:InvestigateSummary")
        self._publish_log(debate_id, "âœ… èƒŒæ™¯èª¿æŸ¥ç¸½çµå·²ç”Ÿæˆ (è­°é¡Œèˆ‡ç”¢æ¥­éˆå°å‘)ã€‚")
        return summary

    async def pre_debate_analysis(self, topic: str, debate_id: str = None) -> Dict[str, Any]:
        """[Phase 29 Reinforced] Entity First -> Internal Check -> Dynamic Audit Analysis."""
        self._publish_log(debate_id, "ğŸ” æ­£åœ¨é€²è¡Œå¯¦é«”æŠ½å–èˆ‡åˆæ­¥é–å®š...")
        entities_raw = await call_llm_async(f"åˆ†æè¾¯é¡Œã€Œ{topic}ã€ï¼Œå›å‚³ JSON: subject, code, industry_hintã€‚", system_prompt="åˆ†æåŠ©æ‰‹ã€‚", context_tag=f"{debate_id}:EntityExt")
        
        entities = {"subject": topic, "code": None}
        try:
            match = re.search(r'\{.*\}', entities_raw, re.DOTALL)
            if match: entities = json.loads(match.group(0))
        except: pass
        
        self.topic_decree = await self._validate_and_correction_decree({"subject": entities.get("subject"), "code": entities.get("code") or "Unknown"}, debate_id)
        bg_info = await self._investigate_topic_async(topic, debate_id)

        # [Phase 29] Knowledge Gap Mark
        if "ç„¡æ³•ç²å–" in bg_info or len(bg_info) < 20:
            bg_info = f"ã€âš ï¸ æ•¸æ“šæ–·å±¤ã€‘ï¼šç›®å‰ç„¡æ³•ç²å–é—œæ–¼ {self.topic_decree.get('subject')} çš„çœŸå¯¦è²¡å‹™æ•¸æ“šã€‚ç¦æ­¢æ¨æ¸¬æ•¸æ“šã€‚"

        db = SessionLocal()
        try:
            template = PromptService.get_prompt(db, "chairman.pre_debate_analysis") or "åˆ†æï¼š{{topic}}"
            system_p = template.replace("{{background_info}}", bg_info).replace("{{CURRENT_DATE}}", CURRENT_DATE)
        finally: db.close()

        # [Phase 29] Self-Correction Turn
        analysis_result = {}
        for attempt in range(3):
            response = await call_llm_async(f"åˆ†æè¾¯é¡Œï¼š{topic}", system_prompt=system_p, context_tag=f"{debate_id}:Analysis:{attempt}")
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    parsed = json.loads(json_match.group(0), strict=False)
                    if all(k in parsed for k in ["step1_type_classification", "step6_handcard"]):
                        analysis_result = parsed; break
                    else: system_p += "\nâš ï¸ æ ¼å¼éŒ¯èª¤ï¼šè«‹å‹™å¿…åŒ…å« step1_type_classification èˆ‡ step6_handcard æ¬„ä½ã€‚"
            except: pass

        if not analysis_result: analysis_result = {"step5_summary": "åˆ†æç”Ÿæˆå¤±æ•—ï¼Œè«‹åŸºæ–¼äº‹å¯¦é€²è¡Œè¾¯è«–ã€‚"}
        if "step6_handcard" in analysis_result: analysis_result["step5_summary"] = analysis_result["step6_handcard"]
        
        # [Strict Dynamic Audit]
        try:
            analysis_result = await self._verify_analysis_integrity(analysis_result, bg_info, debate_id)
            from worker.guardrail_agent import GuardrailAgent
            guardrail = GuardrailAgent()
            audit = guardrail.check("Chairman", json.dumps(analysis_result.get("step5_summary", "")), f"Facts: {bg_info}\nProfile: {self.official_profile_text}")
            if audit.get("status") == "REJECTED":
                self._publish_log(debate_id, f"â›” å¯©æŸ¥å“¡é§å›å¹»è¦ºåˆ†æã€‚æ­£åœ¨å•Ÿå‹•å¼·åˆ¶è„«æ°´...")
                analysis_result["step5_summary"] = await call_llm_async(f"èƒŒæ™¯äº‹å¯¦ï¼š{bg_info}\nå®˜æ–¹å®šç¾©ï¼š{self.official_profile_text}\nè¦æ±‚ï¼šåˆªé™¤æ‰€æœ‰ä¸ç¬¦é ˜åŸŸçš„æŠ€è¡“åè©æˆ–è™›æ§‹æ•¸æ“šã€‚", system_prompt="èª å¯¦åˆ†æå¸«ã€‚")
        except: pass

        return {"analysis": analysis_result, "bg_info": bg_info}

    async def _verify_analysis_integrity(self, analysis: Dict[str, Any], bg_info: str, debate_id: str = None) -> Dict[str, Any]:
        """[Phase 29] Dynamic Semantic Audit (No Hardcoding)."""
        summary = analysis.get("step5_summary", "")
        if not summary: return analysis
        prompt = f"æª¢æŸ¥ã€å®˜æ–¹å®šç¾©ã€‘èˆ‡ã€å¾…æŸ¥æ‘˜è¦ã€‘ã€‚å®šç¾©ï¼š{self.official_profile_text}\nèƒŒæ™¯ï¼š{bg_info}\næ‘˜è¦ï¼š{summary}\nè¦æ±‚ï¼šè‹¥æ‘˜è¦åŒ…å«èˆ‡å®˜æ–¹å®šç¾©è¡Œæ¥­äº’æ–¥çš„è¡“èªæˆ–è™›æ§‹æ•¸æ“šï¼Œå›å‚³ä¿®æ­£å¾Œçš„ JSON ç‰©ç†æ€§åˆªé™¤è©²æ®µã€‚å¦å‰‡å›å‚³ PASSEDã€‚"
        try:
            res = await call_llm_async(prompt, system_prompt="ç„¡æƒ…çš„äº‹å¯¦æ ¡é©—å“¡ã€‚")
            if "PASSED" not in res:
                json_match = re.search(r'\{.*\}', res, re.DOTALL)
                if json_match: analysis["step5_summary"] = json.loads(json_match.group(0))
        except: pass
        return analysis

    async def _validate_and_correction_decree(self, decree: Dict[str, Any], debate_id: str = None) -> Dict[str, Any]:
        subject = decree.get("subject", "Unknown"); code = decree.get("code", "Unknown"); final_decree = decree.copy()
        for k_n, k_c in STOCK_CODES.items():
            if k_n in str(subject):
                final_decree["subject"] = k_n; final_decree["code"] = k_c if "." in str(k_c) else f"{k_c}.TW"
                final_decree["is_verified"] = True; self._publish_log(debate_id, f"âœ… å·²é–å®šï¼š{k_n}")
                return final_decree
        return final_decree

    async def _generate_eda_summary(self, topic: str, debate_id: str, handcard: str = "") -> str:
        self._publish_log(debate_id, "ğŸ“Š å•Ÿå‹• EDA è‡ªå‹•åˆ†æ...")
        pattern = r'\b(\d{4})\b'; matches = re.findall(pattern, topic + str(handcard))
        if not matches: return "(ç„¡æ³•è­˜åˆ¥ä»£ç¢¼)"
        from worker.tool_invoker import call_tool
        loop = asyncio.get_running_loop()
        res = await loop.run_in_executor(None, call_tool, "chairman.eda_analysis", {"symbol": f"{matches[0]}.TW", "debate_id": debate_id})
        return res.get("summary", "(ç„¡æ•¸æ“š)")

    async def summarize_debate(self, debate_id: str, topic: str, rounds_data: list, handcard: str = "") -> str:
        """[Phase 29] Final Verdict with Strict Fact Anchoring and Evidence Tagging."""
        self._publish_log(debate_id, "ğŸ¬ æ­£åœ¨ç”¢å‡ºæœ€çµ‚è£æ±º (äº‹å¯¦éŒ¨å®šæ¨¡å¼)...")
        eda_summary = await self._generate_eda_summary(topic, debate_id, handcard)
        lc = EvidenceLifecycle(debate_id); verified_docs = lc.get_verified_evidence(limit=30)
        evidence_block = "\n".join([f"- ã€Ref:{d.id}ã€‘: {json.dumps(d.content, ensure_ascii=False)[:400]}" for d in verified_docs]) or "(ç„¡äº‹å¯¦è­‰æ“š)"
        
        prompt = f"æ’°å¯«æœ€çµ‚è£æ±ºå ±å‘Šã€‚è¦æ±‚ï¼šåªèƒ½å¼•ç”¨ã€Ref: IDã€‘ä¸­çš„æ•¸æ“šã€‚ç¦æ­¢æåŠèƒŒæ™¯æœªå‡ºç¾çš„è¡Œæ¥­è¡“èªã€‚è­‰æ“šï¼š\n{evidence_block}\nEDAåˆ†æï¼š\n{eda_summary}\nè¨˜éŒ„ï¼š\n{str(rounds_data)[:1000]}"
        verdict = await call_llm_async(prompt, system_prompt="åš´è¬¹ä¸»å¸­ï¼Œå¯§å¯ç•™ç™½ä¹Ÿä¸æé€ ã€‚", context_tag=f"{debate_id}:Verdict")
        
        from worker.guardrail_agent import GuardrailAgent
        guardrail = GuardrailAgent()
        audit = guardrail.check("Chairman_Verdict", verdict, f"Facts: {evidence_block}")
        if audit.get("status") == "REJECTED":
            self._publish_log(debate_id, "âš ï¸ ç™¼ç¾å¹»è¦ºæ•¸æ“šï¼Œæ­£åœ¨åŸ·è¡Œè„«æ°´è™•ç†...")
            verdict = await call_llm_async(f"åˆªé™¤å ±å‘Šä¸­ä»»ä½•ç„¡äº‹å¯¦æ ¹æ“šçš„æ®µè½æˆ–æŠ€è¡“åè©ï¼š\n{verdict}\näº‹å¯¦ï¼š{evidence_block}", system_prompt="æ•¸æ“šè„«æ°´ç·¨è¼¯å™¨ã€‚")
        return verdict
