from agentscope.agent import AgentBase
from typing import Dict, Any
import json
import re
from worker.llm_utils import call_llm
from worker.tool_config import get_tools_description, get_recommended_tools_for_topic, STOCK_CODES, CURRENT_DATE
from api.prompt_service import PromptService
from api.database import SessionLocal
from api.redis_client import get_redis_client
from api.tool_registry import tool_registry
from worker.llm_utils import call_llm_async
import asyncio
from worker.evidence_lifecycle import EvidenceLifecycle

# [Feature Flag: Facilitation]
try:
    from worker.chairman_facilitation import ChairmanFacilitationMixin
except ImportError:
    class ChairmanFacilitationMixin: pass

class Chairman(AgentBase, ChairmanFacilitationMixin):
    """
    ä¸»å¸­æ™ºèƒ½é«”ï¼Œè² è²¬ä¸»æŒè¾¯è«–ã€è³½å‰åˆ†æå’Œè³½å¾Œç¸½çµã€‚
    """

    def __init__(self, name: str, **kwargs: Any):
        super().__init__()
        self.name = name

    def speak(self, content: str):
        """
        ä¸»å¸­ç™¼è¨€ã€‚
        """
        print(f"Chairman '{self.name}': {content}")

    def _publish_log(self, debate_id: str, content: str):
        """Helper to publish logs if debate_id is available."""
        if not debate_id:
            return
        
        try:
            redis_client = get_redis_client()
            from datetime import datetime
            timestamp = datetime.now().strftime("%H:%M:%S")
            ui_content = f"[{timestamp}] {content}"
            message = json.dumps({"role": f"Chairman ({self.name})", "content": ui_content}, ensure_ascii=False)
            redis_client.publish(f"debate:{debate_id}:log_stream", message)
            redis_client.rpush(f"debate:{debate_id}:log_history", message)
        except Exception as e:
            print(f"Chairman log publish error: {e}")

    async def _investigate_topic_async(self, topic: str, debate_id: str = None) -> str:
        """
        Async implementation of investigation loop.
        """
        self._publish_log(debate_id, "ğŸ•µï¸ ä¸»å¸­æ­£åœ¨é€²è¡ŒèƒŒæ™¯èª¿æŸ¥ (Entity Recognition)...")
        
        # 1. Prepare Tools (Search & TEJ + ODS)
        investigation_tools = []
        target_tool_names = ["searxng.search", "tej.company_info", "tej.stock_price"]
        
        # [ODS Integration] Enable ODS for investigation if available
        # Note: In real world, ODS is an agent, not a simple tool.
        # But we can expose a tool interface "ask_data_scientist" that bridges to the agent.
        # For now, we keep using direct tools for basic investigation to save latency.
        
        for name in target_tool_names:
            try:
                tool_data = tool_registry.get_tool_data(name)
                # Ensure valid schema
                schema = tool_data.get('schema')
                if not schema:
                    schema = {"type": "object", "properties": {}, "required": []}
                elif isinstance(schema, dict):
                    if "type" not in schema: schema["type"] = "object"
                    if "properties" not in schema: schema["properties"] = {}
                
                # Fix: description might be a dict (metadata) or a string
                desc = tool_data.get('description', '')
                if isinstance(desc, dict):
                    desc = desc.get('description', '')

                investigation_tools.append({
                    "type": "function",
                    "function": {
                        "name": name,
                        "description": desc,
                        "parameters": schema
                    }
                })
            except:
                pass
        
        if not investigation_tools:
            return "ç„¡æ³•åŠ è¼‰èª¿æŸ¥å·¥å…·ï¼Œè·³éèƒŒæ™¯èª¿æŸ¥ã€‚"

        # 2. Prompt for Investigation
        prompt = f"""
è«‹å°è¾¯é¡Œã€Œ{topic}ã€é€²è¡Œåš´æ ¼çš„èƒŒæ™¯äº‹å¯¦èª¿æŸ¥ (Fact-Checking)ã€‚

**æ ¸å¿ƒä»»å‹™**ï¼š
1. **è­˜åˆ¥å¯¦é«”**ï¼šæ‰¾å‡ºå…¬å¸å…¨åèˆ‡è‚¡ç¥¨ä»£ç¢¼ (e.g., æ£®é‰… -> 8942)ã€‚
2. **ç”¢æ¥­å®šä½**ï¼šç¢ºèªå…¶ä¸»è¦ç”¢å“èˆ‡æ‰€å±¬ç”¢æ¥­ã€‚
   - âš ï¸ æ³¨æ„ï¼šä¸è¦ä¾è³´ç›´è¦ºçŒœæ¸¬ç”¢æ¥­ã€‚è‹¥ TEJ/ChinaTimes æŸ¥ç„¡è³‡æ–™ï¼Œ**å¿…é ˆ**ä½¿ç”¨ `searxng.search` æœå°‹ã€Œ{{å…¬å¸å}} åšä»€éº¼ã€æˆ–ã€Œ{{å…¬å¸å}} ç”¢å“ã€ã€‚
   - ç¯„ä¾‹ï¼šæ£®é‰… (8942) æ˜¯åšã€Œé‡‘å±¬è¤‡åˆæ¿/å»ºæã€ï¼Œçµ•éé›»å­è‚¡ã€‚è«‹å‹™å¿…æ ¸å¯¦ã€‚
3. **æ•¸æ“šæª¢æ ¸**ï¼šç¢ºèªæ˜¯å¦èƒ½ç²å–è²¡å‹™æ•¸æ“šã€‚è‹¥ç„¡æ³•ç²å–ï¼Œè«‹æ¨™è¨˜ç‚ºã€Œæ•¸æ“šç¼ºå¤±ã€ã€‚

èª¿æŸ¥çµæŸå¾Œï¼Œè«‹ç¸½çµä½ ç²å¾—çš„é—œéµèƒŒæ™¯è³‡è¨Šï¼ˆå…¬å¸å…¨åã€ä»£ç¢¼ã€ç¢ºåˆ‡ç”¢æ¥­ã€ä¸»è¦ç”¢å“ï¼‰ã€‚
"""
        # 3. Execution Loop (Simple 1-turn or 2-turn)
        context = []
        
        # Turn 1: Ask LLM to use tools
        self._publish_log(debate_id, "ğŸ•µï¸ æ­£åœ¨æ€è€ƒéœ€è¦çš„èª¿æŸ¥å·¥å…·...")
        response = await call_llm_async(prompt, system_prompt="ä½ æ˜¯è¾¯è«–ä¸»å¸­ï¼Œè² è²¬è³½å‰äº‹å¯¦æ ¸æŸ¥ã€‚", tools=investigation_tools, context_tag=f"{debate_id}:Chairman:Investigate")
        
        # Check tool calls
        # Check tool calls
        tool_results = []
        
        # [Evidence Lifecycle Integration]
        # [Evidence Lifecycle Integration]
        lc = EvidenceLifecycle(debate_id or "global")
        
        try:
            # Simple check for tool calls in response string (Ollama format)
            # or if using native tool calling, response might be JSON-like
            # We reuse the logic from debate_cycle but simplified
            import json
            
            # Try to extract JSON tool call
            # Note: This regex is simple; robust parsing is in tool_invoker/parser
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                tool_call = json.loads(json_match.group(0))
                if isinstance(tool_call, dict) and "tool" in tool_call:
                    t_name = tool_call["tool"]
                    t_params = tool_call["params"]
                    
                    self._publish_log(debate_id, f"ğŸ› ï¸ ä¸»å¸­èª¿ç”¨å·¥å…·: {t_name} {t_params}")
                    
                    # Execute
                    from worker.tool_invoker import call_tool
                    loop = asyncio.get_running_loop()
                    res = await loop.run_in_executor(None, call_tool, t_name, t_params)
                    
                    # [Lifecycle 1] Ingest & Verify
                    doc = lc.ingest(self.name, t_name, t_params, res)
                    doc = lc.verify(doc.id)
                    
                    # [Lifecycle 2] Handle Status
                    if doc.status == "VERIFIED":
                        tool_results.append(f"å·¥å…· {t_name} çµæœ (Verified): {json.dumps(res, ensure_ascii=False)}")
                        self._publish_log(debate_id, f"âœ… è­‰æ“šå·²é©—è­‰ä¸¦å…¥åº« (ID: {doc.id})")
                    elif doc.status == "QUARANTINE":
                        tool_results.append(f"å·¥å…· {t_name} çµæœç•°å¸¸ (Quarantined): {doc.verification_log[-1].get('reason')}")
                        self._publish_log(debate_id, f"âš ï¸ è­‰æ“šç•°å¸¸ï¼Œå·²éš”é›¢ã€‚")
                    
        except Exception as e:
            print(f"Investigation tool error: {e}")

        if not tool_results:
            return "æœªé€²è¡Œå·¥å…·èª¿ç”¨æˆ–èª¿ç”¨å¤±æ•—ã€‚"
            
        # [Lifecycle 3] Create Checkpoint & Handoff
        # We create a checkpoint of this investigation phase
        checkpoint = lc.create_checkpoint(
            step_name="background_investigation",
            context={"topic": topic, "summary_pending": True},
            next_actions={"suggested": "generate_summary"}
        )
        self._publish_log(debate_id, f"ğŸ’¾ å»ºç«‹èª¿æŸ¥å¿«ç…§ (Checkpoint ID: {checkpoint.id})")

        # Summarize findings
        # Only Verified evidence should strongly influence the summary
        summary_prompt = f"""
åŸºæ–¼ä»¥ä¸‹å·²é©—è­‰çš„èª¿æŸ¥è­‰æ“šï¼Œè«‹ç¸½çµé—œæ–¼ã€Œ{topic}ã€çš„èƒŒæ™¯äº‹å¯¦ï¼ˆå…¬å¸ä»£ç¢¼ã€æ¥­å‹™ç­‰ï¼‰ï¼š

{chr(10).join(tool_results)}

æ³¨æ„ï¼šåƒ…ä¾æ“šæ¨™è¨»ç‚º (Verified) çš„å…§å®¹é€²è¡Œäº‹å¯¦é™³è¿°ã€‚
"""
        summary = await call_llm_async(summary_prompt, system_prompt="ä½ æ˜¯è¾¯è«–ä¸»å¸­ã€‚è«‹åŸºæ–¼è­‰æ“šé€²è¡Œå ±å‘Šã€‚", context_tag=f"{debate_id}:Chairman:InvestigateSummary")
        self._publish_log(debate_id, f"ğŸ“‹ èƒŒæ™¯èª¿æŸ¥ç¸½çµï¼š{summary[:100]}...")
        return summary

    async def pre_debate_analysis(self, topic: str, debate_id: str = None) -> Dict[str, Any]:
        """
        åŸ·è¡Œè³½å‰åˆ†æçš„ 7 æ­¥ç®¡ç·š (Async)ã€‚
        """
        print(f"Chairman '{self.name}' is starting pre-debate analysis for topic: '{topic}'")
        self._publish_log(debate_id, f"æ­£åœ¨é–‹å§‹è³½å‰åˆ†æï¼š{topic}...")

        # [New] Step 0: Background Investigation
        bg_info = await self._investigate_topic_async(topic, debate_id)

        # ç²å–æ¨è–¦å·¥å…·
        self._publish_log(debate_id, "ğŸ” æ­¥é©Ÿ 1/3: æ­£åœ¨åˆ†æé¡Œç›®ä¸¦æª¢ç´¢æ¨è–¦å·¥å…·...")
        recommended_tools = get_recommended_tools_for_topic(topic)
        tools_desc = get_tools_description()
        
        # ä½¿ç”¨ PromptService ç²å– Prompt
        self._publish_log(debate_id, "ğŸ§  æ­¥é©Ÿ 2/3: æ­£åœ¨æ§‹å»º 7 æ­¥åˆ†ææ€ç¶­éˆ (Chain of Thought)...")
        db = SessionLocal()
        try:
            # Note: Hardcoded prompt removed. We rely on PromptService to load from prompts/system/chairman_analysis.yaml
            template = PromptService.get_prompt(db, "chairman.pre_debate_analysis")
            
            if not template:
                print("CRITICAL WARNING: 'chairman.pre_debate_analysis' prompt not found in DB or Files.")
                self._publish_log(debate_id, "âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ°åˆ†ææ¨¡æ¿ï¼Œä½¿ç”¨é è¨­æ¨¡æ¿ã€‚")
                # Minimal fallback to prevent crash, but strictly minimal as requested
                template = "è«‹åˆ†æè¾¯é¡Œï¼š{{topic}}"

            from datetime import datetime, timedelta
            now = datetime.strptime(CURRENT_DATE, "%Y-%m-%d")
            current_quarter = (now.month - 1) // 3 + 1
            
            format_vars = {
                # Remove tools_desc to prevent LLM from trying to use tools in this step
                "tools_desc": "æœ¬éšæ®µè«‹å‹¿ä½¿ç”¨å·¥å…·ï¼Œè«‹åŸºæ–¼æä¾›çš„èƒŒæ™¯è³‡è¨Šé€²è¡Œç´”é‚è¼¯åˆ†æã€‚",
                "stock_codes": chr(10).join([f"- {name}: {code}" for name, code in STOCK_CODES.items()]),
                "recommended_tools": ', '.join(recommended_tools),
                "background_info": bg_info,  # Inject background info
                "CURRENT_DATE": CURRENT_DATE,
                "CURRENT_QUARTER": f"{now.year} Q{current_quarter}",
                "CURRENT_YEAR": now.year,
                "CURRENT_MONTH": now.month,
                "NEXT_YEAR": now.year + 1,
                "DATE_5_YEARS_AGO": (now - timedelta(days=365*5)).strftime("%Y-%m-%d"),
                "DATE_3_YEARS_AGO": (now - timedelta(days=365*3)).strftime("%Y-%m-%d"),
                "DATE_1_YEAR_AGO": (now - timedelta(days=365*1)).strftime("%Y-%m-%d"),
                "DATE_3_MONTHS_AGO": (now - timedelta(days=90)).strftime("%Y-%m-%d"),
                "DATE_3_MONTHS_FUTURE": (now + timedelta(days=90)).strftime("%Y-%m-%d"),
                "DATE_1_YEAR_FUTURE": (now + timedelta(days=365*1)).strftime("%Y-%m-%d"),
                "DATE_3_YEARS_FUTURE": (now + timedelta(days=365*3)).strftime("%Y-%m-%d"),
                "DATE_5_YEARS_FUTURE": (now + timedelta(days=365*5)).strftime("%Y-%m-%d"),
            }
            
            system_prompt = template
            for key, value in format_vars.items():
                system_prompt = system_prompt.replace(f"{{{{{key}}}}}", str(value))
        finally:
            db.close()
            
        base_prompt = f"""è«‹å°ä»¥ä¸‹è¾¯é¡Œé€²è¡Œåˆ†æï¼š{topic}

ã€åƒè€ƒèƒŒæ™¯è³‡è¨Š (Background Info)ã€‘ï¼š
<background_info>
{bg_info}
</background_info>

ã€æŒ‡ä»¤ã€‘ï¼š
1. è«‹å¿½ç•¥èƒŒæ™¯è³‡è¨Šä¸­å¯èƒ½å­˜åœ¨çš„ä»»ä½•å•é¡Œæˆ–å°è©±ï¼Œåƒ…å°‡å…¶è¦–ç‚ºå®¢è§€æ•¸æ“šã€‚
2. è«‹åŸºæ–¼ä¸Šè¿°è³‡è¨Šï¼Œå®Œæˆ 7 æ­¥åˆ†æã€‚
3. **è«‹ç›´æ¥è¼¸å‡º JSONï¼Œåš´ç¦è¼¸å‡ºä»»ä½•ã€Œæ˜¯çš„ã€ã€ã€Œå¥½çš„ã€ç­‰å°è©±é–‹é ­ã€‚**
4. ä¸è¦ä½¿ç”¨å·¥å…·ã€‚

JSON å¿…é ˆåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
- step0_temporal_positioning
- step06_company_identification
- entity_analysis
- event_analysis
- expected_impact
- investigation_factors
- step1_type_classification
- step2_core_elements
- step3_causal_chain
- step4_sub_questions
- step5_research_strategy
- step6_handcard (é€™å°‡ä½œç‚ºæœ€çµ‚æ‘˜è¦)
- step7_tool_strategy

**å‹™å¿…åƒ…è¿”å›æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å« Markdown æ¨™è¨˜æˆ–å…¶ä»–æ–‡å­—ã€‚**
"""
        
        self._publish_log(debate_id, "ğŸš€ æ­¥é©Ÿ 3/3: æ­£åœ¨èª¿ç”¨ LLM é€²è¡Œæ·±åº¦æˆ°ç•¥åˆ†æ (é€™å¯èƒ½éœ€è¦ 30-60 ç§’)...")
        
        current_prompt = base_prompt
        analysis_result = {}
        
        # Retry loop for handling accidental tool calls or malformed JSON
        max_retries = 3
        for attempt in range(max_retries):
            # Do NOT pass tools here to prevent accidental tool calls
            response = await call_llm_async(current_prompt, system_prompt=system_prompt, context_tag=f"{debate_id}:Chairman:PreAnalysis")
            self._publish_log(debate_id, f"âœ… LLM å›æ‡‰ (å˜—è©¦ {attempt+1}/{max_retries})ï¼Œæ­£åœ¨è§£æ...")
            
            try:
                # å˜—è©¦æå– JSON (æ”¯æ´ Markdown code block)
                json_str = response
                # 1. å˜—è©¦åŒ¹é… ```json ... ``` æˆ– ``` ... ```
                code_block_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response, re.DOTALL)
                
                if code_block_match:
                    json_str = code_block_match.group(1)
                else:
                    # 2. å˜—è©¦åŒ¹é…æœ€å¤–å±¤çš„ { ... }
                    json_match = re.search(r'\{.*\}', response, re.DOTALL)
                    if json_match:
                        json_str = json_match.group(0)
                
                # å˜—è©¦è§£æ JSON
                try:
                    parsed_json = json.loads(json_str, strict=False)
                except json.JSONDecodeError:
                    # å˜—è©¦ä¿®å¾©å¸¸è¦‹éŒ¯èª¤: æœªè½‰ç¾©çš„æ›è¡Œç¬¦
                    fixed_json_str = json_str.replace('\n', '\\n')
                    parsed_json = json.loads(fixed_json_str, strict=False)

                if isinstance(parsed_json, list) and len(parsed_json) > 0 and isinstance(parsed_json[0], dict):
                    # Handle case where LLM wraps dict in a list
                    parsed_json = parsed_json[0]

                if not isinstance(parsed_json, dict):
                     raise ValueError(f"Parsed JSON is not a dictionary. Type: {type(parsed_json)}")
                
                # Check if it's a tool call
                if "tool" in parsed_json and "params" in parsed_json:
                    tool_name = parsed_json["tool"]
                    tool_params = parsed_json["params"]
                    self._publish_log(debate_id, f"âš ï¸ æª¢æ¸¬åˆ°å·¥å…·èª¿ç”¨ ({tool_name})ï¼Œæ­£åœ¨åŸ·è¡Œè£œæ•‘æªæ–½...")
                    
                    # Execute the tool
                    from worker.tool_invoker import call_tool
                    loop = asyncio.get_running_loop()
                    tool_res = await loop.run_in_executor(None, call_tool, tool_name, tool_params)
                    
                    # Append result to prompt and ask again
                    tool_res_str = json.dumps(tool_res, ensure_ascii=False)
                    current_prompt += f"\n\nã€è£œå……å·¥å…·åŸ·è¡Œçµæœ ({tool_name})ã€‘ï¼š\n{tool_res_str}\n\nè«‹ç¹¼çºŒå®Œæˆä¸Šè¿°çš„ 7 æ­¥åˆ†æ JSON å ±å‘Šï¼Œä¸è¦å†èª¿ç”¨å·¥å…·ã€‚"
                    continue # Retry loop
                
                # If we got here, it's likely the analysis result
                analysis_result = parsed_json
                break # Success
                
            except Exception as e:
                print(f"Error parsing analysis result (attempt {attempt+1}): {e}")
                if attempt == max_retries - 1:
                    # Final attempt failed
                    # Construct a dummy analysis result from response if possible or fail gracefully
                    analysis_result = {
                        "step5_summary": f"åˆ†æå¤±æ•— (è§£æéŒ¯èª¤): {str(e)}\nResponse: {response[:200]}..."
                    }
                    pass

        # ç‚ºäº†å…¼å®¹èˆŠä»£ç¢¼ï¼Œå°‡ step6_handcard æ˜ å°„ç‚º step5_summary (å› ç‚º debate_cycle.py ä½¿ç”¨æ­¤ key)
        if "step6_handcard" in analysis_result:
            analysis_result["step5_summary"] = analysis_result["step6_handcard"]
        elif analysis_result.get("step5_summary") is None: # Only if neither handcard nor summary exists
            # å˜—è©¦å¾å…¶ä»–æ¬„ä½æ§‹å»ºæ‘˜è¦
            summary_parts = []
            if "step1_type_classification" in analysis_result:
                summary_parts.append(f"é¡Œå‹ï¼š{analysis_result['step1_type_classification']}")
            elif "step1_type" in analysis_result: # Backward compatibility
                summary_parts.append(f"é¡Œå‹ï¼š{analysis_result['step1_type']}")
            
            if "step0_5_region_positioning" in analysis_result:
                region_info = analysis_result["step0_5_region_positioning"]
                if isinstance(region_info, dict):
                    region = region_info.get("region", "Unknown")
                    summary_parts.append(f"å€åŸŸå®šä½ï¼š{region}")

            if "step00_company_identification" in analysis_result:
                comp_info = analysis_result["step00_company_identification"]
                if isinstance(comp_info, dict):
                    companies = comp_info.get("identified_companies", "None")
                    codes = comp_info.get("stock_codes", "None")
                    summary_parts.append(f"è­˜åˆ¥å…¬å¸ï¼š{companies} ({codes})")

            if "step0_5_industry_identification" in analysis_result:
                industry_info = analysis_result["step0_5_industry_identification"]
                if isinstance(industry_info, dict):
                    domain = industry_info.get("industry_domain", "Unknown")
                    summary_parts.append(f"æ¶‰åŠç”¢æ¥­ï¼š{domain}")
                    companies = industry_info.get("leading_companies", [])
                    if companies and isinstance(companies, list):
                        company_names = [c.get("name", "") for c in companies if isinstance(c, dict)]
                        summary_parts.append(f"é¾é ­ä¼æ¥­ï¼š{', '.join(company_names)}")
            
            # [New] Add Entity and Event info to summary if handcard/summary is missing
            if "entity_analysis" in analysis_result:
                entity_info = analysis_result["entity_analysis"]
                if isinstance(entity_info, dict):
                    entity = entity_info.get("primary_entity", {})
                    if isinstance(entity, dict):
                        summary_parts.append(f"æ ¸å¿ƒå¯¦é«”ï¼š{entity.get('name', 'N/A')} ({entity.get('code', 'N/A')})")
                elif isinstance(entity_info, str):
                    summary_parts.append(f"æ ¸å¿ƒå¯¦é«”åˆ†æï¼š{entity_info}")
            
            if "event_analysis" in analysis_result:
                event_info = analysis_result["event_analysis"]
                if isinstance(event_info, dict):
                    summary_parts.append(f"äº‹ä»¶é¡å‹ï¼š{event_info.get('event_type', 'N/A')}")
                    summary_parts.append(f"é—œéµè¡Œå‹•ï¼š{event_info.get('action', 'N/A')}")
                elif isinstance(event_info, str):
                    summary_parts.append(f"äº‹ä»¶åˆ†æï¼š{event_info}")
                
            if "step2_elements" in analysis_result: # Same key in new prompt? No, new is same step2_core_elements?
                # Wait, prompt says: step2_core_elements. Old code: step2_elements.
                summary_parts.append(f"é—œéµè¦ç´ ï¼š{analysis_result['step2_elements']}")
            elif "step2_core_elements" in analysis_result:
                summary_parts.append(f"é—œéµè¦ç´ ï¼š{analysis_result['step2_core_elements']}")
                
            if "step5_research_strategy" in analysis_result:
                summary_parts.append(f"è³‡æ–™è’é›†æˆ°ç•¥ï¼š{analysis_result['step5_research_strategy']}")
            
            if summary_parts:
                analysis_result["step5_summary"] = "\n".join(summary_parts)
            else:
                print(f"WARNING: LLM Analysis JSON missing key fields. Keys found: {list(analysis_result.keys())}")
                analysis_result["step5_summary"] = f"åˆ†æå®Œæˆï¼Œä½†åœ¨æå–æ‘˜è¦æ™‚é‡åˆ°å•é¡Œã€‚å®Œæ•´å›æ‡‰å¦‚ä¸‹ï¼š\n{json.dumps(analysis_result, ensure_ascii=False, indent=2)}"

        # Debug: ç¢ºèª step5_summary å­˜åœ¨
        print(f"DEBUG: analysis_result keys: {list(analysis_result.keys())}")
        summary_value = analysis_result.get('step5_summary', 'KEY_NOT_FOUND')
        summary_preview = str(summary_value)[:200] if summary_value else "EMPTY"
        print(f"DEBUG: step5_summary value: {summary_preview}")
        
        # [Topic Locking] Generate Decree
        decree = {
            "subject": "Unknown",
            "code": "Unknown",
            "timeframe": "Unknown",
            "core_question": "Unknown"
        }
        
        try:
            # 1. Subject & Code from Step 06 or entity_analysis
            step06 = analysis_result.get("step06_company_identification", {})
            entity_analysis = analysis_result.get("entity_analysis", {})
            
            if isinstance(step06, dict) and step06.get("identified_companies"):
                decree["subject"] = step06.get("identified_companies", "Unknown")
                decree["code"] = step06.get("stock_codes", "Unknown")
            elif isinstance(entity_analysis, dict):
                primary_entity = entity_analysis.get("primary_entity", {})
                if isinstance(primary_entity, dict):
                    decree["subject"] = primary_entity.get("name", "Unknown")
                    decree["code"] = primary_entity.get("code", "Unknown")
                elif isinstance(entity_analysis.get("name"), str): # Robustness for flatter structure
                    decree["subject"] = entity_analysis.get("name", "Unknown")
                    decree["code"] = entity_analysis.get("code", "Unknown")
            
            # 2. Timeframe & Question from Step 2/Step 0
            step2 = analysis_result.get("step2_core_elements", "")
            step0 = analysis_result.get("step0_temporal_positioning", {})
            
            if isinstance(step0, dict):
                decree["timeframe"] = step0.get("current_phase", "Unknown")
            
            if isinstance(step2, str):
                 decree["core_question"] = step2[:100] # Summarize from elements
                 
            # Add to result
            analysis_result["step00_decree"] = decree
            
            # [Validation] Validate and Correct Decree
            validated_decree = await self._validate_and_correction_decree(decree, debate_id)
            analysis_result["step00_decree"] = validated_decree
            print(f"DEBUG: Final Validated Decree: {validated_decree}")
            
        except Exception as e:
            print(f"Error generating decree: {e}")
            
        # [Analysis Verification] New Step: Verify Integrity of the Analysis
        try:
            analysis_result = await self._verify_analysis_integrity(analysis_result, bg_info, debate_id)
        except Exception as e:
             print(f"Analysis verification failed: {e}")
             self._publish_log(debate_id, f"âš ï¸ åˆ†æé©—è­‰å¤±æ•—ï¼Œå°‡ä½¿ç”¨åŸå§‹çµæœã€‚")

        print(f"Pre-debate analysis completed.")
        return analysis_result

    async def _verify_analysis_integrity(self, analysis: Dict[str, Any], bg_info: str, debate_id: str = None) -> Dict[str, Any]:
        """
        Verify the integrity of the pre-debate analysis result (Handcard).
        Ensures that facts mentioned in the handcard are consistent with background info and verified data.
        """
        self._publish_log(debate_id, "ğŸ›¡ï¸ æ­£åœ¨åŸ·è¡Œä¸»å¸­åˆ†æé©—è­‰ (Analysis Integrity Check)...")
        
        # Extract Handcard content
        handcard = analysis.get("step6_handcard") or analysis.get("step5_summary")
        if not handcard:
            return analysis
            
        handcard_str = json.dumps(handcard, ensure_ascii=False) if isinstance(handcard, dict) else str(handcard)
        
        # Prompt Guardrail to check
        prompt = f"""
        ä½ æ˜¯ç³»çµ±åˆè¦å¯©æŸ¥å“¡ (Guardrail Agent)ã€‚è«‹æª¢æŸ¥ä»¥ä¸‹ã€ä¸»å¸­è³½å‰åˆ†æå ±å‘Šã€‘æ˜¯å¦å­˜åœ¨ã€Œäº‹å¯¦å¹»è¦ºã€æˆ–ã€Œæ•¸æ“šæé€ ã€ã€‚

        ã€èƒŒæ™¯äº‹å¯¦ (Background Info - Verified)ã€‘:
        {bg_info}

        ã€ä¸»å¸­åˆ†æå ±å‘Š (Target to Check)ã€‘:
        {handcard_str}

        è«‹æª¢æŸ¥ä»¥ä¸‹é …ç›®ï¼š
        1. å ±å‘Šä¸­æåˆ°çš„å…·é«”æ•¸å­—ï¼ˆå¦‚è‚¡åƒ¹ã€ç‡Ÿæ”¶ã€æ—¥æœŸï¼‰æ˜¯å¦èˆ‡èƒŒæ™¯äº‹å¯¦ä¸€è‡´ï¼Ÿ
        2. æ˜¯å¦å¼•ç”¨äº†èƒŒæ™¯äº‹å¯¦ä¸­ä¸å­˜åœ¨çš„ã€Œå…·é«”ç´°ç¯€ã€ï¼Ÿ(å¦‚æœæ˜¯ï¼Œé€™æ˜¯å¹»è¦º)
        3. å…¬å¸ä»£ç¢¼èˆ‡åç¨±æ˜¯å¦æ­£ç¢ºï¼Ÿ

        å¦‚æœæœ‰å•é¡Œï¼Œè«‹è¼¸å‡ºä¿®æ­£å»ºè­°ã€‚å¦‚æœæ²’å•é¡Œï¼Œè«‹è¼¸å‡º "PASSED"ã€‚
        åªè¼¸å‡ºæª¢æŸ¥çµæœã€‚
        """
        
        check_result = await call_llm_async(prompt, system_prompt="ä½ æ˜¯åš´æ ¼çš„äº‹å¯¦æŸ¥æ ¸å“¡ã€‚", context_tag=f"{debate_id}:Chairman:AnalysisCheck")
        
        if "PASSED" not in check_result:
            self._publish_log(debate_id, f"âš ï¸ åˆ†æå ±å‘Šæª¢æ¸¬åˆ°æ½›åœ¨é¢¨éšªï¼š\n{check_result[:100]}...")
            
            # Append warning to handcard
            warning_note = f"\n\n[âš ï¸ SYSTEM WARNING]: æœ¬åˆ†æå ±å‘Šéƒ¨åˆ†å…§å®¹å¯èƒ½éœ€é€²ä¸€æ­¥æŸ¥è­‰ã€‚\næŸ¥æ ¸æ„è¦‹: {check_result}"
            
            if isinstance(analysis.get("step6_handcard"), dict):
                analysis["step6_handcard"]["verification_note"] = warning_note
            elif isinstance(analysis.get("step6_handcard"), str):
                 analysis["step6_handcard"] += warning_note
                 
            # Also update summary
            if isinstance(analysis.get("step5_summary"), str):
                 analysis["step5_summary"] += warning_note

        else:
            self._publish_log(debate_id, f"âœ… åˆ†æå ±å‘Šå·²é€šéå®Œæ•´æ€§é©—è­‰ (Guardrail Passed)ã€‚")
            
        return analysis

    async def _validate_and_correction_decree(self, decree: Dict[str, Any], debate_id: str = None) -> Dict[str, Any]:
        """
        Validate and correct the decree (Subject & Code) using tools.
        """
        self._publish_log(debate_id, "âš–ï¸ ä¸»å¸­æ­£åœ¨é©—è­‰é¡Œç›®é–å®š (Decree Validation)...")
        
        subject = decree.get("subject", "Unknown")
        code = decree.get("code", "Unknown")
        final_decree = decree.copy()
        
        # Helper to check validity
        def is_valid(val):
            return val and val not in ["Unknown", "None", ""]

        from worker.tool_invoker import call_tool
        loop = asyncio.get_running_loop()

        # Strategy 1: Verify Code AND Correct Name if exists
        verified = False
        if is_valid(code):
            # 1.1 Priority: ChinaTimes Fundamental (Best for Chinese Name & Sector)
            try:
                res_ct = await loop.run_in_executor(None, call_tool, "chinatimes.stock_fundamental", {"code": code})
                data_ct = res_ct.get("data")
                if data_ct:
                    # Expecting WantRich API: { "Code": "2330", "Name": "å°ç©é›»", "SectorName": "åŠå°é«”æ¥­" ... }
                    ct_name = data_ct.get("Name")
                    ct_sector = data_ct.get("SectorName") or data_ct.get("Industry")
                    
                    if ct_name:
                        # [CORRECTION] Force update subject name from official source
                        final_decree["subject"] = ct_name
                        self._publish_log(debate_id, f"âœ… (ChinaTimes) åç¨±æ ¡æ­£ï¼š{code} -> {ct_name}")
                        verified = True
                        
                    if ct_sector:
                        final_decree["industry"] = ct_sector
                        self._publish_log(debate_id, f"ğŸ­ ç”¢æ¥­ç¢ºèª (ChinaTimes)ï¼š{ct_sector}")
            except Exception as e:
                # print(f"ChinaTimes verification warning: {e}")
                pass

            # 1.2 Priority: TEJ Company Info (Good for Name & Sector)
            if not verified:
                try:
                    res = await loop.run_in_executor(None, call_tool, "tej.company_info", {"coid": code})
                    data = res.get("results") or res.get("data")
                    if data and isinstance(data, list) and len(data) > 0:
                        row = data[0]
                        # TEJ fields: cname (Chinese Name), ename (English Name), ind_name (Industry)
                        official_name = row.get("cname") or row.get("ename")
                        
                        if official_name:
                            final_decree["subject"] = official_name
                            self._publish_log(debate_id, f"âœ… (TEJ) åç¨±æ ¡æ­£ï¼š{code} -> {official_name}")
                            verified = True
                        
                        ind_name = row.get("ind_name") or row.get("tej_ind_name")
                        if ind_name:
                            final_decree["industry"] = ind_name
                            self._publish_log(debate_id, f"ğŸ­ ç”¢æ¥­ç¢ºèª (TEJ)ï¼š{ind_name}")
                except Exception as e:
                    # print(f"TEJ verification warning: {e}")
                    pass

            # 1.3 Fallback: TWSE (Checks existence only, weak name correction)
            if not verified:
                try:
                    from worker.tool_config import CURRENT_DATE
                    res_twse = await loop.run_in_executor(None, call_tool, "twse.stock_day", {"symbol": code, "date": CURRENT_DATE})
                    data_twse = res_twse.get("data") or res_twse.get("results")
                    
                    # If we get price data, code exists. But we can't confirm name.
                    if data_twse and isinstance(data_twse, list) and len(data_twse) > 0:
                        # We assume the user/LLM provided name is "okay" if we can't correct it,
                        # OR we try to fetch name from another specific TWSE tool if available.
                        # For now, mark as verified existence but warn about name.
                        self._publish_log(debate_id, f"âœ… (TWSE) ä»£ç¢¼å­˜åœ¨ç¢ºèªï¼š{code} (åç¨±æœªæ ¡æ­£)")
                        verified = True
                except Exception as e:
                    pass
                try:
                    # Try TEJ Company Info
                    res = await loop.run_in_executor(None, call_tool, "tej.company_info", {"coid": code})
                    # Check directly in 'results' or 'data' depending on API structure
                    # Usually TEJ tools return dict with 'results' list or 'data'
                    data = res.get("results") or res.get("data")
                    if data and isinstance(data, list) and len(data) > 0:
                        # Success! Update subject from official name if possible
                        row = data[0]
                        official_name = row.get("ename") or row.get("cname")
                        if official_name:
                            final_decree["subject"] = official_name
                        
                        # [Industry Grounding] Extract Industry Info
                        ind_name = row.get("ind_name") or row.get("tej_ind_name") # Try standard fields
                        if ind_name:
                            final_decree["industry"] = ind_name
                            self._publish_log(debate_id, f"ğŸ­ ç”¢æ¥­ç¢ºèª (TEJ)ï¼š{ind_name}")
                        
                        self._publish_log(debate_id, f"âœ… (TEJ) é©—è­‰æˆåŠŸï¼š{code} -> {final_decree['subject']}")
                        verified = True
                except Exception as e:
                    print(f"Validation verification failed: {e}")

        # Strategy 2: If not verified (Code invalid or missing), search by Subject
        if not verified and is_valid(subject):
            self._publish_log(debate_id, f"âš ï¸ ä»£ç¢¼æœªç¢ºèªï¼Œæ­£é€éåç¨±ã€Œ{subject}ã€åæŸ¥...")
            try:
                # Use SearXNG
                q = f"{subject} è‚¡ç¥¨ä»£è™Ÿ stock code"
                search_res = await loop.run_in_executor(None, call_tool, "searxng.search", {"q": q, "num_results": 3})
                
                # Use LLM to extract code
                prompt = f"""
                è«‹å¾ä»¥ä¸‹æœå°‹çµæœä¸­æå–ã€Œ{subject}ã€çš„è‚¡ç¥¨ä»£ç¢¼ (Stock Code)ã€‚
                æœå°‹çµæœï¼š
                {str(search_res)[:1000]}
                
                å¦‚æœæ‰¾åˆ°ï¼Œè«‹åªè¼¸å‡ºä»£ç¢¼ (ä¾‹å¦‚ "2330" æˆ– "2330.TW")ã€‚
                å¦‚æœæ‰¾ä¸åˆ°ï¼Œè«‹è¼¸å‡º "Unknown"ã€‚
                """
                extracted_code = await call_llm_async(prompt, system_prompt="ä½ æ˜¯åŠ©æ‰‹ã€‚", context_tag=f"{debate_id}:Chairman:ExtractCode")
                extracted_code = extracted_code.strip().replace('"', '').replace("'", "")
                
                if is_valid(extracted_code) and extracted_code != "Unknown":
                    final_decree["code"] = extracted_code
                    self._publish_log(debate_id, f"âœ… åæŸ¥æˆåŠŸï¼š{subject} -> {extracted_code}")
                    verified = True
                else:
                    self._publish_log(debate_id, f"âŒ åæŸ¥å¤±æ•—ï¼Œç¶­æŒåŸå§‹è¨­å®šã€‚")
            except Exception as e:
                print(f"Validation correction failed: {e}")

        final_decree["is_verified"] = verified
        return final_decree

    def summarize_round(self, debate_id: str, round_num: int, handcard: str = ""):
        """
        å°æœ¬è¼ªè¾¯è«–é€²è¡Œç¸½çµï¼ŒåŸºæ–¼è³½å‰æ‰‹å¡é€²è¡Œè©•ä¼°ã€‚
        """
        print(f"Chairman '{self.name}' is summarizing round {round_num}.")
        
        redis_client = get_redis_client()
        evidence_key = f"debate:{debate_id}:evidence"
        
        # ç²å–æœ¬è¼ªç´¯ç©çš„è­‰æ“š/å·¥å…·èª¿ç”¨
        try:
            evidence_list = [json.loads(item) for item in redis_client.lrange(evidence_key, 0, -1)]
        except Exception as e:
            print(f"Error fetching evidence from Redis: {e}")
            evidence_list = []
        
        # æ§‹å»ºè­‰æ“šæ‘˜è¦ (æ‡‰ç”¨ç°¡å–®çš„ç·Šæ¹ŠåŒ–ç­–ç•¥)
        compact_evidence = []
        for e in evidence_list:
            content = e.get('content', str(e))
            if len(content) > 500:
                content = content[:200] + "...(ç•¥)..." + content[-200:]
            compact_evidence.append(f"- {e.get('role', 'Unknown')}: {content}")
            
        evidence_text = "\n".join(compact_evidence)
        
        # é€™è£¡ç†æƒ³æƒ…æ³ä¸‹æ‡‰è©²ä¹Ÿè¦ç²å–æœ¬è¼ªçš„ç™¼è¨€å…§å®¹ (éœ€å¾ Redis log stream æˆ– DB ç²å–)
        # æš«æ™‚ä¾è³´ evidence_list ä½œç‚ºä»£ç†ï¼Œæˆ–è€…å‡è¨­ debate_cycle æœƒå‚³å…¥ä¸Šä¸‹æ–‡
        
        db = SessionLocal()
        next_round = round_num + 1
        try:
            # Hardcoded prompt removed. Rely on prompts/system/chairman_summary.yaml
            template = PromptService.get_prompt(db, "chairman.summarize_round")
            if not template:
                print("WARNING: 'chairman.summarize_round' prompt not found.")
                template = "è«‹ç¸½çµæœ¬è¼ªè¾¯è«–ã€‚"
            system_prompt = template.format(round_num=round_num, handcard=handcard, next_round=next_round)
            
            # Load User Prompt
            user_template = PromptService.get_prompt(db, "chairman.summarize_round_user")
            if not user_template: user_template = "{evidence_text}"
            user_prompt = user_template.format(evidence_text=evidence_text)
        finally:
            db.close()

        if not evidence_list:
            user_prompt += "\n(æœ¬è¼ªæœªæ”¶é›†åˆ°å…·é«”è­‰æ“šå·¥å…·èª¿ç”¨)"

        summary = call_llm(user_prompt, system_prompt=system_prompt)
        
        prefix = f"ã€ç¬¬ {round_num} è¼ªç¸½çµã€‘\n"
        final_summary = prefix + summary
        self.speak(final_summary)
        
        # æ¸…é™¤æœ¬è¼ªè­‰æ“š (æº–å‚™ä¸‹ä¸€è¼ª)
        try:
            redis_client.delete(evidence_key)
        except Exception as e:
            print(f"Error clearing evidence key: {e}")
            
        return final_summary

    async def _conduct_extended_research(self, topic: str, verdict: str, debate_id: str = None) -> str:
        """
        Conduct extended research to generate actionable advice based on the debate verdict.
        This allows the Chairman to use tools globally to find "Next Steps" for the user.
        """
        self._publish_log(debate_id, "ğŸ”¬ ä¸»å¸­æ­£åœ¨é€²è¡Œå»¶ä¼¸èª¿æŸ¥ (Extended Research) ä»¥ç”Ÿæˆè¡Œå‹•å»ºè­°...")
        
        # 1. Plan Research Questions
        plan_prompt = f"""
        åŸºæ–¼è¾¯é¡Œã€Œ{topic}ã€èˆ‡åˆæ­¥çµè«–ã€Œ{verdict[:200]}...ã€ï¼Œè«‹åˆ—å‡º 3 å€‹å…·é«”çš„å»¶ä¼¸èª¿æŸ¥å•é¡Œï¼Œä»¥ä¾¿ç‚ºæŠ•è³‡è€…ç”Ÿæˆå¯åŸ·è¡Œçš„è¡Œå‹•å»ºè­°ã€‚
        å•é¡Œæ–¹å‘ç¯„ä¾‹ï¼š
        - å¦‚ä½•ä¸‹è¼‰æŸ ETF çš„æŒè‚¡æ¸…å–®ï¼Ÿ
        - æŸé¾é ­ä¼æ¥­çš„æœ€æ–°è‚¡æ¯æ”¯ä»˜ç‡æ˜¯å¤šå°‘ï¼Ÿ
        - å“ªè£¡å¯ä»¥æŸ¥çœ‹æœ€æ–°çš„ç”¢æ¥­é¢¨éšªå ±å‘Šï¼Ÿ
        
        è«‹ç›´æ¥åˆ—å‡ºå•é¡Œï¼Œæ¯è¡Œä¸€å€‹ã€‚
        """
        questions_text = await call_llm_async(plan_prompt, system_prompt="ä½ æ˜¯å°ˆæ¥­æŠ•è³‡é¡§å•ã€‚", context_tag=f"{debate_id}:Chairman:AdvicePlan")
        questions = [q.strip() for q in questions_text.split('\n') if q.strip()]
        
        # 2. Execute Research (Smart Tool Selection)
        research_results = []
        
        # Prepare Tools (Prioritize High-Value Paid Tools)
        target_tool_names = [
            # Premium Paid Tools (ChinaTimes & Google)
            "chinatimes.news_search",
            "chinatimes.stock_fundamental",
            "chinatimes.financial_ratios",
            "google.search", # Paid/Official Google Search
            
            # Standard/Trial Tools (TEJ)
            "tej.company_info",
            "tej.stock_price",
            
            # Fallback
            "searxng.search"
        ]
        
        research_tools = []
        for name in target_tool_names:
            try:
                tool_data = tool_registry.get_tool_data(name)
                # Ensure valid schema
                schema = tool_data.get('schema', {"type": "object", "properties": {}})
                if isinstance(schema, dict):
                     if "type" not in schema: schema["type"] = "object"
                
                desc = tool_data.get('description', '')
                if isinstance(desc, dict): desc = desc.get('description', '')
                
                research_tools.append({
                    "type": "function",
                    "function": {
                        "name": name,
                        "description": desc,
                        "parameters": schema
                    }
                })
            except:
                pass

        from worker.tool_invoker import call_tool
        loop = asyncio.get_running_loop()
        
        for q in questions[:3]: # Limit to 3 queries
            try:
                self._publish_log(debate_id, f"ğŸ” å»¶ä¼¸èª¿æŸ¥ï¼š{q}")
                
                # Ask LLM to pick the best tool for this question
                selection_prompt = f"""
                ä»»å‹™ï¼šå›ç­”å»¶ä¼¸èª¿æŸ¥å•é¡Œã€Œ{q}ã€ã€‚
                
                è«‹å„ªå…ˆä½¿ç”¨ã€ä»˜è²»é«˜éšå·¥å…·ã€‘(Google Search, ChinaTimes) ä¾†ç²å–æœ€æº–ç¢ºçš„è³‡è¨Šã€‚
                TEJ ç‚ºè©¦ç”¨ç‰ˆå·¥å…·ï¼Œåƒ…åœ¨å…¶ä»–å·¥å…·ç„¡æ³•ç²å–æ•¸æ“šæ™‚ä½œç‚ºè¼”åŠ©ä½¿ç”¨ã€‚

                å·¥å…·é¸æ“‡æŒ‡å—ï¼š
                - **æŸ¥æ¬Šå¨æ–°è/è¼¿è«–** -> `chinatimes.news_search` (é¦–é¸), `google.search` (ä»˜è²»é«˜ç²¾æº–)
                - **æŸ¥åŸºæœ¬é¢/è²¡å‹™æ•¸æ“š** -> `chinatimes.stock_fundamental`, `chinatimes.financial_ratios` (é¦–é¸)
                - **æŸ¥å»£æ³›å¤–éƒ¨è³‡è¨Š** -> `google.search`
                - **è¼”åŠ©æ•¸æ“š (è‹¥ä¸Šè¿°çš†ç„¡)** -> `tej.company_info`, `tej.stock_price`
                """
                
                response = await call_llm_async(
                    selection_prompt,
                    system_prompt="ä½ æ˜¯é¦–å¸­ç ”ç©¶å“¡ï¼Œè«‹å„ªå…ˆä½¿ç”¨é«˜æˆæœ¬ä½†é«˜æº–ç¢ºåº¦çš„ä»˜è²»å·¥å…· (ChinaTimes, Google)ã€‚",
                    tools=research_tools,
                    context_tag=f"{debate_id}:Chairman:ResearchExec"
                )
                
                # Parse Tool Call
                tool_output = "No tool used."
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    try:
                        tool_call = json.loads(json_match.group(0))
                        if "tool" in tool_call and "params" in tool_call:
                            t_name = tool_call["tool"]
                            t_params = tool_call["params"]
                            
                            self._publish_log(debate_id, f"ğŸ› ï¸ èª¿ç”¨å·¥å…· ({t_name})...")
                            res = await loop.run_in_executor(None, call_tool, t_name, t_params)
                            tool_output = str(res)[:800] # Increase limit for rich data
                    except Exception as ex:
                        tool_output = f"Tool execution error: {ex}"
                else:
                    # Fallback to search if no tool selected (sometimes LLM just talks)
                    if "search" not in response.lower(): # Avoid re-searching if it was a search intent
                         res = await loop.run_in_executor(None, call_tool, "searxng.search", {"q": q})
                         tool_output = str(res)[:500]

                research_results.append(f"Q: {q}\nResult: {tool_output}")
                
            except Exception as e:
                print(f"Extended research failed for '{q}': {e}")
        
        self._publish_log(debate_id, f"âœ… å»¶ä¼¸èª¿æŸ¥å®Œæˆï¼Œå…±ç²å¾— {len(research_results)} é …ç™¼ç¾ã€‚")
        return "\n\n".join(research_results) if research_results else "å»¶ä¼¸èª¿æŸ¥æœªç²å¾—é¡å¤–è³‡è¨Šã€‚"

    async def _generate_eda_summary(self, topic: str, debate_id: str, handcard: str = "") -> str:
        """
        ç”Ÿæˆ EDA è‡ªå‹•åˆ†ææ‘˜è¦ï¼ˆé€šéå·¥å…·ç³»çµ±ï¼‰ã€‚
        
        æµç¨‹ï¼š
        1. å¾ topic/handcard æå–è‚¡ç¥¨ä»£ç¢¼
        2. èª¿ç”¨ chairman.eda_analysis å·¥å…·
        3. è¿”å›åˆ†ææ‘˜è¦
        
        Returns:
            EDA åˆ†ææ‘˜è¦æ–‡æœ¬
        """
        self._publish_log(debate_id, "ğŸ“Š ä¸»å¸­æ­£åœ¨é€²è¡Œ EDA è‡ªå‹•åˆ†æ...")
        
        try:
            # Step 1: æå–è‚¡ç¥¨ä»£ç¢¼
            stock_codes = self._extract_stock_codes_from_topic(topic, handcard)
            
            if not stock_codes:
                self._publish_log(debate_id, "âš ï¸ æœªèƒ½è­˜åˆ¥è‚¡ç¥¨ä»£ç¢¼ï¼Œè·³é EDA åˆ†æ")
                return "(æœªé€²è¡Œ EDA åˆ†æï¼šç„¡æ³•è­˜åˆ¥è‚¡ç¥¨ä»£ç¢¼)"
            
            # ä½¿ç”¨ç¬¬ä¸€å€‹è­˜åˆ¥åˆ°çš„ä»£ç¢¼
            symbol = stock_codes[0]
            self._publish_log(debate_id, f"ğŸ¯ è­˜åˆ¥åˆ°è‚¡ç¥¨ä»£ç¢¼: {symbol}")
            
            # Step 2: èª¿ç”¨ EDA å·¥å…·
            from worker.tool_invoker import call_tool
            
            params = {
                "symbol": symbol,
                "debate_id": debate_id,
                "lookback_days": 120
            }
            
            loop = asyncio.get_running_loop()
            result = await loop.run_in_executor(None, call_tool, "chairman.eda_analysis", params)
            
            # Step 3: è™•ç†çµæœ
            if result.get("success"):
                self._publish_log(debate_id, f"âœ… EDA åˆ†æå®Œæˆ")
                return result.get("summary", "(EDA åˆ†æå®Œæˆä½†ç„¡æ‘˜è¦)")
            else:
                error_msg = result.get("error", "Unknown error")
                self._publish_log(debate_id, f"âš ï¸ EDA åˆ†æå¤±æ•—: {error_msg}")
                return f"(EDA åˆ†æå¤±æ•—ï¼š{error_msg})"
            
        except Exception as e:
            self._publish_log(debate_id, f"âŒ EDA åˆ†æç•°å¸¸: {str(e)}")
            print(f"EDA generation error: {e}")
            import traceback
            traceback.print_exc()
            return "(EDA åˆ†æå¤±æ•—ï¼šç³»çµ±ç•°å¸¸)"
    
    def _extract_stock_codes_from_topic(self, topic: str, handcard: str = "") -> list:
        """å¾è¾¯è«–ä¸»é¡Œå’Œæ‰‹å¡ä¸­æå–è‚¡ç¥¨ä»£ç¢¼"""
        import re
        
        codes = []
        
        # å˜—è©¦å¾ topic æå–ï¼ˆæ ¼å¼ï¼š2330.TW, 8942, etc.ï¼‰
        pattern = r'\b(\d{4})(?:\.(?:TW|TWO))?\b'
        matches = re.findall(pattern, topic)
        codes.extend([f"{code}.TW" for code in matches])
        
        # å˜—è©¦å¾ handcard æå–
        if handcard:
            handcard_str = json.dumps(handcard, ensure_ascii=False) if isinstance(handcard, dict) else str(handcard)
            matches = re.findall(pattern, handcard_str)
            codes.extend([f"{code}.TW" for code in matches])
        
        # å»é‡
        return list(set(codes))

    async def summarize_debate(self, debate_id: str, topic: str, rounds_data: list, handcard: str = "") -> str:
        """
        å°æ•´å ´è¾¯è«–é€²è¡Œæœ€çµ‚ç¸½çµ (Async)ã€‚
        æ ¸å¿ƒé‚è¼¯ï¼š
        1. è³‡æ–™èšåˆï¼šæ­·å²ç´€éŒ„ + æ­£åæ–¹è«–é»
        2. æˆ°ç•¥å°é½Šï¼šæ³¨å…¥ Handcard æª¢æŸ¥æ˜¯å¦åé¡Œ
        3. è­‰æ“šå¯©æŸ¥ï¼šæ³¨å…¥ Verified EvidenceDoc
        4. EDA è‡ªå‹•åˆ†æï¼šç”Ÿæˆå¯¦è­‰æ•¸æ“šå ±è¡¨ (NEW)
        5. ç¶œåˆè©•åˆ¤ï¼šç”Ÿæˆçµæ§‹åŒ–å ±å‘Š
        6. å»¶ä¼¸å»ºè­°ï¼šç”Ÿæˆå¯åŸ·è¡Œè¡Œå‹•æŒ‡å—
        """
        print(f"Chairman '{self.name}' is making the final conclusion (Async).")
        
        # [NEW] Step 0: EDA è‡ªå‹•åˆ†æ
        eda_summary = await self._generate_eda_summary(topic, debate_id, handcard)
        
        # 1. Fetch Verified Evidence (SSOT)
        lc = EvidenceLifecycle(debate_id)
        verified_docs = lc.get_verified_evidence(limit=20) # Get top 20 verified facts
        
        evidence_summary = []
        for doc in verified_docs:
            # Format: [Tool: X] (Trust: 80) Content Summary
            content_str = json.dumps(doc.content, ensure_ascii=False)[:300]
            evidence_summary.append(f"- ã€å·²é©—è­‰è­‰æ“šã€‘(Tool: {doc.tool_name}): {content_str}")
        
        evidence_block = "\n".join(evidence_summary) if evidence_summary else "(æœ¬å ´è¾¯è«–ç„¡æœ‰æ•ˆé©—è­‰è­‰æ“š)"

        # 2. Build Debate Log
        summary_text = f"è¾¯é¡Œï¼š{topic}\n\n"
        for round_data in rounds_data:
            summary_text += f"--- ç¬¬ {round_data['round']} è¼ª ---\n"
            for key, value in round_data.items():
                if key == "round": continue
                summary_text += f"[{key}]: {str(value)[:500]}...\n" # Truncate for prompt context window
        
        # 3. Construct Structured Prompt for Verdict
        prompt = f"""
        è«‹æ’°å¯«æœ¬å ´è¾¯è«–çš„ã€æœ€çµ‚è£æ±ºå ±å‘Šã€‘ã€‚

        ### è¼¸å…¥è³‡æ–™
        1. **æˆ°ç•¥æ‰‹å¡ (Chairman's Handcard)**ï¼š
        {handcard if handcard else "(ç„¡æˆ°ç•¥æ‰‹å¡)"}

        2. **EDA å¯¦è­‰åˆ†æ (Automated Data Analysis)**ï¼š
           *é€™æ˜¯ç³»çµ±è‡ªå‹•ç”Ÿæˆçš„æ•¸æ“šåˆ†æå ±è¡¨ï¼ŒåŒ…å«é‡åŒ–æŒ‡æ¨™èˆ‡è¦–è¦ºåŒ–åœ–è¡¨ã€‚*
        {eda_summary}

        3. **æ ¸å¿ƒè­‰æ“šåº« (Verified Evidence)**ï¼š
           *é€™æ˜¯ç¶“éç³»çµ±æ ¸å¯¦çš„å–®ä¸€äº‹å¯¦ä¾†æº (SSOT)ï¼Œæ¬Šé‡æœ€é«˜ã€‚*
        {evidence_block}

        4. **è¾¯è«–éç¨‹æ‘˜è¦**ï¼š
        {summary_text}

        ### ä½ çš„ä»»å‹™
        è«‹æ‰®æ¼”å…¬æ­£ã€æ¬Šå¨çš„è¾¯è«–ä¸»å¸­ï¼Œç”Ÿæˆä¸€ä»½çµæ§‹æ¸…æ™°çš„ Markdown å ±å‘Šï¼ŒåŒ…å«ä»¥ä¸‹å››å€‹ç« ç¯€ï¼š

        ## 1. æˆ°ç•¥å°é½Šèˆ‡é›™æ–¹è§€é» (Strategic Alignment & Counterpoints)
        *   å›é¡§æˆ°ç•¥æ‰‹å¡ï¼šæ˜¯å¦èšç„¦æ ¸å¿ƒæˆ°å ´ï¼Ÿ
        *   **å¿…é ˆåŒ…å«åæ–¹è§€é»**ï¼šä¸èƒ½åƒ…å‘ˆç¾æ­£æ–¹ä¸»å¼µã€‚è«‹è£œå……è‡³å°‘ä¸€æ®µåæ–¹çš„æœ‰åŠ›è³ªç–‘ï¼ˆä¾‹å¦‚ï¼šæ–°å¢æˆåˆ†è‚¡çš„é¢¨éšªã€è‚¡æ¯ç¨€é‡‹æ•ˆæ‡‰ç­‰ï¼‰ï¼Œå®Œæ•´å‘ˆç¾äº¤é‹’ã€‚

        ## 2. è­‰æ“šæ•ˆåŠ›èˆ‡é‡åŒ–æŒ‡æ¨™ (Evidence & Quantification)
        *   **åå‘è­‰å½**ï¼šå€åˆ†å¼·è­‰æ“š (Tier 1/2) èˆ‡å¼±è­‰æ“š (Tier 3/4)ã€‚
        *   **é‡åŒ–é—œéµæŒ‡æ¨™**ï¼šé¿å…ç©ºæ³›å½¢å®¹ã€‚è«‹å¼•ç”¨è­‰æ“šä¸­çš„å…·é«”æ•¸å€¼ï¼Œä¾‹å¦‚ï¼š
            *   æ­·å¹´å¹³å‡è‚¡æ¯ç‡ (%)
            *   Beta å€¼ã€VaR æˆ–æ³¢å‹•ç‡ (%)
        *   **è³‡æ–™ä¾†æºå…·é«”åŒ–**ï¼šè‹¥å¼•ç”¨ã€Œå®˜æ–¹å…¬å‘Šã€æˆ–ã€Œè²¡å ±ã€ï¼Œ**å¿…é ˆ**çµ¦å‡ºå…·é«”ä¾†æºï¼ˆå¦‚ï¼šæ–‡ä»¶ç·¨è™Ÿã€å…·é«”æ—¥æœŸã€æˆ– Database IDï¼‰ï¼Œæ–¹ä¾¿é©—è­‰ã€‚

        ## 3. é‚è¼¯å°æ‡‰èˆ‡æ•æ„Ÿåº¦åˆ†æ (Logic & Sensitivity)
        *   **é æ¸¬é€æ˜åº¦**ï¼šé‡å°é—œéµé æ¸¬ï¼ˆå¦‚ç‡Ÿæ”¶æˆé•·ã€è‚¡åƒ¹ç›®æ¨™ï¼‰ï¼Œå¿…é ˆèªªæ˜**èƒŒå¾Œçš„å‡è¨­**èˆ‡**ä¾†æº**ã€‚
        *   **æ•æ„Ÿåº¦åˆ†æ (Sensitivity Analysis)**ï¼š
            *   è«‹æä¾›æƒ…å¢ƒæ¨¡æ“¬ï¼šã€Œè‹¥ [é—œéµè®Šæ•¸] è®Šå‹• X%ï¼Œå‰‡ [çµæœ] é æœŸè®Šå‹• Y%ã€ã€‚
            *   ç¯„ä¾‹ï¼šè‹¥åŠå°é«”åº«å­˜å»åŒ–å»¶å¾Œè‡³ Q3ï¼Œå‰‡é ä¼° EPS ä¸‹ä¿®è‡³ X å…ƒã€‚
        *   **é‚è¼¯æ”»é˜²**ï¼šè©•è¿°é›™æ–¹è«–é»çš„é‚è¼¯å°æ‡‰é—œä¿‚ï¼ˆChallenge & Responseï¼‰ï¼Œè€Œä¸åƒ…æ˜¯å„èªªå„è©±ã€‚

        ## 4. é¢¨éšªè©•ä¼°èˆ‡è­‰æ“šéˆæ¥ (Risk & Citations)
        *   **è­‰æ“šéˆæ¥ (Evidence Linking)**ï¼šæ¯å€‹é—œéµè«–é»å¾Œ**å¿…é ˆ**é™„ä¸Šè­‰æ“šä¾†æºç·¨è™Ÿæˆ–é€£çµï¼ˆä¾‹å¦‚ï¼š[Ref: TEJ-2023Q3] æˆ– [Ref: å®˜æ–¹å…¬å‘Š 2024-01-15]ï¼‰ã€‚
        *   **é¢¨éšªæŒ‡æ¨™çŸ©é™£**ï¼šè«‹ä»¥ Markdown è¡¨æ ¼å‘ˆç¾ï¼š
            | é¢¨éšªå› å­ | è§€æ¸¬æŒ‡æ¨™ (KPI) | è§¸ç™¼æ¢ä»¶ (Trigger) | è¡æ“Šç¨‹åº¦ (High/Med/Low) |
            | :--- | :--- | :--- | :--- |
            | ... | ... | ... | ... |

        ## 5. æœ€çµ‚è£æ±ºèˆ‡è¡Œå‹•å»ºè­° (Verdict & Action)
        *   **å‹è² å‚¾å‘**ï¼š(å¯é¸)
        *   **å…±è­˜äº‹å¯¦**ï¼šé›™æ–¹éƒ½èªåŒçš„å®¢è§€é»ã€‚

        è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œèªæ°£å°ˆæ¥­ä¸”å…·å»ºè¨­æ€§ã€‚
        """
        # Call LLM for Initial Verdict
        initial_verdict = await call_llm_async(prompt, system_prompt="ä½ æ˜¯è¾¯è«–ä¸»å¸­ï¼Œè«‹ä¾ç…§æŒ‡ç¤ºç”Ÿæˆçµæ§‹åŒ–çµæ¡ˆå ±å‘Šã€‚", context_tag=f"{debate_id}:Chairman:FinalVerdict")
        
        # 4. Extended Research for Actionable Advice
        extended_research_data = await self._conduct_extended_research(topic, initial_verdict, debate_id)
        
        # 5. Generate Final Actionable Advice
        db = SessionLocal()
        try:
             advice_template = PromptService.get_prompt(db, "chairman.generate_advice")
             if not advice_template:
                 # Fallback if prompt not loaded in DB yet
                 advice_template = """
                 è«‹åŸºæ–¼è¾¯è«–çµè«–ã€Œ{verdict}ã€èˆ‡å»¶ä¼¸èª¿æŸ¥ã€Œ{research_data}ã€ï¼Œç‚ºç”¨æˆ¶ç”Ÿæˆå…·é«”çš„ã€Œä¸‹ä¸€æ­¥è¡Œå‹•å»ºè­°ã€ã€‚
                 åŒ…å«ï¼šå…·é«”æ“ä½œæ­¥é©Ÿã€ç›£æ¸¬æŒ‡æ¨™ã€æºé€šå»ºè­°ã€‚
                 """
        finally:
             db.close()
             
        advice_prompt = advice_template.format(
            topic=topic,
            verdict=initial_verdict[-500:], # Pass context
            research_data=extended_research_data
        )
        
        actionable_advice = await call_llm_async(advice_prompt, system_prompt="ä½ æ˜¯å°ˆæ¥­æŠ•è³‡é¡§å•ã€‚", context_tag=f"{debate_id}:Chairman:FinalAdvice")
        
        # Combine
        final_conclusion = initial_verdict + "\n\n" + actionable_advice
        
        self._publish_log(debate_id, f"ğŸ¬ æœ€çµ‚è¾¯è«–ç¸½çµèˆ‡è¡Œå‹•å»ºè­°å®Œæˆã€‚")
        
        return final_conclusion