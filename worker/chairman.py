from agentscope.agent import AgentBase
from typing import Dict, Any
import json
import re
from worker.llm_utils import call_llm
from worker.tool_config import get_tools_description, get_recommended_tools_for_topic, STOCK_CODES, CURRENT_DATE
from api.prompt_service import PromptService
from api.database import SessionLocal
from api.redis_client import get_redis_client
from worker.llm_utils import call_llm_async
import asyncio
from worker.evidence_lifecycle import EvidenceLifecycle

# [Feature Flag: Facilitation]
try:
    from worker.chairman_facilitation import ChairmanFacilitationMixin
except ImportError:
    class ChairmanFacilitationMixin: pass

class Chairman(AgentBase, ChairmanFacilitationMixin):
    """
    ä¸»å¸­æ™ºèƒ½é«”ï¼Œè² è²¬ä¸»æŒè¾¯è«–ã€è³½å‰åˆ†æå’Œè³½å¾Œç¸½çµã€‚
    """

    def __init__(self, name: str, **kwargs: Any):
        super().__init__()
        self.name = name

    def speak(self, content: str):
        print(f"Chairman '{self.name}': {content}")

    def _publish_log(self, debate_id: str, content: str):
        """Helper to publish logs if debate_id is available."""
        if not debate_id:
            return
        
        try:
            redis_client = get_redis_client()
            from datetime import datetime
            timestamp = datetime.now().strftime("%H:%M:%S")
            ui_content = f"[{timestamp}] {content}"
            message = json.dumps({"role": f"Chairman ({self.name})", "content": ui_content}, ensure_ascii=False)
            redis_client.publish(f"debate:{debate_id}:log_stream", message)
            redis_client.rpush(f"debate:{debate_id}:log_history", message)
        except Exception as e:
            print(f"Chairman log publish error: {e}")

    async def _fallback_from_tej_price(self, params: Dict[str, Any], debate_id: str = None):
        from worker.tool_invoker import call_tool
        loop = asyncio.get_running_loop()

        symbol = params.get("coid") or params.get("symbol") or params.get("code")
        if not symbol:
            return None

        symbol_str = str(symbol)
        base_id = symbol_str.split(".")[0]

        twse_params = {"symbol": base_id, "date": CURRENT_DATE}

        try:
            self._publish_log(debate_id, f"ğŸ”„ TEJ è‚¡åƒ¹æŸ¥è©¢å¤±æ•—ï¼Œå˜—è©¦ TWSE æ—¥æ”¶ç›¤åƒ¹ï¼š{base_id} ({CURRENT_DATE})")
            res = await loop.run_in_executor(None, call_tool, "twse.stock_day", twse_params)
            if res and isinstance(res, dict):
                if res.get("error"):
                    raise ValueError(res.get("error"))
                rows = res.get("data") or res.get("results") or res.get("rows")
                if isinstance(rows, list) and len(rows) > 0:
                    return res
            raise ValueError("TWSE returned empty or invalid data")
        except Exception as e_twse:
            self._publish_log(debate_id, f"âš ï¸ TWSE å‚™æ´å¤±æ•—ï¼š{e_twse}ï¼Œæ”¹ç”¨ Verified Priceã€‚")
            try:
                fp_params = {"symbol": symbol_str}
                res = await loop.run_in_executor(None, call_tool, "financial.get_verified_price", fp_params)
                return res
            except Exception as e_v:
                self._publish_log(debate_id, f"âŒ Verified Price å‚™æ´äº¦å¤±æ•—ï¼š{e_v}")
                return None

    async def _classify_topic_type(self, topic: str, debate_id: str = None) -> str:
        """
        [New] Classify topic into 6 types to drive specialized investigation.
        Types: policy, value, fact, feasibility, causal, priority
        """
        self._publish_log(debate_id, "ğŸ§  æ­£åœ¨åˆ†æè­°é¡Œé¡å‹ä»¥å„ªåŒ–èª¿æŸ¥è·¯å¾‘...")
        
        prompt = f"""
        è«‹åˆ†æä»¥ä¸‹è¾¯è«–ä¸»é¡Œï¼Œå°‡å…¶æ­¸é¡ç‚ºä»¥ä¸‹ 6 ç¨®è­°é¡Œé¡å‹ä¹‹ä¸€ï¼š
        
        1. policy (æ”¿ç­–é¡)ï¼šæ¶‰åŠæ”¿åºœã€æ³•å¾‹ã€è¦å‰‡çš„åˆ¶å®šæˆ–è®Šæ›´ã€‚
        2. value (åƒ¹å€¼è§€/é“å¾·é¡)ï¼šæ¶‰åŠå€«ç†ã€é“å¾·ã€è‡ªç”±ã€æ¬ŠåŠ›ç­‰æŠ½è±¡æ¦‚å¿µçš„æ¯”è¼ƒã€‚
        3. fact (äº‹å¯¦èªå®šé¡)ï¼šæ¶‰åŠç§‘å­¸ã€æ­·å²ã€ç¤¾æœƒç¾ç‹€çš„å®¢è§€èªå®šã€‚
        4. feasibility (å¯è¡Œæ€§è©•ä¼°é¡)ï¼šæ¶‰åŠæŠ€è¡“ã€é ç®—ã€æ™‚é–“è¡¨æ˜¯å¦èƒ½é”æˆç›®æ¨™ã€‚
        5. causal (å› æœé—œä¿‚é¡)ï¼šæ¶‰åŠæŸè¡Œç‚ºæ˜¯å¦çœŸçš„å°è‡´äº†æŸç¨®çµæœã€‚
        6. priority (å„ªå…ˆé †åºé¡)ï¼šæ¶‰åŠè³‡æºåˆ†é…ã€å¤šå€‹ç›®æ¨™ä¹‹é–“çš„å–æ¨ã€‚
        
        è¾¯é¡Œï¼š{topic}
        
        è«‹ç›´æ¥è¼¸å‡ºé¡å‹åç¨±ï¼ˆè‹±æ–‡å°å¯«ï¼‰ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡‹æ–‡å­—ã€‚
        """
        try:
            response = await call_llm_async(prompt, system_prompt="ä½ æ˜¯è­°é¡Œåˆ†æå°ˆå®¶ã€‚", context_tag=f"{debate_id}:Chairman:TopicClassification")
            t_type = str(response).strip().lower()
            # Clean and match
            for valid in ["policy", "value", "fact", "feasibility", "causal", "priority"]:
                if valid in t_type: return valid
            return "fact" # Default
        except Exception:
            return "fact"

    async def _investigate_topic_async(self, topic: str, debate_id: str = None) -> str:
        """
        Async implementation of investigation loop.
        [Optimized] Specialized investigation based on Topic Type and expanded toolset.
        [CRITICAL FIX] Forced Internal Grounding to override external search hallucinations.
        """
        # 0. Topic Classification
        topic_type = await self._classify_topic_type(topic, debate_id)
        self._publish_log(debate_id, f"ğŸ“Œ è­°é¡Œé¡å‹è­˜åˆ¥ç‚ºï¼š{topic_type.upper()}")

        self._publish_log(debate_id, "ğŸ•µï¸ ä¸»å¸­æ­£åœ¨å•Ÿå‹•å°ˆé …èƒŒæ™¯èª¿æŸ¥...")
        
        # 1. Prepare Tools
        investigation_tools = []
        from api.config import Config
        target_tool_names = [
            "searxng.search", 
            "av.CPI", 
            "av.EXCHANGE_RATE", 
            "internal.get_industry_tree",
            "chinatimes.stock_fundamental"
        ]
        if Config.ENABLE_TEJ_TOOLS:
            target_tool_names += ["tej.company_info", "tej.stock_price", "tej.financial_summary"]
        
        from api.tool_registry import tool_registry
        
        for name in target_tool_names:
            try:
                tool_data = tool_registry.get_tool_data(name)
                investigation_tools.append({
                    "type": "function",
                    "function": {
                        "name": name,
                        "description": tool_data.get('description', ''),
                        "parameters": tool_data.get('schema', {"type": "object"})
                    }
                })
            except: pass

        # 1.5 [CRITICAL] Forced Internal Grounding (Business Description)
        # This part ensures we know EXACTLY what the company does from official DB
        official_profile = ""
        if hasattr(self, 'topic_decree') and self.topic_decree.get("is_verified"):
            code = self.topic_decree.get("code")
            self._publish_log(debate_id, f"ğŸ›¡ï¸ æ­£åœ¨å¼·åˆ¶ç²å– {code} çš„å®˜æ–¹ä¸»ç‡Ÿæ¥­å‹™æè¿°ä»¥é˜²æ­¢å¹»è¦º...")
            from worker.tool_invoker import call_tool
            loop = asyncio.get_running_loop()
            try:
                # Use ChinaTimes for descriptive name and industry
                res_ct = await loop.run_in_executor(None, call_tool, "chinatimes.stock_fundamental", {"code": code})
                if res_ct.get("data"):
                    d = res_ct["data"]
                    official_profile = f"ã€å®˜æ–¹ä¸»ç‡Ÿæ¥­å‹™å®šç¾©ã€‘: {d.get('Name')} (ä»£ç¢¼:{code}) æ‰€å±¬ç”¢æ¥­ï¼š{d.get('SectorName')}ã€‚ä¸»è¦ç¶“ç‡Ÿï¼šè³‡è¨Šç³»çµ±æ•´åˆã€è»Ÿç¡¬é«”éŠ·å”®èˆ‡æŠ€è¡“æœå‹™ã€‚"
                    if "æ•¦é™½" in d.get('Name', ''): # Specific fix for DunYang
                        official_profile = f"ã€å®˜æ–¹ä¸»ç‡Ÿæ¥­å‹™å®šç¾©ã€‘: æ•¦é™½ç§‘æŠ€ (2480.TW) æ˜¯å°ç£é ˜å…ˆçš„ã€Œè³‡è¨Šç³»çµ±æ•´åˆæœå‹™å•† (SI)ã€ï¼Œä¸»è¦ä»£ç†èˆ‡æ•´åˆå…¨çƒçŸ¥åè»Ÿç¡¬é«”ï¼Œæä¾›é¡§å•ã€å»ºç½®èˆ‡ç¶­è­·æœå‹™ã€‚çµ•éå…‰é›»ã€ç›¸æ©Ÿæˆ–æ™¶åœ“ä»£å·¥å» ã€‚"
            except: pass

        # 2. Dynamic Prompt based on Type
        type_requirements = {
            "policy": "å¿…éœ€èª¿æŸ¥ï¼šç¾æœ‰æ³•å¾‹æ”¿ç­–ã€å¯¦æ–½æˆæœ¬é ç®—ã€åŸ·è¡Œä¸Šçš„æŠ€è¡“æˆ–è¡Œæ”¿é›£åº¦ã€å—å½±éŸ¿å„æ–¹çš„ç«‹å ´ã€‚",
            "value": "å¿…éœ€èª¿æŸ¥ï¼šç›¸é—œçš„å€«ç†æ¡†æ¶ã€æ­·å²ç¶“å…¸æ¡ˆä¾‹ã€ä¸åŒæ–‡åŒ–èƒŒæ™¯ä¸‹çš„ç¤¾æœƒå…±è­˜ã€é¡ä¼¼çˆ­è­°çš„çœŸå¯¦åˆ¤ä¾‹ã€‚",
            "fact": "å¿…éœ€èª¿æŸ¥ï¼šå­¸è¡“ç ”ç©¶æ•¸æ“šã€ç§‘å­¸è­‰æ“šã€æ¥­ç•Œå°ˆå®¶å…±è­˜ã€å…·å‚™å…¬ä¿¡åŠ›çš„åæ–¹è§€é»æˆ–åä¾‹ã€‚",
            "feasibility": "å¿…éœ€èª¿æŸ¥ï¼šç•¶å‰æŠ€è¡“æˆç†Ÿåº¦ (TRL)ã€è³‡é‡‘éœ€æ±‚èˆ‡åˆ†é…ã€é è¨ˆæ™‚é–“è¡¨ã€æ ¸å¿ƒç‰©ç†æˆ–æŠ€è¡“éšœç¤™ã€‚",
            "causal": "å¿…éœ€èª¿æŸ¥ï¼šçµ±è¨ˆç›¸é—œæ€§æ•¸æ“šã€æ¡ˆä¾‹å°æ¯”åˆ†æã€æ˜¯å¦å­˜åœ¨éš±è—è®Šé‡ã€åå‘å› æœçš„å¯èƒ½æ€§ã€‚",
            "priority": "å¿…éœ€èª¿æŸ¥ï¼šå„æ–¹æ¡ˆçš„æ©Ÿæœƒæˆæœ¬ã€é‚Šéš›æ”¶ç›Šå°æ¯”ã€æ­·å²ä¸Šçš„æ¬Šè¡¡ç¶“é©—ã€è³‡æºç¼ºå£è©•ä¼°ã€‚"
        }

        # [Phase 27] Supply-Chain Aware Macro Guidance
        macro_guidance = """
        ã€ç”¢æ¥­éˆè¯å‹•èª¿æŸ¥æŒ‡å¼•ã€‘ï¼š
        1. é¦–å…ˆèª¿ç”¨ `internal.get_industry_tree` è­˜åˆ¥ä¸»é«”åœ¨ç”¢æ¥­éˆä¸­çš„è§’è‰²ã€‚
        2. è‹¥ä¸»é«”ç‚ºã€ä¸‹æ¸¸/ç³»çµ±æ•´åˆ(SI)ã€‘ï¼šé‡é»èª¿æŸ¥ã€åŒ¯ç‡ã€‘ï¼ˆé€²å£æˆæœ¬ï¼‰èˆ‡ã€åŒæ¥­ç«¶çˆ­æƒ…æ³ã€‘ã€‚
        3. è‹¥ä¸»é«”ç‚ºã€ä¸­æ¸¸/è£½é€ ã€‘ï¼šé‡é»èª¿æŸ¥ã€é€šè†¨/åŸææ–™åƒ¹æ ¼ã€‘èˆ‡ã€ç”¢èƒ½åˆ©ç”¨ç‡ã€‘ã€‚
        4. è‹¥ä¸»é«”ç‚ºã€ä¸Šæ¸¸/è¨­è¨ˆã€‘ï¼šé‡é»èª¿æŸ¥ã€ç ”ç™¼æŠ•å…¥ã€‘èˆ‡ã€çµ‚ç«¯å¸‚å ´éœ€æ±‚ã€‘ã€‚
        """

        prompt = f"""
è«‹å°è¾¯é¡Œã€Œ{topic}ã€é€²è¡Œå°ˆé …èª¿æŸ¥ã€‚
è­°é¡Œé¡å‹ï¼š{topic_type}
èª¿æŸ¥é‡é»ï¼š{type_requirements.get(topic_type, "")}

{macro_guidance}

{official_profile}

**æ ¸å¿ƒæŒ‡ä»¤**ï¼š
1. **åš´æ ¼å°æµ**ï¼šæœå°‹è©å¿…é ˆç²¾ç¢ºï¼Œåš´ç¦åœ¨æœå°‹è©ä¸­åŠ å…¥æœªç¶“é©—è­‰çš„è¡Œæ¥­æ¨æ¸¬ï¼ˆå¦‚ã€Œå…‰é›»ã€ã€ã€Œç›¸æ©Ÿã€ï¼‰ã€‚
2. **æ•¸æ“šèª å¯¦**ï¼šå¿…é ˆç²å–çœŸå¯¦æ•¸æ“šã€‚è‹¥æœå°‹çµæœèˆ‡ã€å®˜æ–¹ä¸»ç‡Ÿæ¥­å‹™å®šç¾©ã€‘è¡çªï¼Œ**ä»¥å®˜æ–¹å®šç¾©ç‚ºæº–**ï¼Œä¸¦æ¨™è¨˜æœå°‹çµæœç‚ºéŒ¯èª¤é›œè¨Šã€‚
3. **å®è§€èˆ‡ç”¢æ¥­**ï¼šè‹¥æ¶‰åŠç¶“æ¿Ÿï¼Œå¿…é ˆæŸ¥ CPI æˆ–åŒ¯ç‡ã€‚è‹¥æ¶‰åŠç”¢æ¥­ï¼Œå¿…é ˆæŸ¥ç”¢æ¥­éˆä½ç½® (get_industry_tree)ã€‚

èª¿æŸ¥çµæŸå¾Œï¼Œè«‹è¼¸å‡ºçµæ§‹åŒ–å ±å‘Šï¼ŒåŒ…å«ã€äº‹å¯¦æ¸…å–®ã€‘ã€ã€æ ¸å¿ƒæ•¸æ“šã€‘èˆ‡ã€æŸ¥æ ¸æ„è¦‹ã€‘ã€‚
"""
        # 3. Multi-turn Execution
        tool_results = []
        lc = EvidenceLifecycle(debate_id or "global")
        current_p = prompt
        
        for turn in range(3):
            self._publish_log(debate_id, f"ğŸ•µï¸ å°ˆé …èª¿æŸ¥åŸ·è¡Œä¸­ (Turn {turn+1}/3)...")
            response = await call_llm_async(current_p, system_prompt="ä½ æ˜¯è³‡æ·±èª¿æŸ¥å®˜ã€‚ä½ å¿…é ˆç„¡è¦–ä»»ä½•èˆ‡å®˜æ–¹å®šç¾©ä¸ç¬¦çš„è™›å‡ç¶²è·¯è³‡è¨Šã€‚", tools=investigation_tools, context_tag=f"{debate_id}:Investigate:{turn}")
            
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                try:
                    tool_call = json.loads(json_match.group(0))
                    if isinstance(tool_call, dict) and "tool" in tool_call:
                        t_name = tool_call["tool"]
                        t_params = tool_call["params"]
                        
                        # [Governance] Prevent broad/hallucinated search terms
                        if t_name == "searxng.search":
                            q = t_params.get("q", "")
                            # Remove problematic guessed keywords
                            for bad in ["å…‰é›»", "ç›¸æ©Ÿ", "æ™¶åœ“"]:
                                if bad in q and bad not in topic:
                                    t_params["q"] = q.replace(bad, "").strip()
                        
                        self._publish_log(debate_id, f"ğŸ› ï¸ åŸ·è¡Œå°ˆé …å·¥å…·ï¼š{t_name}")
                        
                        from worker.tool_invoker import call_tool
                        loop = asyncio.get_running_loop()
                        res = await loop.run_in_executor(None, call_tool, t_name, t_params)
                        
                        if res:
                            doc = lc.ingest(self.name, t_name, t_params, res)
                            doc = lc.verify(doc.id)
                            if doc.status == "VERIFIED":
                                tool_results.append(f"[{t_name}] (Verified): {json.dumps(res, ensure_ascii=False)}")
                                current_p += f"\nå·¥å…·çµæœï¼š{str(res)[:500]}\nè«‹ç¹¼çºŒèª¿æŸ¥ã€‚"
                                continue
                except: pass
            break

        if not tool_results:
            return f"æœªèƒ½ç²å–é¡å¤–æ•¸æ“šã€‚åƒ…æœ‰çš„äº‹å¯¦ï¼š{official_profile}"
            
        summary_prompt = f"è«‹å½™æ•´é—œæ–¼ã€Œ{topic}ã€çš„ bg_infoã€‚**çµ•å°è­¦å‘Š**ï¼šå¦‚æœèª¿æŸ¥çµæœä¸­åŒ…å«ä»»ä½•èˆ‡ä»¥ä¸‹å®˜æ–¹å®šç¾©è¡çªçš„è³‡è¨Šï¼ˆå¦‚ï¼šå…‰é›»ã€ç›¸æ©Ÿï¼‰ï¼Œå¿…é ˆå°‡å…¶å‰”é™¤ï¼\n\nå®˜æ–¹å®šç¾©ï¼š{official_profile}\n\nèª¿æŸ¥è­‰æ“šï¼š\n" + chr(10).join(tool_results)
        summary = await call_llm_async(summary_prompt, system_prompt="ä½ æ˜¯èª å¯¦çš„æ‘˜è¦å“¡ï¼Œè² è²¬å‰”é™¤ä»»ä½•èˆ‡å®˜æ–¹å®šç¾©ä¸ç¬¦çš„å¹»è¦ºè³‡è¨Šã€‚", context_tag=f"{debate_id}:InvestigateSummary")
        self._publish_log(debate_id, "âœ… èƒŒæ™¯èª¿æŸ¥ç¸½çµå·²æ ¹æ“šè­°é¡Œé¡å‹å®Œæˆå„ªåŒ–ã€‚")
        return summary

    async def _extract_entities_from_query(self, topic: str, debate_id: str = None) -> Dict[str, Any]:
        """
        [Step 1] Initial Entity Extraction from the Query text.
        Returns: {subject: str, code: Optional[str], industry_hint: Optional[str]}
        """
        self._publish_log(debate_id, "ğŸ” æ­£åœ¨å¾è¾¯é¡Œä¸­æŠ½å–æ ¸å¿ƒå¯¦é«” (Entity Extraction)...")
        
        prompt = f"""
        è«‹åˆ†æä»¥ä¸‹è¾¯è«–ä¸»é¡Œï¼Œä¸¦æŠ½å–å‡ºæ ¸å¿ƒè¨è«–çš„ã€Œå…¬å¸å¯¦é«”ã€è³‡è¨Šã€‚
        
        è¾¯é¡Œï¼š{topic}
        
        è«‹ä»¥ JSON æ ¼å¼å›å‚³ï¼š
        {{
            "subject": "å…¬å¸åç¨±ï¼ˆä¾‹å¦‚ï¼šå°ç©é›»ï¼‰",
            "code": "è‚¡ç¥¨ä»£ç¢¼ï¼ˆè‹¥æœ‰æåˆ°ï¼Œä¾‹å¦‚ï¼š2330ï¼‰ï¼Œæ²’æœ‰å‰‡å›å‚³ null",
            "industry_hint": "å¯èƒ½çš„ç”¢æ¥­é¡åˆ¥ï¼ˆä¾‹å¦‚ï¼šåŠå°é«”ï¼‰"
        }}
        """
        try:
            response = await call_llm_async(prompt, system_prompt="ä½ æ˜¯å°ˆæ¥­çš„è­‰åˆ¸åˆ†æåŠ©ç†ï¼Œæ“…é•·ç²¾ç¢ºè­˜åˆ¥å¯¦é«”ã€‚", context_tag=f"{debate_id}:Chairman:EntityExtraction")
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(0))
        except Exception as e:
            print(f"Entity extraction failed: {e}")
            
        return {"subject": topic, "code": None, "industry_hint": None}

    async def pre_debate_analysis(self, topic: str, debate_id: str = None) -> Dict[str, Any]:
        """
        åŸ·è¡Œè³½å‰åˆ†æçš„ 7 æ­¥ç®¡ç·š (Async)ã€‚
        [Optimized Flow]: Entity Extraction -> Internal Check -> [Background Investigation] -> 7-Step Analysis
        """
        print(f"Chairman '{self.name}' is starting pre-debate analysis for topic: '{topic}'")
        self._publish_log(debate_id, f"æ­£åœ¨é–‹å§‹è³½å‰åˆ†æï¼š{topic}...")

        # 1. ç¬¬ä¸€å±¤ï¼šLLM ç›´æ¥æŠ½å–å¯¦é«” (Entity Recognition)
        entities = await self._extract_entities_from_query(topic, debate_id)
        subject = entities.get("subject", topic)
        code = entities.get("code")
        
        # 2. ç¬¬äºŒå±¤ï¼šå…§éƒ¨æ ¡é©—èˆ‡é¡Œç›®é–å®š (Decree & Database Validation)
        self._publish_log(debate_id, f"âš–ï¸ æ­£åœ¨åŸ·è¡Œåˆæ­¥é¡Œç›®é–å®šé©—è­‰ (Decree Validation for '{subject}')...")
        
        initial_decree = {
            "subject": subject,
            "code": code or "Unknown",
            "industry": entities.get("industry_hint", "Unknown")
        }
        
        self.topic_decree = await self._validate_and_correction_decree(initial_decree, debate_id)
        
        # 3. ç¬¬ä¸‰å±¤ï¼šæŒ‰éœ€åŸ·è¡ŒèƒŒæ™¯èª¿æŸ¥ (Background Investigation based on Topic Type)
        bg_info = ""
        is_verified = self.topic_decree.get("is_verified", False)
        
        # å¼·åˆ¶å•Ÿå‹•èƒŒæ™¯èª¿æŸ¥ä»¥ç²å–å®è§€èˆ‡ç”¢æ¥­éˆæ•¸æ“š
        self._publish_log(debate_id, f"ğŸ”¬ å•Ÿå‹•è­°é¡Œé¡å‹å°å‘èª¿æŸ¥...")
        bg_info = await self._investigate_topic_async(topic, debate_id)

        # ç²å–æ¨è–¦å·¥å…·
        self._publish_log(debate_id, "ğŸ” æ­£åœ¨åˆ†æé¡Œç›®ä¸¦æª¢ç´¢æ¨è–¦å·¥å…·...")
        recommended_tools = get_recommended_tools_for_topic(topic)
        tools_desc = get_tools_description()
        
        # ğŸ§  æ§‹å»º 7 æ­¥åˆ†æ
        self._publish_log(debate_id, "ğŸ§  æ­£åœ¨æ§‹å»º 7 æ­¥åˆ†ææ€ç¶­éˆ (Chain of Thought)...")
        db = SessionLocal()
        try:
            template = PromptService.get_prompt(db, "chairman.pre_debate_analysis") or "åˆ†æè¾¯é¡Œï¼š{{topic}}"
            from datetime import datetime, timedelta
            now = datetime.strptime(CURRENT_DATE, "%Y-%m-%d")
            format_vars = {
                "tools_desc": "æœ¬éšæ®µè«‹å‹¿ä½¿ç”¨å·¥å…·ï¼Œè«‹åŸºæ–¼æä¾›çš„èƒŒæ™¯è³‡è¨Šé€²è¡Œç´”é‚è¼¯åˆ†æã€‚",
                "background_info": bg_info,
                "CURRENT_DATE": CURRENT_DATE,
                "stock_codes": chr(10).join([f"- {name}: {code}" for name, code in STOCK_CODES.items()]),
                "recommended_tools": ', '.join(recommended_tools)
            }
            system_prompt = template
            for key, value in format_vars.items():
                system_prompt = system_prompt.replace(f"{{{{{key}}}}}", str(value))
        finally:
            db.close()
            
        base_prompt = f"åˆ†æè¾¯é¡Œï¼š{topic}\n\nã€èƒŒæ™¯äº‹å¯¦ã€‘:\n{bg_info}\n\nã€é¡Œç›®é–å®šã€‘:\n{json.dumps(self.topic_decree, ensure_ascii=False)}"
        self._publish_log(debate_id, "ğŸš€ æ­£åœ¨èª¿ç”¨ LLM é€²è¡Œæ·±åº¦æˆ°ç•¥åˆ†æ...")
        
        current_prompt = base_prompt
        analysis_result = {}
        
        for attempt in range(3):
            response = await call_llm_async(current_prompt, system_prompt=system_prompt, context_tag=f"{debate_id}:Chairman:PreAnalysis")
            try:
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    parsed_json = json.loads(json_match.group(0), strict=False)
                    if "tool" in parsed_json: continue # Handle accidental tool calls
                    analysis_result = parsed_json
                    break
            except: pass

        if "step6_handcard" in analysis_result:
            analysis_result["step5_summary"] = analysis_result["step6_handcard"]
        
        analysis_result["step00_decree"] = self.topic_decree
        
        # [Analysis Verification]
        try:
            # 1. Internal Integrity Check
            analysis_result = await self._verify_analysis_integrity(analysis_result, bg_info, debate_id)
            
            # 2. External Guardrail Audit
            from worker.guardrail_agent import GuardrailAgent
            guardrail = GuardrailAgent()
            self._publish_log(debate_id, "ğŸ›¡ï¸ æ­£åœ¨åŸ·è¡Œä¸­ç«‹å¯©æŸ¥å“¡æ·±åº¦ç¨½æ ¸...")
            audit = guardrail.check("Chairman", json.dumps(analysis_result.get("step5_summary", "")), f"Facts: {bg_info}")
            
            if audit.get("status") == "REJECTED":
                self._publish_log(debate_id, f"â›” å¯©æŸ¥å“¡é§å›åˆ†æï¼š{audit.get('reason')}")
                correction_prompt = f"è«‹æ ¹æ“šä»¥ä¸‹äº‹å¯¦é‡æ–°ç”¢å‡ºã€ç„¡å¹»è¦ºã€‘çš„æ‘˜è¦ï¼š\n{bg_info}"
                analysis_result["step5_summary"] = await call_llm_async(correction_prompt, system_prompt="ä½ æ˜¯èª å¯¦åˆ†æå¸«ã€‚")
        except: pass

        print(f"Pre-debate analysis completed.")
        return {
            "analysis": analysis_result,
            "bg_info": bg_info
        }

    async def _verify_analysis_integrity(self, analysis: Dict[str, Any], bg_info: str, debate_id: str = None) -> Dict[str, Any]:
        """
        Verify the integrity of the pre-debate analysis result (Handcard).
        """
        self._publish_log(debate_id, "ğŸ›¡ï¸ æ­£åœ¨åŸ·è¡Œä¸»å¸­åˆ†æé©—è­‰...")
        handcard = analysis.get("step6_handcard") or analysis.get("step5_summary")
        if not handcard: return analysis
        handcard_str = str(handcard)
        
        prompt = f"æª¢æŸ¥ä»¥ä¸‹åˆ†æå ±å‘Šæ˜¯å¦åŒ…å«æé€ æ•¸æ“šï¼š\nå ±å‘Šï¼š{handcard_str}\näº‹å¯¦èƒŒæ™¯ï¼š{bg_info}\nè¦æ±‚ï¼šèƒŒæ™¯æ²’æåˆ°çš„ç™¾åˆ†æ¯”æˆ–æ•¸æ“šå¿…é ˆåˆªé™¤ã€‚è‹¥æœ‰èª¤è«‹å›å‚³ä¿®æ­£å¾Œçš„ JSONï¼Œå¦å‰‡å›å‚³ PASSEDã€‚"
        check_result = await call_llm_async(prompt, system_prompt="ä½ æ˜¯åš´æ ¼çš„äº‹å¯¦æŸ¥æ ¸å“¡ã€‚", context_tag=f"{debate_id}:AnalysisCheck")
        
        if "PASSED" not in check_result:
            try:
                json_match = re.search(r'\{.*\}', check_result, re.DOTALL)
                if json_match:
                    corrected = json.loads(json_match.group(0))
                    analysis["step5_summary"] = corrected
                    analysis["step6_handcard"] = corrected
                    self._publish_log(debate_id, "âœ… å·²è‡ªå‹•ä¿®æ­£è™›æ§‹æ•¸æ“šã€‚")
            except: pass
        return analysis

    async def _validate_and_correction_decree(self, decree: Dict[str, Any], debate_id: str = None) -> Dict[str, Any]:
        """
        Validate and correct the decree (Subject & Code) using tools.
        """
        self._publish_log(debate_id, "âš–ï¸ ä¸»å¸­æ­£åœ¨é©—è­‰é¡Œç›®é–å®š (Decree Validation)...")
        subject = decree.get("subject", "Unknown")
        code = decree.get("code", "Unknown")
        final_decree = decree.copy()
        
        def is_valid(val):
            return val and val not in ["Unknown", "None", "", "null", "Unknown (Unknown)"]

        # Strategy 0: STOCK_CODES
        for known_name, known_code in STOCK_CODES.items():
            if known_name in str(subject):
                final_decree["subject"] = known_name
                final_decree["code"] = known_code if "." in str(known_code) else f"{known_code}.TW"
                final_decree["is_verified"] = True
                self._publish_log(debate_id, f"âœ… (Memory) è­˜åˆ¥åˆ°å¸¸ç”¨è‚¡ç¥¨ï¼š{known_name} -> {final_decree['code']}")
                return final_decree

        from worker.tool_invoker import call_tool
        loop = asyncio.get_running_loop()
        verified = False
        if is_valid(code):
            try:
                res_ct = await loop.run_in_executor(None, call_tool, "chinatimes.stock_fundamental", {"code": code})
                if res_ct.get("data"):
                    final_decree["subject"] = res_ct["data"].get("Name", subject)
                    final_decree["industry"] = res_ct["data"].get("SectorName", "Unknown")
                    self._publish_log(debate_id, f"âœ… (ChinaTimes) é©—è­‰ï¼š{final_decree['subject']} ({final_decree['industry']})")
                    verified = True
            except: pass

        if not verified and is_valid(subject):
            try:
                q = f"{subject} å°ç£è‚¡ç¥¨ ä»£è™Ÿ site:twse.com.tw"
                search_res = await loop.run_in_executor(None, call_tool, "searxng.search", {"q": q, "num_results": 3})
                prompt = f"å¾æœå°‹çµæœä¸­æå–ã€Œ{subject}ã€çš„ 4 ä½å°è‚¡ä»£ç¢¼ï¼š\n{str(search_res)[:1000]}"
                extracted_code = await call_llm_async(prompt, system_prompt="ä½ æ˜¯ä»£ç¢¼åŠ©æ‰‹ã€‚")
                extracted_code = re.search(r'\b\d{4}\b', extracted_code)
                if extracted_code:
                    final_decree["code"] = f"{extracted_code.group(0)}.TW"
                    verified = True
            except: pass

        final_decree["is_verified"] = verified
        return final_decree

    def summarize_round(self, debate_id: str, round_num: int, handcard: str = ""):
        """å°æœ¬è¼ªè¾¯è«–é€²è¡Œç¸½çµ"""
        redis_client = get_redis_client()
        try:
            evidence_list = [json.loads(item) for item in redis_client.lrange(f"debate:{debate_id}:evidence", 0, -1)]
        except: evidence_list = []
        evidence_text = "\n".join([f"- {e.get('role')}: {str(e.get('content'))[:200]}" for e in evidence_list])
        summary = call_llm(f"ç¸½çµæœ¬è¼ªè­‰æ“šï¼š\n{evidence_text}", system_prompt="ä½ æ˜¯è¾¯è«–ä¸»å¸­ã€‚")
        final_summary = f"ã€ç¬¬ {round_num} è¼ªç¸½çµã€‘\n" + summary
        self.speak(final_summary)
        return final_summary

    async def _conduct_extended_research(self, topic: str, verdict: str, debate_id: str = None) -> str:
        """åŸ·è¡Œå»¶ä¼¸èª¿æŸ¥"""
        self._publish_log(debate_id, "ğŸ”¬ ä¸»å¸­æ­£åœ¨é€²è¡Œå»¶ä¼¸èª¿æŸ¥...")
        from api.tool_registry import tool_registry
        target_tools = []
        for name in ["av.CPI", "av.EXCHANGE_RATE", "searxng.search"]:
            try:
                t_data = tool_registry.get_tool_data(name)
                target_tools.append({"type": "function", "function": {"name": name, "description": t_data['description'], "parameters": t_data['schema']}})
            except: pass
        res = await call_llm_async(f"æ ¹æ“šçµè«– '{verdict[:200]}' ç‚ºæŠ•è³‡è€…æœé›† 3 å€‹å»¶ä¼¸æ•¸æ“šã€‚", system_prompt="ä½ æ˜¯ç ”ç©¶å“¡ã€‚", tools=target_tools)
        return res

    async def summarize_debate(self, debate_id: str, topic: str, rounds_data: list, handcard: str = "") -> str:
        """æ•´å ´è¾¯è«–æœ€çµ‚ç¸½çµ"""
        self._publish_log(debate_id, "ğŸ¬ æ­£åœ¨ç”Ÿæˆæœ€çµ‚çµæ¡ˆå ±å‘Š...")
        verdict = await call_llm_async(f"è¾¯é¡Œï¼š{topic}\néç¨‹ï¼š{str(rounds_data)[:2000]}", system_prompt="ä½ æ˜¯è¾¯è«–ä¸»å¸­ã€‚è«‹ç”Ÿæˆ Markdown çµæ¡ˆå ±å‘Šã€‚")
        return verdict
