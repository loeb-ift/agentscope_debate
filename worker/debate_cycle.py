from typing import List, Dict, Any
from worker.chairman import Chairman
from worker.guardrail_agent import GuardrailAgent
from agentscope.agent import AgentBase
import json
import re
import os
import sys
import yaml
import asyncio
import resource
import difflib
from datetime import datetime, timezone, timedelta
from worker.llm_utils import call_llm, call_llm_async
from worker.tool_config import get_tools_description, get_tools_examples, STOCK_CODES, CURRENT_DATE
from api.prompt_service import PromptService
from api.database import SessionLocal
import hashlib
from worker.memory import ReMePersonalLongTermMemory, ReMeTaskLongTermMemory, ReMeToolLongTermMemory, ReMeHistoryMemory, HippocampalMemory
from api.tool_registry import tool_registry
from api.toolset_service import ToolSetService
from api.redis_client import get_redis_client
from api import models
from mars.types.errors import ToolError, ToolRecoverableError, ToolTerminalError, ToolFatalError, TejErrorType

class DebateCycle:
    """
    ç®¡ç†æ•´ä¸ªè¾©è®ºå¾ªç¯ï¼ŒåŒ…æ‹¬ä¸»å¸­å¼•å¯¼ã€æ­£åæ–¹å‘è¨€å’Œæ€»ç»“ã€‚
    """

    def __init__(self, debate_id: str, topic: str, chairman: Chairman, teams: List[Dict], rounds: int, enable_cross_examination: bool = True):
        self.debate_id = debate_id
        self.topic = topic
        self.chairman = chairman
        self.teams = teams # List of dicts: [{"name": "...", "side": "...", "agents": [AgentBase...]}]
        self.rounds = rounds
        self.enable_cross_examination = enable_cross_examination
        self.redis_client = get_redis_client()
        self.evidence_key = f"debate:{self.debate_id}:evidence"
        self.rounds_data = []
        self.analysis_result = {}
        self.history = []
        self.full_history = []  # å®Œæ•´æ­·å²è¨˜éŒ„ï¼ˆä¸å£“ç¸®ï¼Œç”¨æ–¼å ±å‘Šï¼‰
        self.compressed_history = "ç„¡"  # å­˜å„² LLM å£“ç¸®å¾Œçš„æ­·å²æ‘˜è¦ (Legacy)
        self.archived_summaries = [] # List of structured summaries
        self.agent_tools_map = {} # å­˜å„²æ¯å€‹ Agent é¸æ“‡çš„å·¥å…·åˆ—è¡¨
        self.hippocampus = HippocampalMemory(debate_id) # Init Hippocampal Memory
        self.discovered_urls = set() # [Governance] Track URLs found in search results
        self.browse_quota = 0 # [Governance] "Search once, browse once" logic
        self.latest_db_date = None # [Phase 18] Date Awareness Handshake
        
        # [Optimization] Persistent LTM instances for buffering
        self.history_memory = ReMeHistoryMemory(debate_id)
        self.tool_memory = ReMeToolLongTermMemory()
        
        # [Robustness] Failure Mode Memory
        # Key: f"{agent_name}:{tool_name}:{error_type}" -> Value: {count, last_params_hash}
        self._failure_memory: Dict[str, Dict[str, Any]] = {}
        
        # [Observability] Loop Sentinel
        self._loop_sentinel: Dict[str, int] = {} # Key: signature -> count
        
        # Log de-duplication cache: key -> {"last_ts": datetime, "suppressed": int}
        self._log_dedupe: Dict[str, Dict[str, Any]] = {}
        
        # [Debug] Setup debug log directory
        self.debug_log_enabled = os.getenv("DEBUG_LOG_ENABLE", "false").lower() == "true"
        if self.debug_log_enabled:
            self.debug_log_dir = "debate_logs"
            os.makedirs(self.debug_log_dir, exist_ok=True)
            
            # Generate timestamp for filenames
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # [Realtime] Stream log file
            self.stream_log_path = os.path.join(self.debug_log_dir, f"stream_{self.debate_id}_{ts}.log")
            self._log_to_file(f"=== Debate Stream Started: {self.debate_id} at {ts} ===")
            
            # [Debug] Round log filename
            self._debug_filename = f"debate_debug_{self.debate_id}_{ts}.txt"
        
        # [Debug] Full Execution Trace
        self.debug_trace: List[Dict[str, Any]] = []
        
        # [Observability Phase 6] Tool Stats
        self.tool_stats = {
            "count": 0,
            "total_time": 0.0,
            "estimated_cost": 0.0
        }
        
        # [Governance] Guardrail Agent
        self.guardrail_agent = GuardrailAgent()

    def _log_to_file(self, message: str):
        """Append message to the realtime stream log."""
        if not self.debug_log_enabled or not hasattr(self, 'stream_log_path'):
            return
        try:
            with open(self.stream_log_path, "a", encoding="utf-8") as f:
                timestamp = datetime.now().strftime("%H:%M:%S")
                f.write(f"[{timestamp}] {message}\n")
        except Exception as e:
            print(f"Failed to write to stream log: {e}")

    def _get_memory_usage(self) -> str:
        """ç²å–ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨é‡ (MB)"""
        try:
            usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
            # MacOS: bytes, Linux: KB
            if sys.platform == 'darwin':
                return f"{usage / 1024 / 1024:.2f} MB"
            return f"{usage / 1024:.2f} MB"
        except Exception:
            return "N/A"

    def _publish_log(self, role: str, content: str):
        """
        ç™¼å¸ƒæ—¥èªŒåˆ° Redisï¼Œä¾›å‰ç«¯ SSE è¨‚é–±ã€‚
        å…·å‚™å»é‡èˆ‡ç¯€æµï¼š
        - åŒä¸€ role+content åœ¨ 1 ç§’å…§é‡è¤‡ï¼Œå°‡è¢«æŠ‘åˆ¶ä¸¦ç´¯è¨ˆ suppressed è¨ˆæ•¸ã€‚
        - ä¸‹ä¸€æ¬¡å…è¨±çš„è¼¸å‡ºæœƒé™„å¸¶ "(previous N duplicates suppressed)" è¨»è¨˜ã€‚
        """
        # Ensure timestamp is Asia/Taipei (GMT+8)
        tz_taipei = timezone(timedelta(hours=8))
        now = datetime.now(timezone.utc).astimezone(tz_taipei)
        timestamp = now.strftime("%H:%M:%S")

        # De-duplication key
        key = f"{role}|{content}"
        entry = self._log_dedupe.get(key)
        allow_publish = True
        suppressed_note = ""
        dedupe_window_seconds = 1.0

        if entry:
            last_ts = entry.get("last_ts")
            suppressed = entry.get("suppressed", 0)
            # If within the dedupe window, suppress
            if last_ts and (now - last_ts).total_seconds() < dedupe_window_seconds:
                entry["suppressed"] = suppressed + 1
                entry["last_ts"] = now
                self._log_dedupe[key] = entry
                allow_publish = False
            else:
                # Outside the window: if there were suppressed duplicates, annotate once
                if suppressed:
                    suppressed_note = f" (previous {suppressed} duplicates suppressed)"
                # Reset counter and publish
                entry["suppressed"] = 0
                entry["last_ts"] = now
                self._log_dedupe[key] = entry
        else:
            # First time seeing this message
            self._log_dedupe[key] = {"last_ts": now, "suppressed": 0}

        if not allow_publish:
            return
        
        # Add timestamp to console log
        print(f"[{timestamp}] {role}: {content[:100]}...{suppressed_note}")
        
        # [Realtime] Log to file
        self._log_to_file(f"[{role}] {content}{suppressed_note}")
        
        # Add timestamp to UI content
        ui_content = f"[{timestamp}] {content}{suppressed_note}"
        
        message = json.dumps({"role": role, "content": ui_content}, ensure_ascii=False)
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", message)
        # Persist log for late-joiners
        self.redis_client.rpush(f"debate:{self.debate_id}:log_history", message)

    def _publish_progress(self, percentage: int, message: str, stage: str = "setup"):
        """
        ç™¼å¸ƒé€²åº¦æ›´æ–°äº‹ä»¶ï¼Œä¾›å‰ç«¯é¡¯ç¤ºé€²åº¦æ¢ã€‚
        """
        event_data = {
            "type": "progress_update",
            "progress": percentage,
            "message": message,
            "stage": stage,
            "timestamp": datetime.now().isoformat()
        }
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", json.dumps(event_data, ensure_ascii=False))

    def _save_round_debug_log(self, round_num: int, team_summaries: Dict[str, str]):
        """
        Save detailed debug log for the current round (Appended to single file).
        """
        if not self.debug_log_enabled:
            return

        try:
            # Use single file for the whole debate
            # Filename initialized in __init__
            filename = getattr(self, '_debug_filename', f"debate_debug_{self.debate_id}.txt")
            filepath = os.path.join(self.debug_log_dir, filename)
            
            with open(filepath, "a", encoding="utf-8") as f:
                f.write(f"\n{'='*60}\n")
                f.write(f"=== ç¬¬ {round_num} è¼ªé™¤éŒ¯æ—¥èªŒ (Round {round_num} Debug Log) ===\n")
                f.write(f"{'='*60}\n")
                f.write(f"Debate ID: {self.debate_id}\n")
                f.write(f"Topic: {self.topic}\n")
                f.write(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("--- å„åœ˜éšŠç¸½çµ (Team Summaries) ---\n")
                for team, summary in team_summaries.items():
                    f.write(f"[{team}]:\n{summary}\n\n")
                
                f.write("\n--- è¿‘æœŸå°è©±æ­·å² (Detailed History - Recent) ---\n")
                for item in self.history[-50:]: # Last 50 items
                    f.write(f"[{item.get('role')}]: {str(item.get('content'))[:500]}...\n")
                
                f.write("\n--- å®Œæ•´åŸ·è¡Œè¿½è¹¤ï¼šLLM è¼¸å…¥è¼¸å‡ºèˆ‡å·¥å…·çµæœ (Full Execution Trace) ---\n")
                
                for i, trace in enumerate(self.debug_trace):
                    f.write(f"\n[Trace #{i+1}] {trace.get('timestamp')}\n")
                    f.write(f"Agent: {trace.get('agent')}\n")
                    f.write(f"Step: {trace.get('step')}\n")
                    f.write(f"Event: {trace.get('event')}\n")
                    
                    if "prompt" in trace:
                        f.write(f"Full Prompt:\n{trace['prompt']}\n")
                    if "response" in trace:
                        f.write(f"LLM Response: {trace['response']}\n")
                    if "tool" in trace:
                        f.write(f"Tool Call: {trace['tool']} params={trace.get('params')}\n")
                    if "result" in trace:
                        # Full Result
                        try:
                            res_str = json.dumps(trace['result'], ensure_ascii=False, indent=2, default=str)
                        except:
                            res_str = str(trace['result'])
                        f.write(f"Tool Result: {res_str}\n")
                    f.write("-" * 40 + "\n")

                f.write("\n--- å‰ç«¯èˆ‡ç³»çµ±æ—¥èªŒä¸²æµ (Frontend & System Logs) ---\n")
                try:
                    # Fetch all logs from Redis
                    redis_logs = self.redis_client.lrange(f"debate:{self.debate_id}:log_history", 0, -1)
                    for log_json in redis_logs:
                        try:
                            entry = json.loads(log_json)
                            f.write(f"[{entry.get('role')}]: {entry.get('content')}\n")
                        except:
                            f.write(f"[Raw]: {log_json}\n")
                except Exception as e:
                    f.write(f"[Error fetching system logs]: {e}\n")

            print(f"[Debug] Round {round_num} log saved to {filepath}")
        except Exception as e:
            print(f"[Debug] Failed to save debug log: {e}")

    def _run_jury_evaluation(self, final_conclusion: str) -> str:
        """
        Run jury evaluation on the final conclusion.
        """
        self._publish_log("System", "âš–ï¸ æ­£åœ¨é€²è¡Œè©•å¯©åœ˜è©•ä¼° (Jury Evaluation)...")
        self._publish_progress(95, "è©•å¯©åœ˜æ­£åœ¨è©•åˆ†...", "jury")
        
        db = SessionLocal()
        try:
            # Simple Jury Prompt
            template = PromptService.get_prompt(db, "debate.jury_system")
            if not template: template = "ä½ æ˜¯å…¬æ­£çš„è¾¯è«–è©•å¯©åœ˜ã€‚è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡é€²è¡Œè©•ä¼°ã€‚"
            system_prompt = template

            user_template = PromptService.get_prompt(db, "debate.jury_user")
            if not user_template:
                user_template = """
è«‹é‡å°ä»¥ä¸‹è¾¯è«–çµè«–é€²è¡Œè©•ä¼°ï¼š

è¾¯é¡Œï¼š{topic}
æœ€çµ‚çµè«–ï¼š
{conclusion}

è«‹çµ¦å‡ºè©•åˆ† (0-100) èˆ‡å…·é«”è©•èªã€‚è©•èªå¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚
"""
            user_prompt = user_template.format(conclusion=final_conclusion, topic=self.topic)
        finally:
            db.close()
            
        try:
            jury_report = call_llm(user_prompt, system_prompt=system_prompt)
            self._publish_log("Jury", f"è©•å¯©åœ˜å ±å‘Šå‡ºçˆï¼š\n{jury_report}")
            return jury_report
        except Exception as e:
            print(f"Jury evaluation failed: {e}")
            return f"Jury evaluation failed: {str(e)}"

    def _save_report_to_file(self, conclusion: str, jury_report: str = None, investment_report: str = None, start_time: datetime = None, end_time: datetime = None):
        """
        å°‡è¾¯è«–éç¨‹ä¿å­˜ç‚º Markdown æ–‡ä»¶ã€‚
        """
        import re
        from datetime import datetime, timedelta, timezone
        
        report_dir = "data/replays"
        os.makedirs(report_dir, exist_ok=True)
        
        # æ¸…ç†é¡Œç›®ï¼Œç§»é™¤éæ³•æ–‡ä»¶åå­—ç¬¦
        safe_topic = re.sub(r'[<>:"/\\|?*]', '', self.topic)
        safe_topic = safe_topic.replace(' ', '_')[:50]  # é™åˆ¶é•·åº¦
        
        # ç”Ÿæˆæ™‚é–“æˆ³ï¼ˆå¯è®€æ ¼å¼ï¼Œå¼·åˆ¶ GMT+8ï¼‰
        tz_taipei = timezone(timedelta(hours=8))
        now = datetime.now(timezone.utc).astimezone(tz_taipei)
        timestamp = now.strftime("%Y%m%d_%H%M%S")
        
        # çµ„åˆæª”åï¼šé¡Œç›®_æ™‚é–“.md
        filename = f"{safe_topic}_{timestamp}.md"
        filepath = os.path.join(report_dir, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"# è¾¯è«–å ±å‘Šï¼š{self.topic}\n\n")
            f.write(f"**ID**: {self.debate_id}\n")
            f.write(f"**Date**: {now.strftime('%Y-%m-%d %H:%M:%S')} (GMT+8)\n\n")
            
            f.write("## ğŸ† æœ€çµ‚çµè«–\n\n")
            f.write(f"{conclusion}\n\n")

            if jury_report:
                f.write("## âš–ï¸ è©•å¯©åœ˜è©•ä¼°å ±å‘Š\n\n")
                f.write(f"{jury_report}\n\n")
            
            if investment_report:
                f.write("---\n\n")
                f.write("# ğŸ“‘ æ·±åº¦æŠ•è³‡ç ”ç©¶å ±å‘Š (Investment Report)\n\n")
                f.write(f"{investment_report}\n\n")
                f.write("---\n\n")

            f.write("## ğŸ“ è¾¯è«–éç¨‹è¨˜éŒ„\n\n")
            for item in self.full_history:
                role = item.get("role", "Unknown")
                content = item.get("content", "")
                f.write(f"### {role}\n")
                f.write(f"{content}\n\n")
                f.write("---\n\n")
            
            # Duration Stats
            if start_time and end_time:
                duration = end_time - start_time
                f.write("## â±ï¸ çµ±è¨ˆè³‡è¨Š\n")
                f.write(f"- **é–‹å§‹æ™‚é–“**: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- **çµæŸæ™‚é–“**: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- **ç¸½è€—æ™‚**: {str(duration).split('.')[0]}\n")
                
        print(f"Report saved to {filepath}")

    def start(self) -> Dict[str, Any]:
        """
        å¼€å§‹è¾©è®ºå¾ªç¯ (Sync wrapper around async start).
        """
        return asyncio.run(self.start_async())

    async def start_async(self) -> Dict[str, Any]:
        """
        å¼€å§‹è¾©è®ºå¾ªç¯ (Async).
        """
        start_time = datetime.now()
        print(f"Debate '{self.debate_id}' has started. Mem: {self._get_memory_usage()}")
        self._publish_log("System", f"Debate '{self.debate_id}' has started.")
        self._publish_progress(5, "åˆå§‹åŒ–è¾¯è«–ç’°å¢ƒ...", "init")
        
        # 0.5 [Phase 18] Database Handshake (Date Awareness)
        self._publish_progress(8, "æ­£åœ¨æª¢æ¸¬è³‡æ–™åº«æœ€æ–°æ—¥æœŸ...", "init")
        await self._check_db_date_async()

        # 0. è³½å‰åˆ†æ

        # Check Task LTM for similar past debates
        # [OPTIONAL] Disabled to avoid cold-start issues if not required
        # task_mem = ReMeTaskLongTermMemory()
        # similar_tasks = await task_mem.retrieve_similar_tasks_async(self.topic)
        # if similar_tasks:
        #     print(f"DEBUG: Found similar past debates:\n{similar_tasks}")
        #     self._publish_log("System", f"Found similar past debates:\n{similar_tasks}")

        self._publish_progress(10, "ä¸»å¸­æ­£åœ¨é€²è¡Œè³½å‰åˆ†æ...", "analysis")
        
        # Chairman analysis is now fully async
        self.analysis_result = await self.chairman.pre_debate_analysis(self.topic, debate_id=self.debate_id)
        
        # [Topic Locking] Store Decree in Hippocampus
        decree = self.analysis_result.get("step00_decree", {})
        if decree:
            # Store as a "Core Memory" (High importance, no decay)
            # We treat it as a special tool result from "Chairman"
            await self.hippocampus.store(
                agent_id="Chairman",
                tool="system.decree",
                params={"topic": self.topic},
                result=decree
            )
            # Also store in local state for injection
            self.topic_decree = decree
            self._publish_log("System", f"ğŸ”’ é¡Œç›®é–å®š (Decree Issued): {decree.get('subject')} ({decree.get('code')})")

        summary = self.analysis_result.get('step5_summary', 'ç„¡')
        self.chairman.speak(f"è³½å‰åˆ†æå®Œæˆã€‚æˆ°ç•¥æ‘˜è¦ï¼š{summary}")
        self._publish_log("Chairman (Analysis)", f"è³½å‰åˆ†æå®Œæˆã€‚\næˆ°ç•¥æ‘˜è¦ï¼š{summary}")

        # [New] Neutral Fact-Check (Double Validation)
        # åˆ©ç”¨ä¸­ç«‹åœ˜éšŠé€²è¡Œç¬¬äºŒé“äº‹å¯¦æ ¸æŸ¥ï¼Œç¢ºä¿ Chairman çš„ Decree (é¡Œç›®é–å®š) ç„¡èª¤
        await self._conduct_neutral_fact_check(decree)
        
        self._publish_progress(30, "åˆ†æå®Œæˆï¼Œæº–å‚™ Agent å·¥å…·...", "tool_selection")
        
        # 1. Agent å‹•æ…‹é¸æ“‡å·¥å…· (Initialization Phase)
        print("Agents are selecting their tools...")
        self._publish_log("System", "ğŸ¯ è¾¯è«–æº–å‚™éšæ®µï¼šå„ Agent æ­£åœ¨é¸æ“‡æœ€é©åˆçš„å·¥å…·...")
        
        total_agents = sum(len(team['agents']) for team in self.teams)
        if total_agents == 0:
            total_agents = 1 # Avoid division by zero
        
        # Run tool selection sequentially
        self._publish_log("System", f"ğŸš€ å•Ÿå‹• {total_agents} å€‹ Agent é †åºå·¥å…·é¸æ“‡...")
        
        agent_processed_count = 0
        for team in self.teams:
            side = team.get('side', 'neutral')
            for agent in team['agents']:
                 await self._agent_select_tools_async(agent, side)
                 agent_processed_count += 1
                 # Calculate progress from 30% to 90%
                 progress = 30 + int((agent_processed_count / total_agents) * 60)
                 self._publish_progress(progress, f"Agent {agent.name} å·¥å…·é…ç½®å®Œæˆ ({agent_processed_count}/{total_agents})", "tool_selection")

        self._publish_log("System", "âœ… æ‰€æœ‰ Agent å·¥å…·é¸æ“‡å®Œæˆã€‚")
        self._publish_progress(100, "æº–å‚™å°±ç·’ï¼Œè¾¯è«–é–‹å§‹ï¼", "start")

        
        for i in range(1, self.rounds + 1):
            print(f"--- Round {i} --- (Mem: {self._get_memory_usage()})")
            self._publish_log("System", f"--- Round {i} ---")
            round_result = await self._run_round_async(i)
            self.rounds_data.append(round_result)
            
            # [Phase 18] Chairman Emergency Mode (After Round 1)
            if i == 1:
                await self._check_and_trigger_emergency_mode(round_result)
        
        # 4. æœ€çµ‚ç¸½çµ
        handcard = self.analysis_result.get('step6_handcard') or self.analysis_result.get('step5_summary', 'ç„¡æ‰‹å¡')
        final_conclusion = await self.chairman.summarize_debate(self.debate_id, self.topic, self.rounds_data, handcard)
        self._publish_log("Chairman (Conclusion)", final_conclusion)

        # 5. Jury è©•ä¼°
        jury_report = self._run_jury_evaluation(final_conclusion)

        # 6. ç”Ÿæˆæ­£å¼æŠ•è³‡å ±å‘Š (Report Editor)
        investment_report = await self._generate_investment_report(self.rounds_data, final_conclusion)

        # Record outcome to Task LTM
        # [OPTIONAL] Disabled as debates are independent and history is not required
        # task_mem = ReMeTaskLongTermMemory()
        # await task_mem.record_async(self.topic, final_conclusion)
        
        end_time = datetime.now()
        # Save to File (Markdown Report)
        self._save_report_to_file(final_conclusion, jury_report, investment_report, start_time, end_time)

        print(f"Debate '{self.debate_id}' has ended.")
        self._publish_log("System", f"Debate '{self.debate_id}' has ended.")
        
        # [CLEANUP] Clear Semantic Cache for this debate
        try:
            from api.vector_store import VectorStore
            await VectorStore.delete_by_filter(
                collection_name="llm_semantic_cache",
                filter_conditions={"context": self.debate_id}
            )
            print(f"DEBUG: Cleared semantic cache for debate {self.debate_id}")
        except Exception as e:
            print(f"WARNING: Failed to clear semantic cache: {e}")

        # [Duration Stats]
        total_duration = datetime.now() - start_time
        duration_msg = f"ğŸ è¾¯è«–çµæŸã€‚ç¸½è€—æ™‚: {str(total_duration).split('.')[0]}"
        
        # [Phase 6] Cache Stats & Metrics
        cache_stats = self.hippocampus.stats
        total_reqs = cache_stats['wm_hits'] + cache_stats['wm_misses']
        hit_rate = (cache_stats['wm_hits'] / total_reqs * 100) if total_reqs > 0 else 0
        
        # Semantic Cache Stats
        from worker.llm_utils import _semantic_cache_buffer
        sem_hits = _semantic_cache_buffer.stats["hits"]
        sem_misses = _semantic_cache_buffer.stats["misses"]
        sem_total = sem_hits + sem_misses
        sem_hit_rate = (sem_hits / sem_total * 100) if sem_total > 0 else 0
        
        # [Cost Stats] Retrieve from Redis
        try:
            usage = self.redis_client.hgetall(f"debate:{self.debate_id}:usage")
            total_tokens = int(usage.get("total_tokens", 0))
            search_count = int(usage.get("search_count", 0))
            # Redis cost only tracks LLM cost via CostService
            llm_cost = float(usage.get("total_cost", 0.0))
            
            # Combine tool cost
            total_cost = llm_cost + self.tool_stats['estimated_cost']
        except:
            total_tokens = 0
            search_count = 0
            total_cost = self.tool_stats['estimated_cost'] # Fallback to tool cost only

        avg_latency = (self.tool_stats["total_time"] / self.tool_stats["count"]) if self.tool_stats["count"] > 0 else 0
        
        stats_msg = f"ğŸ“Š Cache Stats: WM Hit {hit_rate:.1f}% | Sem Hit {sem_hit_rate:.1f}% | Saved Calls: {cache_stats['wm_hits'] + sem_hits}"
        perf_msg = f"âš¡ Perf: Avg Tool Latency {avg_latency:.2f}s | LLM: {total_tokens} toks | Search: {search_count} calls | Total: ${total_cost:.4f}"
        
        detailed_stats = {
            "hippocampus_hit_rate": hit_rate,
            "semantic_cache_hit_rate": sem_hit_rate,
            "api_calls_saved": cache_stats['wm_hits'] + sem_hits,
            "tool_api_cost": self.tool_stats["estimated_cost"],
            "search_count": search_count,
            "total_cost": total_cost,
            "total_llm_tokens": total_tokens,
            "qdrant_writes": cache_stats['ltm_writes'],
            "avg_tool_latency": avg_latency
        }
        
        print(f"[{datetime.now().strftime('%H:%M:%S')}] {duration_msg}")
        print(f"DEBUG: FINAL METRICS: {json.dumps(detailed_stats, indent=2)}")
        
        self._publish_log("System", duration_msg)
        self._publish_log("System", stats_msg)
        self._publish_log("System", perf_msg)

        # Send explicit DONE signal to close the stream
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", "[DONE]")
        
        return {
            "topic": self.topic,
            "rounds_data": self.rounds_data,
            "analysis": self.analysis_result,
            "final_conclusion": final_conclusion,
            "jury_report": jury_report,
            "investment_report": investment_report
        }

    async def _generate_investment_report(self, rounds_data: List[Dict], final_conclusion: str) -> str:
        """
        èª¿ç”¨ Report Editor Agent ç”Ÿæˆçµæ§‹åŒ–æŠ•è³‡å ±å‘Š
        """
        self._publish_log("System", "ğŸ“‘ æ­£åœ¨ç”Ÿæˆæ·±åº¦æŠ•è³‡ç ”ç©¶å ±å‘Š (Report Generation)...")
        self._publish_progress(98, "æ­£åœ¨æ’°å¯«æŠ•è³‡å ±å‘Š...", "report")
        
        # 1. Prepare Context
        # Flatten history for context
        full_context = ""
        for r in rounds_data:
            round_log = r.get('log', [])
            for entry in round_log:
                full_context += f"[{entry['role']}]: {entry['content']}\n\n"
        
        full_context += f"[Chairman Conclusion]: {final_conclusion}\n"
        
        # 2. Setup Agent
        # Create a temporary ReportEditor agent instance
        
        # Define a simple agent class compatible with AgentBase
        class ReportAgent(AgentBase):
            def __init__(self, name: str, role: str, system_prompt: str):
                super().__init__(name=name, sys_prompt=system_prompt) # Try passing standard args if supported, or just init
                self.name = name
                self.role = role
                self.system_prompt = system_prompt
        
        # Load system prompt
        db = SessionLocal()
        try:
            report_agent_model = db.query(models.Agent).filter(models.Agent.role == "report_editor").first()
            
            if not report_agent_model:
                print("Warning: Report Editor agent not found in DB, using ad-hoc.")
                sys_prompt = "ä½ æ˜¯å°ˆæ¥­æŠ•è³‡å ±å‘Šä¸»ç­†..."
                # Fallback instantiation
                try:
                    agent = ReportAgent(name="Report Editor", role="report_editor", system_prompt=sys_prompt)
                except TypeError:
                    # Fallback for AgentBase without args
                    class SimpleAgent:
                        def __init__(self, name, role, system_prompt):
                            self.name = name
                            self.role = role
                            self.system_prompt = system_prompt
                    agent = SimpleAgent(name="Report Editor", role="report_editor", system_prompt=sys_prompt)
            else:
                # Use robust instantiation
                try:
                    agent = ReportAgent(
                        name=report_agent_model.name,
                        role=report_agent_model.role,
                        system_prompt=report_agent_model.system_prompt
                    )
                except TypeError:
                     # If AgentBase init fails, use Simple Mock
                    class SimpleAgent:
                        def __init__(self, name, role, system_prompt):
                            self.name = name
                            self.role = role
                            self.system_prompt = system_prompt
                    agent = SimpleAgent(
                        name=report_agent_model.name,
                        role=report_agent_model.role,
                        system_prompt=report_agent_model.system_prompt
                    )
                
        finally:
            db.close()
            
        # 3. Equip Tools
        # Force equip Strategic ToolSet or Report tools
        # We can reuse _agent_select_tools_async logic, but better to force equip specific report tools to ensure coverage
        report_tools = [
            # Basic
            "tej.company_info", "tej.financial_summary", "tej.stock_price",
            "chinatimes.stock_fundamental", "internal.get_industry_tree", "searxng.search",
            # Financial Statements (Detailed)
            "chinatimes.balance_sheet", "chinatimes.income_statement",
            "chinatimes.cash_flow", "chinatimes.financial_ratios"
        ]
        self.agent_tools_map[agent.name] = report_tools
        
        # 4. Execute
        # We reuse _agent_turn_async to leverage the tool-use loop!
        # But _agent_turn_async constructs its own prompt. We need to override or inject the instruction.
        # _agent_turn_async uses `debater.tool_instruction`.
        # We can trick it by setting a special side? No.
        # We will manually run the loop logic here simplified, or modify _agent_turn_async to accept custom prompt.
        
        # Easier: Just use _agent_turn_async but with a "special" round number or side that triggers different prompt logic?
        # OR: Duplicate the loop logic here for specialized reporting.
        # Let's Duplicate simplified loop for safety and customization.
        
        system_prompt = agent.system_prompt
        user_prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹è¾¯è«–è¨˜éŒ„ï¼Œæ’°å¯«ä¸€ä»½å®Œæ•´çš„æŠ•è³‡ç ”ç©¶å ±å‘Šã€‚
å ±å‘Šå¿…é ˆåŒ…å«ï¼šæŠ•è³‡è©•ç­‰ã€é‡é»æ‘˜è¦ã€åŸºæœ¬è³‡æ–™ã€ç‡Ÿé‹æ¦‚æ³ã€ç”¢æ¥­åˆ†æã€è²¡å‹™åˆ†æã€ä¼°å€¼åˆ†æã€é¢¨éšªåˆ†æã€æŠ•è³‡å»ºè­°ã€‚
è«‹å‹™å¿…ä½¿ç”¨å·¥å…·è£œå……è¾¯è«–ä¸­ç¼ºå¤±çš„æ•¸æ“šï¼ˆå¦‚ç‡Ÿæ”¶ä½”æ¯”ã€æœ€æ–°è‚¡åƒ¹ã€PE Bandï¼‰ã€‚
è¼¸å‡ºæ ¼å¼å¿…é ˆåŒ…å« [CHART_DATA] JSON å€å¡Šã€‚

è¾¯è«–è¨˜éŒ„ï¼š
{full_context}
"""
        
        # === Report Generation Loop (Simplified) ===
        max_steps = 5
        current_step = 0
        current_prompt = user_prompt
        
        final_report = ""
        
        # Equip tools for Ollama
        ollama_tools = []
        for name in report_tools:
            try:
                t_data = tool_registry.get_tool_data(name)
                # Fix: description might be a dict (metadata) or a string
                desc = t_data.get('description', '')
                if isinstance(desc, dict):
                    desc = desc.get('description', '')

                ollama_tools.append({
                    "type": "function",
                    "function": {
                        "name": name,
                        "description": desc,
                        "parameters": t_data.get('schema', {})
                    }
                })
            except:
                pass

        while current_step < max_steps:
            current_step += 1
            self._publish_log("Report Editor", f"æ­£åœ¨æ’°å¯«å ±å‘Š (Step {current_step})...")
            
            response = await call_llm_async(
                current_prompt,
                system_prompt=system_prompt,
                context_tag=f"{self.debate_id}:ReportEditor",
                tools=ollama_tools
            )
            
            # Check tool call
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            is_tool = False
            if json_match:
                try:
                    tool_call = json.loads(json_match.group(0))
                    if "tool" in tool_call and "params" in tool_call:
                        is_tool = True
                        t_name = tool_call["tool"]
                        t_params = tool_call["params"]
                        
                        self._publish_log("Report Editor", f"èª¿ç”¨å·¥å…·è£œå……æ•¸æ“š: {t_name}")
                        
                        # Execute
                        from worker.tool_invoker import call_tool
                        loop = asyncio.get_running_loop()
                        res = await loop.run_in_executor(None, call_tool, t_name, t_params)
                        
                        # Update prompt
                        current_prompt = f"å·¥å…· {t_name} çµæœï¼š\n{json.dumps(res, ensure_ascii=False, indent=2)}\n\nè«‹ç¹¼çºŒæ’°å¯«å ±å‘Šã€‚"
                        continue
                except:
                    pass
            
            if not is_tool:
                # Final result
                final_report = response
                break
        
        self._publish_log("Report Editor", "å ±å‘Šæ’°å¯«å®Œæˆã€‚")
        return final_report

    async def _conduct_neutral_fact_check(self, decree: Dict[str, Any]):
        """
        è®“ä¸­ç«‹åœ˜éšŠ (Neutral Team) é©—è­‰ Chairman çš„é¡Œç›®é–å®š (Decree) æ˜¯å¦ç¬¦åˆäº‹å¯¦ã€‚
        è‹¥ç™¼ç¾é‡å¤§å‡ºå…¥ï¼ˆå¦‚ç”¢æ¥­éŒ¯èª¤ï¼‰ï¼Œå˜—è©¦ä¿®æ­£ã€‚
        """
        neutral_team = next((t for t in self.teams if t.get('side') == 'neutral'), None)
        if not neutral_team or not decree:
            return

        self._publish_log("System", "âš–ï¸ å•Ÿå‹•ä¸­ç«‹åœ˜éšŠäº‹å¯¦æ ¸æŸ¥ (Neutral Fact-Check)...")
        agent = neutral_team['agents'][0] # Pick the first neutral agent
        
        # 1. Equip Tools (Ad-hoc)
        # Neutral needs search & basic tools
        tools = ["searxng.search", "tej.company_info", "chinatimes.stock_fundamental"]
        # Assuming we can use these tools directly via call_tool wrapper or just LLM knowledge if strong enough?
        # Better to use tools. We can reuse _agent_turn_async logic but with a specific prompt.
        
        # We need to temporarily set tools for this agent if not set
        if agent.name not in self.agent_tools_map:
            self.agent_tools_map[agent.name] = tools

        # 2. Prompt
        check_prompt = f"""
ã€ç³»çµ±ä»»å‹™ï¼šäº‹å¯¦æ ¸æŸ¥ã€‘
ä¸»å¸­å°è¾¯é¡Œé€²è¡Œäº†ä»¥ä¸‹é–å®š (Decree)ï¼š
- ä¸»é«”: {decree.get('subject')}
- ä»£ç¢¼: {decree.get('code')}
- ç”¢æ¥­: {decree.get('industry')}

è«‹ä½ ä½¿ç”¨å·¥å…·é©—è­‰ä¸Šè¿°è³‡è¨Šæ˜¯å¦æ­£ç¢ºã€‚
ç‰¹åˆ¥æª¢æŸ¥ã€Œç”¢æ¥­ã€æ˜¯å¦ç¬¦åˆè©²å…¬å¸çš„å¯¦éš›æ¥­å‹™ã€‚
ä¾‹å¦‚ï¼šæ£®é‰… (8942) æ˜¯é‡‘å±¬/å»ºæï¼Œè‹¥ä¸»å¸­èªªæ˜¯é›»å­ï¼Œè«‹æŒ‡å‡ºéŒ¯èª¤ã€‚

è¼¸å‡ºæ ¼å¼ï¼š
è‹¥æ­£ç¢ºï¼Œè¼¸å‡º "PASS"ã€‚
è‹¥éŒ¯èª¤ï¼Œè«‹è¼¸å‡º "FAIL: [ä¿®æ­£å¾Œçš„ç”¢æ¥­/ä»£ç¢¼]"ã€‚
"""
        # 3. Execute
        # Reuse _agent_turn_async but we need to inject this prompt.
        # Since _agent_turn_async uses a fixed prompt template, we might need a specialized method or trick it.
        # Let's use call_llm_async directly with tools manually to keep it isolated.
        
        from worker.tool_invoker import call_tool
        
        # Construct tool definitions for LLM
        ollama_tools = []
        for t_name in tools:
            try:
                t_data = tool_registry.get_tool_data(t_name)
                # Fix: description might be a dict (metadata) or a string
                desc = t_data.get('description', '')
                if isinstance(desc, dict):
                    desc = desc.get('description', '')

                ollama_tools.append({
                    "type": "function",
                    "function": {
                        "name": t_name,
                        "description": desc,
                        "parameters": t_data.get('schema', {})
                    }
                })
            except: pass

        # Simple Loop (1 turn)
        sys_p = "ä½ æ˜¯å…¬æ­£çš„äº‹å¯¦æŸ¥æ ¸å“¡ã€‚"
        response = await call_llm_async(check_prompt, system_prompt=sys_p, tools=ollama_tools, context_tag=f"{self.debate_id}:NeutralCheck")
        
        # Handle Tool Call if any
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            try:
                tool_call = json.loads(json_match.group(0))
                if "tool" in tool_call:
                    t_name = tool_call["tool"]
                    t_params = tool_call["params"]
                    self._publish_log(f"{agent.name} (Fact-Check)", f"èª¿ç”¨å·¥å…·é©—è­‰: {t_name}")
                    
                    loop = asyncio.get_running_loop()
                    res = await loop.run_in_executor(None, call_tool, t_name, t_params)
                    
                    # Second pass with tool result
                    response = await call_llm_async(
                        f"å·¥å…·çµæœï¼š{json.dumps(res, ensure_ascii=False)[:500]}\nè«‹çµ¦å‡ºæœ€çµ‚åˆ¤æ–· (PASS/FAIL)ã€‚",
                        system_prompt=sys_p,
                        context_tag=f"{self.debate_id}:NeutralCheck:Res"
                    )
            except: pass

        if "FAIL" in response:
            self._publish_log("System", f"âš ï¸ ä¸­ç«‹æ ¸æŸ¥ç™¼ç¾æ½›åœ¨éŒ¯èª¤ï¼š{response}")
            # [Auto-Correction] If Neutral provides a correction, apply it?
            # Parsing "FAIL: [Correct]" is hard.
            # For now, just Log Warning.
            # Or append to history so everyone knows.
            self.history.append({"role": "System (Fact-Check Warning)", "content": f"ä¸­ç«‹åœ˜éšŠå°é¡Œç›®é–å®šæå‡ºç•°è­°ï¼š{response}ã€‚è«‹å„æ–¹è¾¯æ‰‹æ³¨æ„æ ¸å¯¦ã€‚"})
        else:
            self._publish_log("System", "âœ… ä¸­ç«‹äº‹å¯¦æ ¸æŸ¥é€šéã€‚")

    async def _check_db_date_async(self):
        """
        [Phase 18] Handshake with DB to find the latest available date.
        Uses TSMC (2330.TW) as a canary to probe database freshness.
        """
        try:
            from worker.tool_invoker import call_tool
            loop = asyncio.get_running_loop()
            
            # [Optimization] Direct latest date probe
            # Instead of guessing date ranges, ask for the single latest record
            params = {
                "coid": "2330.TW",
                "opts.limit": 1,
                "sort": "mdate.desc"
            }
            
            self._publish_log("System", f"ğŸ” æ­£åœ¨æª¢æ¸¬è³‡æ–™åº«æœ€æ–°æ—¥æœŸ (Probe: 2330.TW)...")
            
            # Add timeout protection
            result = await asyncio.wait_for(
                loop.run_in_executor(None, call_tool, "tej.stock_price", params),
                timeout=10.0
            )
            
            found_date = None
            if isinstance(result, dict):
                 data = result.get("data") or result.get("results")
                 if isinstance(data, list) and data:
                     row = data[0]
                     d = row.get("mdate")
                     if d:
                         found_date = str(d).split("T")[0]

            if found_date:
                self.latest_db_date = found_date
                self._publish_log("System", f"ğŸ“… è³‡æ–™åº«æœ€æ–°æ•¸æ“šæ—¥æœŸç¢ºèª: {self.latest_db_date}")
            else:
                self._publish_log("System", f"âš ï¸ ç„¡æ³•ç¢ºèªè³‡æ–™åº«æ—¥æœŸ (å…©æ¬¡æ¢æ¸¬çš†å¤±æ•—)ã€‚")
                # Fallback: Don't set a fake date, just leave as None.
                self.latest_db_date = None

        except Exception as e:
            print(f"DB Handshake Failed: {e}")
            self._publish_log("System", f"âš ï¸ è³‡æ–™åº«é€£ç·šæª¢æŸ¥å¤±æ•—: {e}")

    async def _run_round_async(self, round_num: int) -> Dict[str, Any]:
        """
        Run a single debate round (Async).
        """
        round_log = []
        team_summaries = {}
        
        for team in self.teams:
             team_result = await self._process_team_deliberation(team, round_num)
             
             # Append to global history
             self.history.extend(team_result['log'])
             self.full_history.extend(team_result['log'])
             
             round_log.extend(team_result['log'])
             team_summaries[team['name']] = team_result['summary']
             
        # Save round debug log
        self._save_round_debug_log(round_num, team_summaries)
        
        return {
            "round": round_num,
            "team_summaries": team_summaries,
            "log": round_log
        }

    async def _neutral_verification_turn_async(self, agent: AgentBase, team_name: str, round_num: int) -> str:
        """
        Neutral agent verification turn.
        """
        return await self._agent_turn_async(agent, "neutral", round_num)

    async def _check_and_trigger_emergency_mode(self, round_result: Dict):
        """
        Check if agents are failing to get data and trigger emergency web search.
        """
        # Heuristic: If summaries contain keywords like "no data", "empty", "lack of evidence"
        team_summaries = round_result.get("team_summaries", {})
        combined_text = " ".join(team_summaries.values()).lower()
        
        failure_signals = ["no data", "empty", "lack of evidence", "æŸ¥ç„¡è³‡æ–™", "æ•¸æ“šä¸è¶³", "ç„¡æ³•é©—è­‰"]
        score = sum(1 for s in failure_signals if s in combined_text)
        
        if score >= 2: # Threshold
            self._publish_log("Chairman (Emergency)", "ğŸš¨ åµæ¸¬åˆ°å¤šæ–¹æ•¸æ“šä¸è¶³ã€‚ä¸»å¸­å•Ÿå‹•ã€Œç·Šæ€¥ç ”ç©¶æ¨¡å¼ (Emergency Research Mode)ã€ï¼")
            self._publish_log("System", "ğŸ”“ å¼·åˆ¶è§£é– Web Search å·¥å…·çµ¦æ‰€æœ‰ Agent...")
            
            # Force enable search tools for everyone
            for agent_name in self.agent_tools_map:
                if "searxng.search" not in self.agent_tools_map[agent_name]:
                    self.agent_tools_map[agent_name].append("searxng.search")
                    
            # Inject a system note into history
            msg = "ã€ä¸»å¸­æŒ‡ä»¤ã€‘é‘‘æ–¼å…§éƒ¨æ•¸æ“šåº«è³‡æ–™ä¸è¶³ï¼Œç¾å·²é–‹æ”¾ç¶²çµ¡æœç´¢æ¬Šé™ã€‚è«‹å–„ç”¨ `searxng.search` æŸ¥æ‰¾å¤–éƒ¨æ–°èèˆ‡å ±å‘Šä¾†è£œå……è«–é»ã€‚"
            self.history.append({"role": "Chairman (System)", "content": msg})
            self.full_history.append({"role": "Chairman (System)", "content": msg})

    async def _process_team_deliberation(self, team: Dict, round_num: int) -> Dict[str, Any]:
        """
        Process a single team's deliberation asynchronously.
        """
        team_name = team['name']
        team_side = team.get('side', 'neutral')
        team_agents = team['agents']
        total_agents_in_team = len(team_agents)
        
        team_icon = "ğŸŸ¦" if team_side == "pro" else "ğŸŸ¥" if team_side == "con" else "ğŸŸ©"
        self._publish_log("System", f"{team_icon} ã€{team_name}ã€‘é–‹å§‹å…§éƒ¨è¨è«–...")
        
        team_discussion_log_text = [] # For summary generation
        team_history_entries = [] # For returning to main thread
        
        # Within a team, agents might still need to speak in order, OR parallel?
        # Usually debate implies responding to each other.
        # However, "Intra-Team Debate" in this simplified version is just each agent speaking once.
        # We can make agents within a team parallel too!
        
        agent_results = []
        for agent in team_agents:
            if team_side == "neutral":
                 content = await self._neutral_verification_turn_async(agent, team_name, round_num)
            else:
                 content = await self._agent_turn_async(agent, team_name, round_num)
            agent_results.append(content)
        
        for idx, (agent, content) in enumerate(zip(team_agents, agent_results)):
             role_label = f"{team_name} - {agent.name}"
             
             entry = {"role": role_label, "content": content}
             team_history_entries.append(entry)
             team_discussion_log_text.append(f"{agent.name}: {content}")
             
             # Publish individual log (Note: Might arrive out of order visually if not carefully handled on frontend,
             # but here we publish as soon as done)
             self._publish_log(role_label, content)

        # ç”Ÿæˆåœ˜éšŠå…±è­˜èˆ‡åˆ†æ­§ç¸½çµ
        self._publish_log("System", f"ğŸ“Š {team_name} æ­£åœ¨æ•´ç†åœ˜éšŠå…±è­˜...")
        team_summary = await self._generate_team_summary_async(team_name, team_discussion_log_text)
        self._publish_log(f"{team_name} (Summary)", team_summary)
        
        return {
            "name": team_name,
            "summary": team_summary,
            "log": team_history_entries
        }

    def _generate_team_summary(self, team_name: str, discussion_log: List[str]) -> str:
         return asyncio.run(self._generate_team_summary_async(team_name, discussion_log))

    async def _generate_team_summary_async(self, team_name: str, discussion_log: List[str]) -> str:
        """
        ç”Ÿæˆåœ˜éšŠå…§éƒ¨çš„å…±è­˜èˆ‡åˆ†æ­§ç¸½çµ (Async).
        """
        discussion_text = "\n".join(discussion_log)
        
        db = SessionLocal()
        try:
            sys_template = PromptService.get_prompt(db, "debate.team_summary_system")
            if not sys_template: sys_template = "Summarize team discussion."
            system_prompt = sys_template.format(team_name=team_name)

            user_template = PromptService.get_prompt(db, "debate.team_summary_user")
            if not user_template: user_template = "{discussion_text}"
            user_prompt = user_template.format(discussion_text=discussion_text)
        finally:
            db.close()
            
        return await call_llm_async(user_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:TeamSummary:{team_name}")

    def _agent_select_tools(self, agent: AgentBase, side: str):
         """Sync wrapper for backward compatibility"""
         return asyncio.run(self._agent_select_tools_async(agent, side))

    async def _agent_select_tools_async(self, agent: AgentBase, side: str):
        """
        Agent åœ¨è¾¯è«–é–‹å§‹å‰å‹•æ…‹é¸æ“‡æœ€é©åˆçš„å·¥å…· (Async).
        """
        db = SessionLocal()
        try:
            # ç²å–è©² Agent å¯ç”¨çš„å·¥å…·åˆ—è¡¨ (å¾ DB ToolSet)
            agent_id = getattr(agent, 'id', None)
            if not agent_id:
                # å˜—è©¦å¾ DB æŸ¥æ‰¾
                db_agent = db.query(models.Agent).filter(models.Agent.name == agent.name).first()
                if db_agent:
                    agent_id = db_agent.id
            
            if agent_id:
                available_tools_list = ToolSetService.get_agent_available_tools(db, agent_id)
            else:
                # Fallback: å¦‚æœæ‰¾ä¸åˆ° IDï¼Œåˆ—å‡ºæ‰€æœ‰å·¥å…· (æˆ–åƒ… Global)
                all_tools_dict = tool_registry.list()
                available_tools_list = []
                for name, data in all_tools_dict.items():
                    available_tools_list.append({"name": name, "description": data['description']})

            # [Optimization Phase 7] Role-Based Tool Suggestion
            # Sort/Tag tools based on agent side
            sorted_tools = []
            
            # Define priority sets
            # [Phase 1 Update] Hide raw 'tej.stock_price' to force use of 'financial.get_verified_price'
            # We filter OUT tej.stock_price from the suggestion list, but keep other tej tools (like financial_summary)
            
            # [New] ChinaTimes Tools (Priority if enabled)
            chinatimes_tools = [t for t in available_tools_list if "chinatimes" in t['name']]
            
            tej_tools = [t for t in available_tools_list if "tej" in t['name'] and t['name'] != "tej.stock_price"]
            
            # 'financial.get_verified_price' is in official_tools
            official_tools = [t for t in available_tools_list if "twse" in t['name'] or "verified" in t['name']]
            
            # Exclude chinatimes from backup/other
            backup_tools = [t for t in available_tools_list if ("yahoo" in t['name'] or "search" in t['name']) and "chinatimes" not in t['name']]
            other_tools = [t for t in available_tools_list if t not in tej_tools and t not in official_tools and t not in backup_tools and t['name'] != "tej.stock_price" and "chinatimes" not in t['name']]
            
            # Helper to tag tools
            def tag_tools(tools, tag):
                return [{"name": t['name'], "description": f"{tag} {t['description']}"} for t in tools]

            if side in ["pro", "con"]:
                # Pro/Con prioritize Verified Price & ChinaTimes (Facts)
                sorted_tools.extend(tag_tools(chinatimes_tools, "[æ¨è–¦:æ–°èäº‹å¯¦]"))
                sorted_tools.extend(tag_tools(official_tools, "[æ¨è–¦:2025æœ€æ–°æ•¸æ“š/å®˜æ–¹é©—è­‰]"))
                sorted_tools.extend(tej_tools) # Other TEJ tools
                sorted_tools.extend(backup_tools)
                sorted_tools.extend(other_tools)
            elif side == "neutral":
                # Neutral prioritize Official/Verified (Audit)
                sorted_tools.extend(tag_tools(official_tools, "[æ¨è–¦:å®˜æ–¹é©—è­‰]"))
                sorted_tools.extend(tag_tools(chinatimes_tools, "[æ¨è–¦:äº‹å¯¦æŸ¥æ ¸]"))
                sorted_tools.extend(tej_tools)
                sorted_tools.extend(backup_tools)
                sorted_tools.extend(other_tools)
            else:
                # Default mix
                sorted_tools = []
                sorted_tools.extend(tag_tools(chinatimes_tools, "[æ¨è–¦]"))
                sorted_tools.extend(official_tools)
                sorted_tools.extend(tej_tools)
                sorted_tools.extend(backup_tools)
                sorted_tools.extend(other_tools)

            tools_list_text = "\n".join([f"- {t['name']}: {t['description']}" for t in sorted_tools])
        finally:
            db.close()
        
        # DB session for prompt
        db = SessionLocal()
        try:
            sys_template = PromptService.get_prompt(db, "debate.tool_selection_system")
            if not sys_template: sys_template = "You are {agent_name}."
            system_prompt = sys_template.format(agent_name=agent.name, side=side, topic=self.topic)

            user_template = PromptService.get_prompt(db, "debate.tool_selection_user")
            if not user_template: user_template = "Select tools: {tools_list_text}"
            user_prompt = user_template.format(tools_list_text=tools_list_text)
        finally:
            db.close()

        try:
            # Async LLM Call
            response = await call_llm_async(user_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}:ToolSelection")
            
            # å˜—è©¦è§£æ JSON (æ”¯æ´ List æˆ– Dict æ ¼å¼)
            selected_tools = []
            
            # [FIX] Force include ChinaTimes if available in global list
            has_chinatimes = any("chinatimes" in t['name'] for t in available_tools_list)
            if has_chinatimes:
                for t in available_tools_list:
                    if "chinatimes" in t['name'] and t['name'] not in selected_tools:
                        selected_tools.append(t['name'])
            
            # [Fix Phase 21] Robust JSON Parsing
            # 1. Clean Markdown code blocks ```json ... ```
            cleaned_response = re.sub(r'```json\s*(.*?)\s*```', r'\1', response, flags=re.DOTALL)
            cleaned_response = re.sub(r'```\s*(.*?)\s*```', r'\1', cleaned_response, flags=re.DOTALL)
            
            # 2. Try List [...]
            list_match = re.search(r'\[.*\]', cleaned_response, re.DOTALL)
            if list_match:
                try:
                    selected_tools_llm = json.loads(list_match.group(0))
                    if isinstance(selected_tools_llm, list):
                        selected_tools.extend(selected_tools_llm)
                except:
                    pass

            # 3. Try Dict {"tools": [...]} if list failed
            if not selected_tools:
                dict_match = re.search(r'\{.*\}', cleaned_response, re.DOTALL)
                if dict_match:
                    try:
                        data = json.loads(dict_match.group(0))
                        if isinstance(data, dict):
                            selected_tools_llm = data.get("tools") or data.get("tool_names") or []
                            if isinstance(selected_tools_llm, list):
                                selected_tools.extend(selected_tools_llm)
                    except:
                        pass
            
            # Final validation and deduplication
            available_names = set(t['name'] for t in available_tools_list)
            valid_tools = []
            seen = set()
            for t in selected_tools:
                if t in available_names and t not in seen:
                    valid_tools.append(t)
                    seen.add(t)
            
            # Ensure forced tools are still there (if user LLM didn't select them, we added them at start, but validation might filter them if they are not in available list)
            # Actually, we added them only if they are in available_tools_list, so they should pass validation unless logic is wrong.
            # But let's double check.
            if has_chinatimes:
                for t in available_tools_list:
                    if "chinatimes" in t['name'] and t['name'] not in seen:
                        valid_tools.append(t['name'])
                        seen.add(t['name'])

            if valid_tools:
                self.agent_tools_map[agent.name] = valid_tools
                print(f"Agent {agent.name} selected tools: {valid_tools}")
                
                # æ ¼å¼åŒ–å·¥å…·åˆ—è¡¨é¡¯ç¤º
                tools_display = "\n".join([f"  â€¢ {tool}" for tool in valid_tools])
                self._publish_log(f"{agent.name} (Setup)", f"âœ… å·²é¸æ“‡ {len(valid_tools)} å€‹å·¥å…·ï¼š\n{tools_display}")
            else:
                # [Fix Phase 21] Improved Fallback Strategy
                # Fallback: Instead of equipping ALL tools (which explodes context), equip a Safe Default Set
                # Role-based fallback
                # Determine base tools based on availability (feature flags)
                base_search_tool = "searxng.search"
                # Check if chinatimes is available in registry list (hacky check on name list)
                has_chinatimes = any("chinatimes" in t['name'] for t in available_tools_list)
                
                if side == "neutral":
                    default_tools = ["financial.get_verified_price", "twse.stock_day", "internal.search_company"]
                else:
                    default_tools = ["financial.get_verified_price", "tej.financial_summary", "internal.search_company"]
                
                # Add Search Tool (Prioritize ChinaTimes if available)
                if has_chinatimes:
                    default_tools.append("news.search_chinatimes")
                
                default_tools.append(base_search_tool)
                
                # Filter defaults to ensure they are available to this agent
                available_names = [t['name'] for t in available_tools_list]
                # We need to ensure 'financial.get_verified_price' is in available_tools_list?
                # It should be if it's registered globally or assigned.
                # If not, we might need to add it explicitly to the fallback if we trust it exists.
                safe_fallback = [t for t in default_tools if t in available_names]
                
                # If no safe fallback found (rare), then fall back to all
                if not safe_fallback:
                    safe_fallback = available_names
                
                self.agent_tools_map[agent.name] = safe_fallback
                
                print(f"Agent {agent.name} failed to select tools. Raw response: {response[:100]}... Using fallback: {safe_fallback}")
                
                tools_display = "\n".join([f"  â€¢ {tool}" for tool in safe_fallback])
                self._publish_log(f"{agent.name} (Setup)", f"âš ï¸ å·¥å…·é¸æ“‡è§£æå¤±æ•— (Raw: {response[:50]}...)ï¼Œå·²å•Ÿç”¨å®‰å…¨é è¨­å·¥å…·çµ„ ({len(safe_fallback)}å€‹)ï¼š\n{tools_display}")

        except Exception as e:
            print(f"Error in tool selection for {agent.name}: {e}")
            # Final Fallback
            self.agent_tools_map[agent.name] = ["searxng.search"]
            self._publish_log(f"{agent.name} (Setup)", f"âŒ å·¥å…·é¸æ“‡ç™¼ç”ŸéŒ¯èª¤: {str(e)}ã€‚å·²å•Ÿç”¨åŸºç¤æœå°‹å·¥å…·ã€‚")

    def _summarize_old_turns(self):
        """
        åˆ†å±¤æ‘˜è¦ (Hierarchical Summarization)ï¼š
        å°‡èˆŠçš„å°è©±æ­·å²é€²è¡Œçµæ§‹åŒ–æ‘˜è¦ï¼Œä¿ç•™æ¯å€‹è§’è‰²çš„æ ¸å¿ƒè§€é»ã€‚
        """
        keep_recent = 5 # ä¿ç•™æœ€è¿‘ 5 æ¢ (å¢åŠ ä¸Šä¸‹æ–‡)
        
        if len(self.history) <= keep_recent + 2:
            return

        # æå–éœ€è¦å£“ç¸®çš„èˆŠè¨Šæ¯
        to_compress = self.history[:-keep_recent]
        # æ›´æ–° self.historyï¼Œåªä¿ç•™æœ€è¿‘çš„è¨Šæ¯
        self.history = self.history[-keep_recent:]
        
        # æ§‹å»ºå¾…æ‘˜è¦æ–‡æœ¬
        conversation_text = ""
        for item in to_compress:
            role = item.get('role')
            content = str(item.get('content'))
            if len(content) > 500:
                content = content[:500] + "..."
            conversation_text += f"[{role}]: {content}\n\n"
        
        db = SessionLocal()
        try:
            template = PromptService.get_prompt(db, "debate.hierarchical_summarizer")
            if not template: template = "Summarize: {conversation_text}"
            system_prompt = template
            user_prompt = f"è«‹æ‘˜è¦ä»¥ä¸‹å°è©±ï¼š\n\n{conversation_text}"
        finally:
            db.close()
        
        try:
            summary = call_llm(user_prompt, system_prompt=system_prompt)
            if summary:
                self.archived_summaries.append(summary)
                print(f"DEBUG: Hierarchical summary generated. Length: {len(summary)}")
                self._publish_log("System", "å·²å°èˆŠçš„è¾¯è«–æ­·å²é€²è¡Œåˆ†å±¤æ‘˜è¦è™•ç†ã€‚")
        except Exception as e:
            print(f"WARNING: Hierarchical summarization failed: {e}")
            # Fallback: Just append raw text truncated if summary fails?
            # Or just keep it in history? No, that would lose data or explode context.
            # Let's append a placeholder.
            self.archived_summaries.append(f"(æ‘˜è¦å¤±æ•—: {str(e)})")

    def _get_compact_history(self, max_length=2000) -> str:
        """
        ç²å–å„ªåŒ–å¾Œçš„è¾¯è«–æ­·å² (Hierarchical Summary + Recent History)
        """
        # 1. å˜—è©¦è§¸ç™¼æ‘˜è¦
        self._summarize_old_turns()
        
        # 2. çµ„åˆæ­·å²
        # A. çµæ§‹åŒ–æ‘˜è¦å€
        archived_text = "ã€éå¾€è¾¯è«–æ‘˜è¦ã€‘\n" + "\n".join(self.archived_summaries)
        
        # B. è¿‘æœŸå°è©±å€
        active_history_text = "ã€è¿‘æœŸå°è©±ã€‘\n"
        for item in self.history:
            content = item.get("content", "")
            if len(content) > 800:
                content = content[:300] + "...(ç•¥)..." + content[-300:]
            active_history_text += f"{item.get('role')}: {content}\n\n"
        
        return f"{archived_text}\n\n{active_history_text}"

    def _agent_turn(self, agent: AgentBase, side: str, round_num: int) -> str:
        return asyncio.run(self._agent_turn_async(agent, side, round_num))

    async def _agent_turn_async(self, agent: AgentBase, side: str, round_num: int) -> str:
        """
        åŸ·è¡Œå–®å€‹ Agent çš„å›åˆï¼šæ€è€ƒ -> å·¥å…· -> ç™¼è¨€ (Async)
        """
        print(f"Agent {agent.name} ({side}) is thinking...")
        self._publish_log(f"{agent.name} (Thinking)", f"{agent.name} æ­£åœ¨æ€è€ƒä¸¦æ±ºå®šä½¿ç”¨çš„ç­–ç•¥...")
        
        # æ§‹å»º Prompt - ä½¿ç”¨ Agent è‡ªå·±é¸æ“‡çš„å·¥å…·
        selected_tool_names = self.agent_tools_map.get(agent.name, [])
        ollama_tools = []
        
        # å¦‚æœæœ‰é¸æ“‡ï¼Œå‰‡åªé¡¯ç¤ºé¸æ“‡çš„å·¥å…·ï¼›å¦å‰‡é¡¯ç¤ºæ‰€æœ‰ã€Œå¯ç”¨ã€çš„å·¥å…·
        if selected_tool_names:
            filtered_tools = {}
            for name in selected_tool_names:
                try:
                    # Using get_tool_data ensures lazy tools are loaded and schema is available
                    # Assuming version 'v1' for now as selection doesn't specify version
                    tool_data = tool_registry.get_tool_data(name)
                    filtered_tools[name] = tool_data
                    
                    # Convert to Ollama tool format
                    # Ensure parameters schema is valid and robust
                    params_schema = tool_data.get('schema')
                    if not params_schema:
                        params_schema = {"type": "object", "properties": {}, "required": []}
                    elif isinstance(params_schema, dict):
                        # Ensure 'type' is object
                        if "type" not in params_schema:
                            params_schema["type"] = "object"
                        # Ensure 'properties' exists
                        if "properties" not in params_schema:
                            params_schema["properties"] = {}
                    
                    # Fix: description might be a dict (metadata) or a string
                    desc = tool_data.get('description', '')
                    if isinstance(desc, dict):
                        desc = desc.get('description', '')

                    ollama_tools.append({
                        "type": "function",
                        "function": {
                            "name": name,
                            "description": desc,
                            "parameters": params_schema
                        }
                    })
                except Exception as e:
                    print(f"Warning: Selected tool '{name}' not found or failed to load: {e}")

            if not filtered_tools:
                 # å¦‚æœé¸æ“‡ç„¡æ•ˆï¼Œå›é€€åˆ°é¡¯ç¤ºè©² Agent æ‰€æœ‰å¯ç”¨çš„å·¥å…· (ToolSet)
                 tools_desc = get_tools_description()
            else:
                 tools_desc = "ä½ å·²é¸æ“‡ä¸¦æ¿€æ´»ä»¥ä¸‹å·¥å…·ï¼ˆç³»çµ±å·²è‡ªå‹•æ›è¼‰ï¼‰ï¼š\n" + "\n".join([f"- {name}: {data['description']}" for name, data in filtered_tools.items()])
        else:
            # å¦‚æœæ²’æœ‰é¸æ“‡ï¼ˆä¾‹å¦‚åˆå§‹åŒ–å¤±æ•—ï¼‰ï¼Œé¡¯ç¤ºæ‰€æœ‰å·¥å…·
            tools_desc = get_tools_description()
            
        # Append Meta-Tool Description
        # Dynamically fetch available groups from registry for the hint
        available_groups = set()
        for _, t_data in tool_registry.list().items():
             available_groups.add(t_data.get('group', 'basic'))
        groups_str = " | ".join([f"'{g}'" for g in sorted(available_groups)])
        
        tools_desc += f"\n\n### reset_equipped_tools\nDescription: å‹•æ…‹åˆ‡æ›å·¥å…·çµ„ (active tool group)ã€‚è‹¥ä½ æ‰¾ä¸åˆ°éœ€è¦çš„å·¥å…·ï¼Œè«‹å˜—è©¦åˆ‡æ›ã€‚\nParameters: {{'group': {groups_str}}}"
        
        # Append Chairman Intervention Tool (Virtual)
        tools_desc += "\n\n### call_chairman\nDescription: ç•¶ä½ ç™¼ç¾è¾¯é¡Œè³‡è¨Šåš´é‡ä¸è¶³ï¼ˆå¦‚ç¼ºä¹èƒŒæ™¯ã€å®šç¾©ä¸æ¸…ï¼‰ï¼Œç„¡æ³•é€²è¡Œæœ‰æ•ˆåˆ†ææ™‚ï¼Œè«‹ä½¿ç”¨æ­¤å·¥å…·é€šçŸ¥ä¸»å¸­ä»‹å…¥è™•ç†ã€‚\nParameters: {'reason': 'èªªæ˜å…·é«”ç¼ºå°‘ä»€éº¼è³‡è¨Šæˆ–èƒŒæ™¯'}"

        tools_examples = get_tools_examples() # Examples æš«æ™‚ä¿æŒå…¨é›†ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥éæ¿¾
        
        # Retrieve Tool LTM hints
        tool_hints = ""
        # Use persistent instance
        tool_hints = await self.tool_memory.retrieve_async(self.topic) # Use topic as context for now
        if tool_hints:
            tools_examples += f"\n\n**éå¾€æˆåŠŸå·¥å…·èª¿ç”¨åƒè€ƒ (ReMe Tool LTM)**:\n{tool_hints}"

        # Retrieve RAG Context (Relevant History)
        rag_context = ""
        # Use persistent instance
        # Use current agent role and topic as query
        query = f"{agent.name} {side} {self.topic}"
        relevant_turns = await self.history_memory.retrieve_async(query, top_k=2)
        if relevant_turns:
            rag_context = "\n".join([f"> [{t['role']} (Round {t['round']})]: {str(t['content'])[:200]}..." for t in relevant_turns])

        history_text = self._get_compact_history()
        if rag_context:
            history_text += f"\n\nã€ç›¸é—œæ­·å²å›é¡§ (RAG)ã€‘\n{rag_context}"
        
        db = SessionLocal()
        try:
            # 1. System Prompt Construction
            # [Governance] Use PromptService.compose_system_prompt to inject Base Contract
            
            # A. Prepare Agent Persona
            custom_prompt = getattr(agent, 'system_prompt', '').strip()
            if not custom_prompt:
                custom_prompt = f"ä½ æ˜¯ {agent.name}ï¼Œä»£è¡¨ {side} æ–¹ã€‚"
            
            # Additional Context
            persona_context = f"""
{custom_prompt}

è¾¯é¡Œï¼š{self.topic}
ç«‹å ´ï¼š{side}
"""
            # B. Operational Rules (Externalized)
            operational_rules = PromptService.get_prompt(db, "debater.operational_rules")
            if not operational_rules:
                # Minimal fallback if not found
                operational_rules = "System Rules: Use tools first. Do NOT fabricate data."

            # [Phase 18] Dynamic Data Honesty Rules
            if self.latest_db_date:
                operational_rules += f"\nSystem Note: The database data ends on {self.latest_db_date}. Do not query future dates."

            # C. [Topic Locking] Inject Decree
            decree_text = ""
            if hasattr(self, 'topic_decree') and self.topic_decree:
                d = self.topic_decree
                decree_text = f"""
# ğŸ”” DEBATE CONTEXT (IMMUTABLE DECREE)
- **Target Subject**: {d.get('subject', 'Unknown')} ({d.get('code', 'Unknown')})
- **Target Industry**: {d.get('industry', 'Unknown')}
- **Timeframe**: {d.get('timeframe', 'Unknown')}
- **Core Question**: {d.get('core_question', 'Unknown')}

[CONSTRAINT]: You MUST discuss THIS subject in the context of THIS industry ({d.get('industry', 'Unknown')}). Do NOT deviate to other industries.
"""

            # D. Compose Final System Prompt
            final_persona = f"{decree_text}\n\n{persona_context}\n\n# Operational Rules\n{operational_rules}"
            system_prompt = PromptService.compose_system_prompt(db, override_content=final_persona, agent_name=agent.name)
            
            # 2. User Prompt (Tool Instruction)
            user_template = PromptService.get_prompt(db, "debater.tool_instruction")
            if not user_template: user_template = "Instructions: {history_text} {tools_desc}"
            
            # [Phase 18] Dynamic Date Injection
            db_date_info = ""
            if self.latest_db_date:
                db_date_info = f"\n**æ³¨æ„ï¼šè³‡æ–™åº«æœ€æ–°æ•¸æ“šæ—¥æœŸç‚º {self.latest_db_date}ã€‚**"
            
            # [Fix] Load Fallback Hint from Database
            fallback_hint = PromptService.get_prompt(db, "debater.fallback_hint")
            if not fallback_hint:
                fallback_hint = "\nğŸ’¡ Hint: Use 'searxng.search' if structured data is missing."
            
            # [Governance] Browser Info
            browser_info = f"\n### ğŸŒ ç€è¦½æ²»ç†ç‹€æ…‹ (Browser Governance Status)\n- **å‰©é¤˜ç€è¦½é…é¡**: {self.browse_quota} é» (æ¯æ¬¡æœå°‹æˆåŠŸçå‹µ 1 é»)\n"
            if self.discovered_urls:
                # Show top 5 discovered URLs if many
                show_urls = list(self.discovered_urls)[:5]
                browser_info += "- **å·²ç™¼ç¾å¯ç”¨ç¶²å€ (Discovered URLs)**:\n  " + "\n  ".join(show_urls)
                if len(self.discovered_urls) > 5:
                    browser_info += f"\n  ... (å…± {len(self.discovered_urls)} å€‹ç¶²å€)"
            else:
                browser_info += "- **ç›®å‰å°šæœªç™¼ç¾å¯ç”¨ç¶²å€ï¼Œè«‹å…ˆä½¿ç”¨æœå°‹å·¥å…·å–å¾—æ•¸æ“šå¾Œå†ç”³è«‹ç€è¦½ã€‚**"

            user_prompt = user_template.format(
                round_num=round_num,
                history_text=history_text,
                chairman_summary=self.analysis_result.get('step5_summary', 'ç„¡'),
                current_date=f"{CURRENT_DATE} {db_date_info}",
                stock_codes=chr(10).join([f"- {name}: {code}" for name, code in STOCK_CODES.items()]),
                tools_desc=tools_desc + browser_info,
                tools_examples=tools_examples,
                fallback_hint=fallback_hint
            )
        finally:
            db.close()
        
        # === Multi-Step Tool Execution Loop ===
        base_max_steps = int(os.getenv("MAX_AGENT_TOOL_STEPS", 5))
        extension_steps = int(os.getenv("EXTENSION_STEPS", 3))
        max_steps = base_max_steps
        extensions_used = 0
        last_extension_reason = ""
        
        current_step = 0
        current_prompt = user_prompt
        collected_evidence = [] # Track evidence for fallback report
        tool_call_history = [] # Track last N tool calls to prevent loops (A-B-A patterns)
        
        # [Governance] Retry Loop Context
        guardrail_retries = 0
        MAX_GUARDRAIL_RETRIES = 2
        
        while True: # Outer Loop for Extension Retry
            while current_step < max_steps:
                current_step += 1
                
                # Async LLM Call (Passing tools!)
                response = await call_llm_async(
                    current_prompt,
                    system_prompt=system_prompt,
                    context_tag=f"{self.debate_id}:{agent.name}",
                    tools=ollama_tools if ollama_tools else None
                )
                print(f"DEBUG: Agent {agent.name} response (Step {current_step}): {response[:500]}")
                
                # [Debug] Trace LLM IO
                trace_item = {
                    "timestamp": datetime.now().isoformat(),
                    "agent": agent.name,
                    "step": current_step,
                    "event": "LLM_RESPONSE",
                    "prompt": current_prompt,
                    "response": response
                }
                self.debug_trace.append(trace_item)
                
                # [Realtime] Log trace details
                self._log_to_file(f"--- [LLM IO] {agent.name} Step {current_step} ---\nPrompt Preview: {current_prompt[:200]}...\nResponse Preview: {response[:200]}...")

                # --- [Governance] Guardrail Check ---
                # Check ALL text responses, and potentially Tool Calls (if we want to block dangerous tools)
                # Here we check Text Responses (non-tool calls) primarily to stop Hallucination/Scope Creep
                is_tool_call = False
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    try:
                        tool_call_test = json.loads(json_match.group(0))
                        if isinstance(tool_call_test, dict) and "tool" in tool_call_test:
                            is_tool_call = True
                    except:
                        pass
                
                # Guardrail Logic: Intercept final speech or reasoning steps
                if not is_tool_call:
                    check_context = f"Topic: {self.topic}\nLast Evidence: {str(collected_evidence[-1]) if collected_evidence else 'None'}"
                    audit_result = self.guardrail_agent.check(agent.name, response, check_context)
                    
                    if audit_result["status"] == "REJECTED":
                        self._publish_log("Guardrail", f"â›” æ””æˆªé•è¦ç™¼è¨€ ({audit_result['violation_type']}): {audit_result['reason']}")
                        
                        if guardrail_retries < MAX_GUARDRAIL_RETRIES:
                            guardrail_retries += 1
                            current_prompt = f"ã€Guardrail åˆè¦è­¦å‘Šã€‘\nä½ çš„å›ç­”è¢«æ‹’çµ•ï¼ŒåŸå› ï¼š{audit_result['reason']}ã€‚\nä¿®æ­£æŒ‡ä»¤ï¼š{audit_result['correction_instruction']}\n\nè«‹æ ¹æ“šæŒ‡ä»¤ä¿®æ­£å¾Œé‡æ–°è¼¸å‡ºã€‚"
                            
                            # Log Audit Event
                            self.redis_client.publish("guardrail:audit", json.dumps({
                                "debate_id": self.debate_id,
                                "agent": agent.name,
                                "action": "REJECTED",
                                "reason": audit_result["reason"]
                            }, ensure_ascii=False))
                            
                            # Decrease step count to not penalize retry? Or consume step?
                            # Design: Consume step to force convergence.
                            continue
                        else:
                            self._publish_log("Guardrail", f"âš ï¸ é‡è©¦æ¬¡æ•¸éå¤šï¼Œå¼·åˆ¶æ”¾è¡Œ (æ¨™è¨˜ç‚ºé¢¨éšªå…§å®¹)ã€‚")
                            # Force Pass but Log Warning
                            # (Proceed as normal)
                    elif audit_result["status"] == "WARNING":
                         self._publish_log("Guardrail", f"âš ï¸ åˆè¦è­¦å‘Š: {audit_result['reason']}")

                # ------------------------------------

                # Check for tool call
                try:
                    # å˜—è©¦æå– JSON
                    json_match = re.search(r'\{.*\}', response, re.DOTALL)
                    if not json_match:
                        # No JSON found -> Assume final speech -> Return
                        return response
                    
                    json_str = json_match.group(0)
                    try:
                        tool_call = json.loads(json_str)
                    except json.JSONDecodeError:
                        # JSON parse failed -> Treat as text
                        return response

                    # Check if valid tool call
                    if isinstance(tool_call, dict) and "tool" in tool_call and "params" in tool_call:
                        tool_name = str(tool_call["tool"]).strip()
                        params = tool_call["params"]
                        
                        # --- Check for Duplicate Call (Loop Prevention & Sentinel) ---
                        current_call_signature = f"{tool_name}:{json.dumps(params, sort_keys=True)}"
                        
                        # [Robustness] Enhanced Loop Detection (History Check)
                        # Check against ALL previous calls in this turn to prevent ANY exact repeats
                        if current_call_signature in tool_call_history:
                            print(f"âš ï¸ Loop detected: Agent {agent.name} repeated call {tool_name}")
                            self._publish_log(f"{agent.name} (System)", f"âš ï¸ åµæ¸¬åˆ°é‡è¤‡èª¿ç”¨ ({tool_name})ï¼Œå·²æ””æˆªã€‚")
                            
                            # [Fix] Instead of just prompting, simulate a failed result to break the loop
                            # This forces the Agent to process a "result" and move on, rather than ignoring the system prompt.
                            fake_result = {
                                "error": "Loop Detected: You have already called this tool with these exact parameters.",
                                "suggestion": "Please modify your parameters (e.g., change keyword, date range) or use a different tool. If you cannot find data, please report 'No Data' and move to conclusion."
                            }
                            
                            current_prompt = f"""å·¥å…· {tool_name} çš„åŸ·è¡Œçµæœ (ç³»çµ±æ””æˆª)ï¼š
{json.dumps(fake_result, ensure_ascii=False, indent=2)}

ã€ç³»çµ±æç¤ºã€‘
1. åš´ç¦é‡è¤‡èª¿ç”¨ç›¸åŒåƒæ•¸çš„å·¥å…·ã€‚
2. è‹¥é€£çºŒå¤šæ¬¡ç„¡æ³•å–å¾—æ•¸æ“šï¼Œèªªæ˜ä½ é‡åˆ°äº†çŸ¥è­˜ç¼ºå£ï¼Œä¸¦ç«‹å³ç™¼è¡¨æœ¬è¼ªç¸½çµï¼Œä¸è¦å†å˜—è©¦èª¿ç”¨å·¥å…·ã€‚
"""
                            # [Observability] Log Metric
                            print(f"[LOOP_DETECTED] agent={agent.name} tool={tool_name} type=history_repeat")
                            continue
                        
                        tool_call_history.append(current_call_signature)
                        
                        # Soft loop check (frequency)
                        sentinel_key = f"{agent.name}:{current_call_signature}"
                        self._loop_sentinel[sentinel_key] = self._loop_sentinel.get(sentinel_key, 0) + 1
                        if self._loop_sentinel[sentinel_key] > 2:
                             print(f"[LOOP_DETECTED] agent={agent.name} tool={tool_name} type=frequent_access count={self._loop_sentinel[sentinel_key]}")
                        # --------------------------------------------------

                        # --- Meta-Tool: reset_equipped_tools ---
                        if tool_name == "reset_equipped_tools":
                            target_group = params.get("group", "basic")
                            print(f"âš™ï¸ Agent {agent.name} is resetting equipped tools to group: {target_group}")
                            self._publish_log(f"{agent.name} (Meta-Tool)", f"Resetting tools to group: {target_group}")
                            
                            group_tools = tool_registry.list(groups=[target_group])
                            self.agent_tools_map[agent.name] = list(group_tools.keys())
                            
                            # Recursive retry with new tools (Reset steps)
                            return await self._agent_turn_async(agent, side, round_num)

                        # --- Meta-Tool: call_chairman (Intervention) ---
                        if tool_name == "call_chairman":
                            reason = params.get("reason", "æœªèªªæ˜åŸå› ")
                            print(f"ğŸš¨ Agent {agent.name} is calling Chairman for help: {reason}")
                            self._publish_log(f"{agent.name} (SOS)", f"è«‹æ±‚ä¸»å¸­ä»‹å…¥ï¼š{reason}")

                            # [Loop Fix] Auto-Equip Tools on "Missing Data" complaints
                            # If reason contains "lack", "missing", "data", "price", "stock" -> try to equip fallback tools
                            triggers = ["ç¼º", "miss", "data", "æ•¸æ“š", "è³‡æ–™", "price", "stock", "è‚¡åƒ¹", "2480"]
                            if any(t in reason.lower() for t in triggers):
                                fallback_tools = ["chinatimes.stock_rt", "financial.get_verified_price", "twse.stock_day"]
                                added_tools = []
                                current_tools = self.agent_tools_map.get(agent.name, [])
                                
                                for ft in fallback_tools:
                                    if ft not in current_tools:
                                        current_tools.append(ft)
                                        added_tools.append(ft)
                                
                                if added_tools:
                                    self.agent_tools_map[agent.name] = current_tools
                                    self._publish_log("System", f"ğŸ› ï¸ [Auto-Fix] åµæ¸¬åˆ° Agent ç¼ºå°‘æ•¸æ“šå·¥å…·ï¼Œå·²è‡ªå‹•ç‚º {agent.name} è£å‚™ï¼š{', '.join(added_tools)}")

                            chairman_prompt = f"Agent {agent.name} ({side}æ–¹) åœ¨åˆ†æè¾¯é¡Œã€Œ{self.topic}ã€æ™‚é‡åˆ°å›°é›£ã€‚\nå›å ±åŸå› ï¼š{reason}\nè«‹æ ¹æ“šä½ çš„è³½å‰åˆ†ææ‰‹å¡ï¼Œæä¾›å¼•å°ã€‚"
                            clarification = await call_llm_async(chairman_prompt, system_prompt="ä½ æ˜¯è¾¯è«–ä¸»å¸­ã€‚è«‹å”åŠ©é‡åˆ°å›°é›£çš„è¾¯æ‰‹ã€‚")
                            
                            self._publish_log("Chairman (Intervention)", f"ä¸»å¸­å›æ‡‰ï¼š{clarification}")
                            
                            intervention_msg = {"role": "Chairman (Intervention)", "content": f"è£œå……èªªæ˜ï¼š\n{clarification}\nè«‹ç¹¼çºŒåˆ†æã€‚"}
                            self.history.append(intervention_msg)
                            
                            # Recursive retry (Reset steps)
                            return await self._agent_turn_async(agent, side, round_num)

                        # --- Meta-Tool: request_extension (Early access check) ---
                        if tool_name == "request_extension":
                             print(f"Agent {agent.name} requested extension prematurely.")
                             self._publish_log(f"{agent.name} (System)", "âš ï¸ ä½ é‚„æœ‰å‰©é¤˜çš„èª¿æŸ¥æ¬¡æ•¸ï¼Œè«‹å„ªå…ˆä½¿ç”¨å·¥å…·é€²è¡Œèª¿æŸ¥ã€‚")
                             current_prompt = "ç³»çµ±æç¤ºï¼šä½ é‚„æœ‰å‰©é¤˜çš„èª¿æŸ¥æ¬¡æ•¸ï¼Œç„¡éœ€ç”³è«‹å»¶é•·ã€‚è«‹ç¹¼çºŒä½¿ç”¨å·¥å…·æœå°‹æ•¸æ“šã€‚"
                             continue
                        
                        # --- Memory Tool Context Injection ---
                        if tool_name == "search_shared_memory":
                            params["debate_id"] = self.debate_id

                        # --- Regular Tool Execution ---
                        
                        # [STRICT TOOL VALIDATION]
                        # Check if the tool is in the equipped list for this agent
                        equipped_tools = self.agent_tools_map.get(agent.name, [])
                        
                        # [Governance] Active Fallback for Disabled/Missing Tools (e.g. tej.*)
                        if tool_name not in equipped_tools:
                            fallback_tool = None
                            if tool_name.startswith("tej."):
                                # Primary fallback for TEJ is official TWSE or Search
                                if "stock_price" in tool_name: fallback_tool = "financial.get_verified_price"
                                elif "company_info" in tool_name: fallback_tool = "internal.search_company"
                                else: fallback_tool = "searxng.search"
                            
                            if fallback_tool and fallback_tool in equipped_tools:
                                self._publish_log(f"{agent.name} (System)", f"ğŸ”„ è‡ªå‹•å°æµï¼šå·¥å…· {tool_name} ç›®å‰ç¦ç”¨ï¼Œå·²åˆ‡æ›è‡³ {fallback_tool}")
                                tool_name = fallback_tool
                                # Fall through to normal execution with new name
                            else:
                                print(f"âŒ Blocked: Agent {agent.name} tried to call unequipped tool: {tool_name}")
                                error_msg = f"Error: Tool '{tool_name}' is disabled or not in your equipped list. You can only use: {equipped_tools}."
                                self._publish_log(f"{agent.name} (System)", f"â›” æ‹’çµ•åŸ·è¡Œï¼šå·¥å…· {tool_name} ä¸å¯ç”¨")
                                collected_evidence.append(f"ã€ç³»çµ±éŒ¯èª¤ã€‘èª¿ç”¨å¤±æ•—ï¼š{error_msg}")
                                current_prompt = f"ç³»çµ±æç¤ºï¼šå·¥å…·ã€Œ{tool_name}ã€ç›®å‰ç„¡æ³•ä½¿ç”¨ã€‚è«‹å„ªå…ˆæ”¹ç”¨æœå°‹æˆ–å…¶ä»–å¯ç”¨å·¥å…·ã€‚"
                                continue

                        # --- [Governance Gate] Chairman Approval Check ---
                        tool_meta = tool_registry.get_tool_data(tool_name)
                        if tool_meta.get("requires_approval"):
                            approval = await self._request_chairman_tool_approval(agent, tool_name, params)
                            if not approval.get("approved"):
                                self._publish_log("System", f"â›” {agent.name} çš„å·¥å…·è«‹æ±‚è¢«ä¸»å¸­é§å›ã€‚å»ºè­°ï¼š{approval.get('guidance')}")
                                current_prompt = f"ã€ä¸»å¸­æŒ‡ä»¤ã€‘ä½ çš„å·¥å…·èª¿ç”¨è¢«é§å›ã€‚\nç†ç”±ï¼š{approval.get('reason')}\næŒ‡å°å»ºè­°ï¼š{approval.get('guidance')}\nè«‹èª¿æ•´ç­–ç•¥ï¼Œä¾‹å¦‚ä¸ä¾è³´æ­¤å·¥å…·ç¹¼çºŒåˆ†æï¼Œæˆ–ä¿®æ­£ç†ç”±å¾Œé‡è©¦ã€‚"
                                continue # Skip execution and let agent reason
                                
                        print(f"âœ“ Agent {agent.name} calling {tool_name}")
                        self._publish_log(f"{agent.name} (Tool)", f"Calling {tool_name} with {params}")
                        
                        try:
                            # 1. Check Working Memory (Sensory Gating)
                            cached_result = await self.hippocampus.retrieve_working_memory(tool_name, params)
                            
                            if cached_result:
                                tool_result = cached_result['result']
                                
                                # [Memory Opt] Mark as Adopted since we are using it
                                await self.hippocampus.mark_adopted(tool_name, params)
                                
                                # Create a preview string for debugging
                                try:
                                    result_str = json.dumps(tool_result, ensure_ascii=False)
                                except:
                                    result_str = str(tool_result)
                                # Show FULL content for debugging as requested
                                self._publish_log(f"{agent.name} (Memory)", f"ğŸ§  å¾æµ·é¦¬è¿´çŸ­æœŸè¨˜æ†¶ä¸­ç²å–äº†çµæœ (Access: {cached_result['access_count']}) ã€{result_str}ã€")
                            else:
                                # 2. Execute Tool (Sensory Input)
                                from worker.tool_invoker import call_tool
                                loop = asyncio.get_running_loop()
                                
                                # [Observability] Track Latency & Cost
                                start_tool = datetime.now()
                                tool_result = await loop.run_in_executor(None, call_tool, tool_name, params)
                                tool_duration = (datetime.now() - start_tool).total_seconds()
                                
                                self.tool_stats["count"] += 1
                                self.tool_stats["total_time"] += tool_duration
                                
                                # Simple Cost Model
                                cost = 0.0
                                if tool_name.startswith("tej."): cost = 0.03 # $0.03 per TEJ call
                                elif tool_name.startswith("financial."): cost = 0.01 # Auditor
                                
                                # Google Search Cost Logic
                                if "search" in tool_name or "google" in tool_name:
                                    # Increment search count in Redis
                                    search_key = f"debate:{self.debate_id}:usage"
                                    self.redis_client.hincrby(search_key, "search_count", 1)
                                    
                                    # Cost calculation (Simplified: assume > 2M calls globally or just track usage)
                                    # $3 per 1M = $0.000003 per call
                                    # For this debate, we track estimated cost
                                    cost = 0.000003
                                
                                self.tool_stats["estimated_cost"] += cost
                                
                                # 3. Store in Working Memory
                                await self.hippocampus.store(agent.name, tool_name, params, tool_result)
                                self._publish_log(f"{agent.name} (Tool)", f"å·¥å…· {tool_name} åŸ·è¡ŒæˆåŠŸä¸¦å­˜å…¥æµ·é¦¬è¿´ã€‚")

                                # [Governance] Track discovered URLs for search tools
                                if "search" in tool_name or "fetch" in tool_name:
                                    found_urls = self._extract_urls(tool_result)
                                    if found_urls:
                                        self.discovered_urls.update(found_urls)
                                        self.browse_quota += 1 # [Governance] "Every search grants ONE browsing opportunity"
                                        self._publish_log("System", f"ğŸ” ç™¼ç¾ {len(found_urls)} å€‹æ–°é€£çµã€‚å·²ç™¼æ”¾ 1 é»ç€è¦½é…é¡ (ç›®å‰é…é¡: {self.browse_quota})ã€‚")
                            
                            # --- [Memory Management Opt] Summarization ---
                            if tool_name.startswith("browser.") or (isinstance(tool_result, str) and len(tool_result) > 4000):
                                tool_result = await self._summarize_content(str(tool_result), tool_name)
                            
                            # Publish Tool Result Preview to Log Stream
                            result_preview_log = str(tool_result)
                            if len(result_preview_log) > 500:
                                result_preview_log = result_preview_log[:500] + "... (é»æ“ŠæŸ¥çœ‹å®Œæ•´æ•¸æ“š)"
                            self._publish_log(f"{agent.name} (Tool Result)", f"ğŸ“Š å·¥å…·åŸ·è¡Œçµæœæ‘˜è¦ï¼š\n{result_preview_log}")
                            
                            # Print full result to backend console for debugging (as requested)
                            print(f"DEBUG: Full tool result for {tool_name}:\n{json.dumps(tool_result, ensure_ascii=False, indent=2, default=str)}")
                            
                            # [Debug] Trace Tool Result
                            self.debug_trace.append({
                                "timestamp": datetime.now().isoformat(),
                                "agent": agent.name,
                                "step": current_step,
                                "event": "TOOL_RESULT",
                                "tool": tool_name,
                                "params": params,
                                "result": tool_result
                            })
                            
                            # [Realtime] Log trace details
                            self._log_to_file(f"--- [TOOL RESULT] {agent.name} ---\nTool: {tool_name}\nParams: {params}\nResult Preview: {str(tool_result)[:200]}...")

                            # Record successful tool usage to Tool LTM
                            try:
                                # Use persistent instance
                                await self.tool_memory.record_async(
                                    intent=f"Debate on {self.topic}",
                                    tool_name=tool_name,
                                    params=params,
                                    result=tool_result,
                                    success=True
                                )
                            except Exception as e:
                                print(f"Warning: Failed to record tool usage to LTM: {e}")

                            # Record Evidence
                            evidence_entry = {
                                "role": f"{agent.name} ({side})",
                                "agent_name": agent.name,
                                "side": side,
                                "tool": tool_name,
                                "params": params,
                                "result": tool_result,
                                "timestamp": datetime.now().isoformat(),
                                "verified": False,
                                "round": round_num
                            }
                            self.redis_client.rpush(self.evidence_key, json.dumps(evidence_entry, ensure_ascii=False))
                            
                            # [Optimization Phase 18] Data Honesty Check
                            # Check if result is effectively empty
                            is_empty_result = False
                            if isinstance(tool_result, dict):
                                # TEJ standard: {'data': [], ...} or {'results': []}
                                if not tool_result.get("data") and not tool_result.get("results") and not tool_result.get("content"):
                                     # Check specific keys that might contain data
                                     if "data" in tool_result or "results" in tool_result:
                                         is_empty_result = True
                            elif isinstance(tool_result, list) and len(tool_result) == 0:
                                is_empty_result = True
                            
                            # Add to local collection (Truncated for summary)
                            # Avoid huge context overhead
                            result_str = str(tool_result)
                            if len(result_str) > 200:
                                preview = result_str[:200] + "... (å®Œæ•´å…§å®¹å·²å­˜æª”)"
                            else:
                                preview = result_str
                                
                            collected_evidence.append(f"ã€è­‰æ“š {current_step}ã€‘{tool_name}\nçµæœæ‘˜è¦: {preview}")
                            
                            # Prepare prompt for next step
                            next_prompt_suffix = ""
                            if is_empty_result:
                                next_prompt_suffix = "\n\nâš ï¸ **ç³»çµ±è­¦å‘Š (Data Honesty)**ï¼šæ­¤å·¥å…·èª¿ç”¨è¿”å›äº† **ç©ºæ•¸æ“š (Empty)**ã€‚\né€™æ„å‘³è‘— TEJ æ•¸æ“šåº«ä¸­å¯èƒ½æ²’æœ‰é€™æ®µæœŸé–“çš„è³‡æ–™ã€‚\n\n**è«‹ç«‹å³åŸ·è¡Œ Fallback ç­–ç•¥**ï¼š\n1. è‹¥ä½ æ˜¯æŸ¥è©¢è‚¡åƒ¹ï¼Œè«‹æ”¹ç”¨ `twse.stock_day` (åƒæ•¸: symbol, date) æˆ– `yahoo.stock_price`ã€‚\n2. è‹¥ä½ æ˜¯æŸ¥è©¢è²¡å‹™æ•¸æ“šï¼Œè«‹å˜—è©¦èª¿æ•´æ—¥æœŸç¯„åœæˆ–æ”¹ç”¨ `searxng.search` æŸ¥æ‰¾æ–°èå ±å°ã€‚\n3. **çµ•å°ç¦æ­¢**ç·¨é€ æ•¸æ“šã€‚"

                        except Exception as e:
                            # [Error Taxonomy & Failure Mode Handling]
                            error_msg = str(e)
                            is_fatal = False
                            advice = ""
                            
                            # Check for Structured ToolError
                            if isinstance(e, ToolError):
                                error_type = e.error_type
                                meta = e.metadata
                                
                                # Failure Mode Memory Check
                                # Hash params to detect "same error + same params"
                                param_hash = hashlib.md5(json.dumps(params, sort_keys=True).encode()).hexdigest()
                                fm_key = f"{agent.name}:{tool_name}:{error_type.value}"
                                
                                if fm_key not in self._failure_memory:
                                    self._failure_memory[fm_key] = {"count": 0, "hashes": set()}
                                
                                self._failure_memory[fm_key]["count"] += 1
                                self._failure_memory[fm_key]["hashes"].add(param_hash)
                                
                                # Circuit Breaker logic
                                if self._failure_memory[fm_key]["count"] > 3:
                                    advice += "\n\nâš ï¸ ç³»çµ±è­¦å‘Šï¼šä½ å·²é€£çºŒå¤šæ¬¡é­é‡æ­¤é¡å‹éŒ¯èª¤ã€‚è«‹åœæ­¢å˜—è©¦æ­¤è·¯å¾‘ï¼Œæ”¹ç”¨å…¶ä»–åˆ†ææ–¹æ³•ã€‚"
                                
                                if error_type == TejErrorType.RECOVERABLE:
                                    advice = f"\nğŸ’¡ å»ºè­°èª¿æ•´åƒæ•¸ï¼š{meta.get('hint', 'è«‹æª¢æŸ¥åƒæ•¸æ ¼å¼')}ã€‚"
                                    if "retry_after" in meta:
                                        time.sleep(meta["retry_after"]) # Basic backoff
                                        
                                elif error_type == TejErrorType.TERMINAL:
                                    advice = "\nâ›” æ­¤éŒ¯èª¤ç‚ºçµ‚ç«¯éŒ¯èª¤ï¼ˆè³‡æ–™ä¸å­˜åœ¨æˆ–è·¯å¾‘ç„¡æ•ˆï¼‰ã€‚è«‹å‹¿å†é‡è©¦æ­¤å·¥å…·/åƒæ•¸çµ„åˆã€‚"
                                    # We could force stop tool usage here, but prompt guidance is softer first step.
                                    
                                elif error_type == TejErrorType.FATAL:
                                    advice = "\nğŸ”¥ åš´é‡éŒ¯èª¤ã€‚è«‹ç«‹å³åœæ­¢å·¥å…·èª¿ç”¨ï¼Œä¸¦å‘ä¸»å¸­å›å ±ã€‚"
                                    is_fatal = True

                            # --- Tool Name Correction Logic (Legacy Fallback) ---
                            elif "not found" in error_msg or "Tool" in error_msg:
                                all_tools = list(tool_registry.list().keys())
                                matches = []
                                fuzzy = difflib.get_close_matches(tool_name, all_tools, n=3, cutoff=0.4)
                                matches.extend(fuzzy)
                                tool_name_lower = tool_name.lower()
                                for t in all_tools:
                                    if tool_name_lower in t.lower() or t.lower() in tool_name_lower:
                                        if t not in matches: matches.append(t)
                                matches = matches[:5]
                                if matches: error_msg += f" Did you mean: {', '.join(matches)}?"
                                else: error_msg += f" Available tools: {', '.join(all_tools[:5])}..."
                            # ----------------------------------
                            
                            final_msg = f"Tool execution error: {error_msg}{advice}"
                            tool_result = {"error": final_msg}
                            print(f"ERROR: Tool {tool_name} failed: {final_msg}")
                            
                            # [Debug] Trace Tool Failure
                            self.debug_trace.append({
                                "timestamp": datetime.now().isoformat(),
                                "agent": agent.name,
                                "step": current_step,
                                "event": "TOOL_FAILURE",
                                "tool": tool_name,
                                "params": params,
                                "result": tool_result
                            })

                            # Record failed tool usage
                            try:
                                await self.tool_memory.record_async(
                                    intent=f"Debate on {self.topic}",
                                    tool_name=tool_name,
                                    params=params,
                                    result=final_msg,
                                    success=False
                                )
                            except Exception as ex:
                                print(f"Warning: Failed to record tool failure to LTM: {ex}")

                            collected_evidence.append(f"ã€è­‰æ“š {current_step}ã€‘{tool_name}\nåŸ·è¡Œå¤±æ•—: {final_msg}")
                            
                            if is_fatal:
                                # Break inner loop to force conclusion or chairman call
                                current_prompt = f"ç³»çµ±ç™¼ç”Ÿåš´é‡éŒ¯èª¤ ({error_msg})ï¼Œè«‹ç«‹å³çµ‚æ­¢èª¿æŸ¥ä¸¦å›å ±ã€‚"
                                # Force next step to be text response (conclusion)
                                # But we continue loop to let agent explain.
                        
                        # Update prompt with tool result for NEXT step
                        # Use variable next_prompt_suffix if defined (from Data Honesty Check)
                        if 'next_prompt_suffix' not in locals():
                            next_prompt_suffix = ""

                        current_prompt = f"""å·¥å…· {tool_name} çš„åŸ·è¡Œçµæœï¼š
{json.dumps(tool_result, ensure_ascii=False, indent=2)}

ã€ç³»çµ±æç¤ºã€‘
1. è«‹æª¢æŸ¥ä¸Šè¿°çµæœä¸­çš„ system_hint (è‹¥æœ‰)ã€‚
2. è‹¥ç²å¾—äº†å…¬å¸ ID/Tickerï¼Œè«‹å‹™å¿…ç¹¼çºŒèª¿ç”¨è²¡å‹™æˆ–è‚¡åƒ¹å·¥å…· (å¦‚ tej.stock_price, tej.financial_summary) ä»¥ç²å–æ·±åº¦æ•¸æ“šã€‚
3. ä¸è¦åªåœç•™åœ¨æœå°‹çµæœï¼Œè«‹æŒ–æ˜æ•¸æ“šèƒŒå¾Œçš„è¶¨å‹¢ã€‚
4. å¦‚æœè­‰æ“šå·²è¶³å¤ æ”¯æŒä½ çš„è«–é»ï¼Œè«‹è¼¸å‡ºæœ€çµ‚ç™¼è¨€ï¼ˆç´”æ–‡å­—ï¼‰ã€‚{next_prompt_suffix}
"""
                        
                        # Loop continues to next step...
                        continue

                    # Handle Error JSON
                    elif isinstance(tool_call, dict) and "error" in tool_call:
                        # ... (Existing error handling logic) ...
                        # For brevity, if error JSON, we treat as text or retry logic (omitted complex retry for now to fit structure)
                        # Let's just return it or basic text to avoid stuck loop
                        return str(tool_call)
                    
                    else:
                        # JSON found but not a tool call -> Treat as text response
                        return response

                except Exception as e:
                    print(f"Error in agent loop: {e}")
                    return response
            
            # --- Loop Limit Reached ---
            # Allow multiple extension requests (Auto-Approve first 2, then Chairman Review)
            # Limit total extensions to prevent infinite loop (e.g., max 3 times total)
            if extensions_used < 3:
                print(f"INFO: Agent {agent.name} reached step limit ({max_steps}). Offering extension ({extensions_used+1}/3).")
                self._publish_log(f"{agent.name} (System)", "âš ï¸ èª¿æŸ¥æ¬¡æ•¸å·²ç”¨ç›¡ã€‚æ­£åœ¨è©¢å•æ˜¯å¦éœ€è¦å»¶é•·èª¿æŸ¥...")
                
                # Externalized Prompt
                db = SessionLocal()
                try:
                    ext_template = PromptService.get_prompt(db, "debate.extension_option")
                    if not ext_template: ext_template = "Max steps reached. 1. Conclude. 2. Extend."
                    extension_option_prompt = ext_template.format(base_max_steps=base_max_steps, extension_steps=extension_steps)
                finally:
                    db.close()

                # Ask Agent (Bypass Semantic Cache to prevent loops)
                # We append a random nonce to context_tag or prompt to force cache miss if call_llm_async doesn't support skip_cache arg yet
                import uuid
                nonce = str(uuid.uuid4())[:8]
                decision_response = await call_llm_async(
                    extension_option_prompt,
                    system_prompt=system_prompt,
                    context_tag=f"{self.debate_id}:{agent.name}:ExtDecision:{nonce}"
                )
                
                # Check for extension request
                json_match = re.search(r'\{.*\}', decision_response, re.DOTALL)
                if json_match:
                    try:
                        req = json.loads(json_match.group(0))
                        if req.get("tool") == "request_extension":
                            reason = req.get("params", {}).get("reason", "ç„¡ç†ç”±")
                            self._publish_log(f"{agent.name} (Request)", f"ç”³è«‹å»¶é•·èª¿æŸ¥ ({extensions_used+1}/3)ï¼š{reason}")
                            
                            # [Hippocampus] Check Shared Memory first
                            self._publish_log("System", f"ğŸ§  æ­£åœ¨æŸ¥è©¢æµ·é¦¬è¿´è¨˜æ†¶ä»¥é©—è­‰å»¶é•·éœ€æ±‚...")
                            mem_results = await self.hippocampus.search_shared_memory(query=reason, limit=3)
                            
                            if "No relevant memories" not in mem_results and len(mem_results) > 50:
                                self._publish_log("System", f"âœ… æµ·é¦¬è¿´ä¸­ç™¼ç¾ç›¸é—œè³‡è¨Šï¼Œå»¶é•·ç”³è«‹è‡ªå‹•é§å›ä¸¦æä¾›è³‡è¨Šã€‚")
                                current_prompt = f"ã€ç³»çµ±æç¤ºã€‘å»¶é•·ç”³è«‹å·²è‡ªå‹•é§å›ï¼Œå› ç‚ºåœ¨å…±äº«è¨˜æ†¶ä¸­ç™¼ç¾äº†ç›¸é—œè³‡è¨Šï¼š\n\n{mem_results}\n\nè«‹åˆ©ç”¨é€™äº›è³‡è¨Šç¹¼çºŒä½ çš„è«–è¿°æˆ–ç¸½çµã€‚"
                                continue # Back to agent loop
                            
                            # --- [Optimization Phase 1] Auto-Approve Logic ---
                            should_auto_approve = False
                            deny_reason_auto = ""
                            
                            # Detect Loop: If reason is EXACTLY same as last time, deny auto-approve
                            if reason.strip() == last_extension_reason.strip():
                                self._publish_log("System (Loop Breaker)", f"ğŸ›‘ åµæ¸¬åˆ°é‡è¤‡çš„å»¶é•·ç†ç”±ï¼Œæ‹’çµ•è‡ªå‹•æ‰¹å‡†ã€‚")
                                deny_reason_auto = "ç†ç”±é‡è¤‡ (Loop Detected)"
                            # Only auto-approve first 2 times if unique
                            elif extensions_used < 2:
                                # 1. Substantiality Check
                                filler_words = ["need time", "more steps", "process", "thinking", "continue", "investigate", "research"]
                                is_only_filler = any(w in reason.lower() for w in filler_words) and len(reason) < 25
                                has_specifics = any(c.isupper() for c in reason) or any(c.isdigit() for c in reason)
                                
                                # 2. Repetition Check
                                is_repeated = (reason.strip() == last_extension_reason.strip())
                                
                                if len(reason) < 10:
                                    deny_reason_auto = "ç†ç”±éçŸ­"
                                elif is_repeated:
                                    deny_reason_auto = "ç†ç”±é‡è¤‡"
                                elif is_only_filler and not has_specifics:
                                    deny_reason_auto = "ç¼ºä¹å…·é«”ç´°ç¯€ (éœ€åŒ…å«å¯¦é«”æˆ–æ•¸æ“š)"
                                else:
                                    should_auto_approve = True
                            
                            if should_auto_approve:
                                self._publish_log("System (Auto-Approve)", f"âœ… ç³»çµ±è‡ªå‹•æ‰¹å‡†å»¶é•· (ç¬¦åˆè‡ªå‹•æ”¾è¡Œæ¨™æº–)ã€‚")
                                max_steps += extension_steps
                                extensions_used += 1
                                last_extension_reason = reason
                                current_prompt = f"ç³»çµ±å·²è‡ªå‹•æ‰¹å‡†ä½ çš„å»¶é•·ç”³è«‹ã€‚\nå¢åŠ äº† {extension_steps} æ¬¡èª¿ç”¨æ©Ÿæœƒã€‚\nè«‹ç¹¼çºŒèª¿æŸ¥ã€‚"
                                continue # Back to agent loop
                            
                            if extensions_used < 2 and not should_auto_approve:
                                self._publish_log("System (Auto-Approve)", f"âš ï¸ è‡ªå‹•æ‰¹å‡†æ‹’çµ• ({deny_reason_auto})ï¼Œè½‰äº¤ä¸»å¸­å¯©æ ¸...")

                            # --- End Auto-Approve ---

                            # Call Chairman for Review (Fallback)
                            db = SessionLocal()
                            try:
                                review_template = PromptService.get_prompt(db, "debate.chairman_review_extension")
                                # If template not found (e.g. not init yet), use fallback
                                if not review_template:
                                    review_template = """
ä½ æ˜¯ä¸»å¸­ã€‚Agent {agent_name} ç”³è«‹å»¶é•·èª¿æŸ¥ã€‚
ç†ç”±ï¼š{reason}
è­‰æ“šæ‘˜è¦ï¼š{evidence_summary}
è«‹å›å‚³ JSON: {{"approved": true/false, "reason": "...", "guidance": "..."}}
"""
                                chairman_sys = review_template.format(
                                    agent_name=agent.name, 
                                    side=side, 
                                    topic=self.topic, 
                                    reason=reason,
                                    evidence_summary="\n".join(collected_evidence)[-1000:] # Last 1000 chars
                                )
                            finally:
                                db.close()
                                
                            chairman_res = await call_llm_async("è«‹é€²è¡Œå¯©æ ¸ã€‚", system_prompt=chairman_sys, context_tag=f"{self.debate_id}:Chairman")
                            
                            # Parse Chairman Decision
                            try:
                                res_json = json.loads(re.search(r'\{.*\}', chairman_res, re.DOTALL).group(0))
                                if res_json.get("approved"):
                                    max_steps += extension_steps
                                    extensions_used += 1
                                    last_extension_reason = reason
                                    self._publish_log("Chairman (Review)", f"âœ… æ‰¹å‡†å»¶é•·ï¼š{res_json.get('reason')}")
                                    
                                    # Update prompt with guidance
                                    current_prompt = f"ä¸»å¸­å·²æ‰¹å‡†å»¶é•·èª¿æŸ¥ã€‚\næŒ‡å°ï¼š{res_json.get('guidance')}\nè«‹ç¹¼çºŒä½ çš„èª¿æŸ¥æˆ–ç™¼è¨€ã€‚"
                                    continue # Continue Outer Loop (re-enters Inner Loop with higher max_steps)
                                else:
                                    self._publish_log("Chairman (Review)", f"âŒ æ‹’çµ•å»¶é•·ï¼š{res_json.get('reason')}")
                                    current_prompt = f"ä¸»å¸­æ‹’çµ•äº†ä½ çš„ç”³è«‹ã€‚\nç†ç”±ï¼š{res_json.get('reason')}\nè«‹ç«‹å³æ ¹æ“šç¾æœ‰è³‡è¨Šç™¼è¡¨ç¸½çµã€‚"
                                    # Fall through to forced summary (or return text if agent replies text next time)
                                    # Actually, we should force summary NOW or give one last chance?
                                    # Let's give one last chance with text-only constraint.
                                    final_res = await call_llm_async(current_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}")
                                    return final_res
                                    
                            except Exception as e:
                                print(f"Error parsing chairman review: {e}")
                                # Fallback: Deny
                    except:
                        pass
                
                # If not extension request or denied/failed, return the response as text (if it's text)
                # or fallback report if it's still JSON but not extension
                if not json_match:
                    return decision_response
            
            # If reached here, it means extension denied or invalid request, break outer loop to fallback
            break
        
        # Loop ended (either max steps reached again, or denied extension)
        # FORCE A CONCLUSION: Instead of returning a system report, force the LLM to speak based on whatever it has.
        print(f"WARNING: Agent {agent.name} reached max steps ({max_steps}). Forcing conclusion.")
        
        evidence_text = "\n\n".join(collected_evidence)
        self._publish_log(f"{agent.name} (System)", f"âš ï¸ èª¿ç”¨æ¬¡æ•¸è€—ç›¡ï¼Œæ­£åœ¨å¼·åˆ¶ç”Ÿæˆç¸½çµç™¼è¨€...")
        
        force_conclusion_prompt = f"""
ã€ç³»çµ±å¼·åˆ¶æŒ‡ä»¤ã€‘
ä½ å·²ç¶“é”åˆ°å·¥å…·èª¿ç”¨æ¬¡æ•¸ä¸Šé™ï¼Œä¸èƒ½å†ä½¿ç”¨å·¥å…·äº†ã€‚
è«‹æ ¹æ“šä½ ç›®å‰å·²è’é›†åˆ°çš„è­‰æ“šï¼ˆæˆ–è‹¥ç„¡è­‰æ“šï¼Œå‰‡æ ¹æ“šä½ çš„å°ˆæ¥­çŸ¥è­˜èˆ‡é‚è¼¯æ¨æ¼”ï¼‰ï¼Œç«‹å³ç™¼è¡¨ä½ çš„æœ¬è¼ªè«–é»ã€‚

**å·²è’é›†çš„è­‰æ“šæ‘˜è¦**ï¼š
{evidence_text}

è«‹ç›´æ¥è¼¸å‡ºä½ çš„è¾¯è«–ç™¼è¨€ï¼ˆç´”æ–‡å­—ï¼‰ï¼š
"""
        try:
            # Force call without tool capability (modify system prompt? No, just strong instruction)
            # We use the same system prompt but a very strong user instruction.
            final_speech = await call_llm_async(force_conclusion_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}")
            return final_speech
        except Exception as e:
             # If even this fails, then fallback to report
             print(f"Error in forced conclusion: {e}")
             return f"(ç³»çµ±å ±å‘Šï¼šAgent åœ¨å¼·åˆ¶ç¸½çµæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè­‰æ“šå¦‚ä¸‹)\n{evidence_text}"

    async def _summarize_content(self, content: str, tool_name: str) -> str:
        """
        [Memory Management Optimization]
        Summarize large content to save tokens and prevent context window overflow.
        """
        if not content:
            return content
            
        # Threshold: 2000 chars
        if len(content) < 2000:
            return content
            
        print(f"ğŸ§  [Memory Opt] Summarizing large content from {tool_name} ({len(content)} chars)...")
        self._publish_log("System", f"ğŸ§  æ­£åœ¨ç‚ºå·¥å…· {tool_name} çš„é¾å¤§çµæœé€²è¡Œå„ªåŒ–èˆ‡æ‘˜è¦...")
        
        summary_prompt = f"""
ä½ æ˜¯ä¸€å€‹ç²¾ç°¡çš„è³‡æ–™åˆ†æåŠ©æ‰‹ã€‚è«‹å°‡ä»¥ä¸‹å¾å·¥å…· `{tool_name}` ç²å–çš„åŸå§‹è³‡æ–™ï¼Œåœ¨ä¿ç•™æ‰€æœ‰æ ¸å¿ƒäº‹å¯¦ã€æ•¸æ“šã€æ—¥æœŸèˆ‡å¯¦é«”ï¼ˆå…¬å¸å/ä»£è™Ÿï¼‰çš„å‰æä¸‹ï¼Œé€²è¡Œæ¥µé™å£“ç¸®ã€‚

**åŸå§‹è³‡æ–™ (éƒ¨åˆ†é¡¯ç¤º)**:
{content[:8000]}

**è¦æ±‚**:
1. åƒ…ä¿ç•™å°è¾¯è«–ã€Œ{self.topic}ã€æœ‰é‚Šéš›åƒ¹å€¼çš„è³‡è¨Šã€‚
2. è¼¸å‡ºæ ¼å¼å¿…é ˆç‚ºæ¢åˆ—å¼ï¼Œä¸”ç¸½é•·åº¦ä¸è¶…é 800 å­—ã€‚
3. è‹¥åŒ…å«è‚¡åƒ¹æˆ–è²¡å‹™æ•¸æ“šï¼Œè«‹ä¿ç•™æœ€æ–°çš„æ•¸å€¼ã€‚

æ‘˜è¦å…§å®¹ï¼š
"""
        try:
            summary = await call_llm_async(summary_prompt, system_prompt="ä½ æ˜¯é«˜æ•ˆèƒ½è³‡æ–™éæ¿¾å™¨ã€‚")
            return f"{summary}\n\n[è¨»ï¼šåŸå§‹è³‡æ–™å·²æˆªæ–·ä¸¦ç”±ç³»çµ±æ‘˜è¦ï¼ŒåŸå§‹é•·åº¦ï¼š{len(content)} å­—å…ƒ]"
        except Exception as e:
            print(f"Warning: Summarization failed: {e}")
            return content[:3000] + "... [æ‘˜è¦å¤±æ•—ï¼Œç³»çµ±è‡ªå‹•æˆªæ–·]"

    async def _request_chairman_tool_approval(self, agent: AgentBase, tool_name: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """
        [Governance Gate]
        Request explicit approval from Chairman for high-cost tools.
        """
        justification = params.get("justification", "Agent æœªæä¾›æ˜ç¢ºç†ç”±")
        url_hint = params.get("url", "")
        
        # --- [Governance Gate] Pre-check for Browse tools ---
        if tool_name.startswith("browser."):
            # 1. Check Quota
            if self.browse_quota <= 0:
                self._publish_log("Governance", f"ğŸ›‘ è‡ªå‹•é§å›ï¼šç›®å‰ç„¡ç€è¦½é…é¡ã€‚è«‹å…ˆèª¿ç”¨æœå°‹å·¥å…·ä»¥ç²å–é…é¡ã€‚")
                return {"approved": False, "reason": "ç„¡ç€è¦½é…é¡", "guidance": "æ¯æ¬¡æœå°‹åƒ…ç²å¾—ä¸€æ¬¡ç²¾æº–ç€è¦½æ©Ÿæœƒã€‚è«‹å…ˆé€²è¡Œæœå°‹ã€‚"}
            
            # 2. Check URL Discovery (Strict Allowlist)
            if url_hint and url_hint not in self.discovered_urls:
                self._publish_log("Governance", f"ğŸ›‘ è‡ªå‹•é§å›ï¼šç¶²å€æœªè¢«é©—è­‰ã€‚Agent åªèƒ½è¨ªå•æœå°‹çµæœä¸­å­˜åœ¨çš„ URLã€‚")
                return {"approved": False, "reason": "ç¶²å€æœªç¶“æœå°‹ç™¼ç¾", "guidance": "å®‰å…¨é™åˆ¶ï¼šä½ åªèƒ½èª¿ç”¨ç¶“ç”±æœå°‹å¼•æ“ç™¼ç¾çš„åˆæ³• URLã€‚"}

        self._publish_log("Governance", f"ğŸ›¡ï¸ æ””æˆªåˆ°å—é™å·¥å…·èª¿ç”¨ï¼š{tool_name}ã€‚æ­£åœ¨è«‹æ±‚ä¸»å¸­æ ¸å‡†...")
        self._publish_log("Agent", f"ğŸ™‹ {agent.name} ç”³è«‹ä½¿ç”¨ {tool_name}ï¼šã€{justification}ã€" + (f" (ç›®æ¨™: {url_hint})" if url_hint else ""))
        
        db = SessionLocal()
        try:
            template = """
ä½ æ˜¯è¾¯è«–ä¸»å¸­ã€‚ç›®å‰è¾¯æ‰‹ {agent_name} ç”³è«‹ä½¿ç”¨é«˜æˆæœ¬å·¥å…· `{tool_name}`ã€‚

**è¾¯é¡Œ**: {topic}
**ç”³è«‹ç†ç”±**: {justification}
**ç›®æ¨™/åƒæ•¸**: {params}

**ä¸»å¸­è·è²¬**:
1. ç¢ºä¿é–±è®€è©²ç¶²é æ˜¯æœ‰æ•ˆç›Šä¸”å…·é—œè¯æ€§çš„ã€‚
2. éµå®ˆã€Œæ¯æ¬¡æœå°‹åƒ…ç²å¾—ä¸€æ¬¡ç€è¦½é…é¡ã€çš„é™åˆ¶ã€‚
3. è©•ä¼°è©²ç¶²å€æ˜¯å¦å€¼å¾—æ¶ˆè€—ç›®å‰å¯¶è²´çš„ç€è¦½é…é¡ï¼ˆå‰©é¤˜é…é¡ï¼š{quota}ï¼‰ã€‚
4. è‹¥ç†ç”±ä¸è¶³ä»¥èªªæœä½ ï¼Œè«‹äºˆé§å›ä¸¦çµ¦äºˆæŒ‡å°ã€‚

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼š
{{
  "approved": true/false,
  "reason": "æ ¸å‡†æˆ–é§å›çš„å…·é«”ç†ç”±",
  "guidance": "çµ¦è¾¯æ‰‹çš„é€²ä¸€æ­¥æŒ‡å°å»ºè­°"
}}
"""
            review_prompt = template.format(
                agent_name=agent.name,
                tool_name=tool_name,
                topic=self.topic,
                justification=justification,
                params=json.dumps(params, ensure_ascii=False),
                quota=self.browse_quota
            )
        finally:
            db.close()
            
        try:
            response = await call_llm_async(review_prompt, system_prompt="ä½ æ˜¯åš´æ ¼ä¸”å…¬æ­£çš„è¾¯è«–ä¸»å¸­ï¼Œè² è²¬è³‡æºåˆ†é…èˆ‡å“è³ªæ§ç®¡ã€‚", context_tag=f"{self.debate_id}:Chairman")
            decision = json.loads(re.search(r'\{.*\}', response, re.DOTALL).group(0))
            
            if decision.get("approved"):
                self._publish_log("Chairman", f"âœ… æ ¸å‡†èª¿ç”¨ {tool_name}ï¼š{decision.get('reason')}")
                if tool_name.startswith("browser."):
                    self.browse_quota -= 1 # [Governance] Consume Quota
                    self._publish_log("System", f"ğŸ“‰ ç€è¦½é…é¡å·²æ¶ˆè€—ã€‚å‰©é¤˜é…é¡ï¼š{self.browse_quota}")
            else:
                self._publish_log("Chairman", f"ğŸ›‘ é§å›èª¿ç”¨ {tool_name}ï¼š{decision.get('reason')}")
                
            return decision
        except Exception as e:
            print(f"Error in Chairman tool approval: {e}")
            return {"approved": False, "reason": "ç³»çµ±å¯©æ ¸ç™¼ç”Ÿç•°å¸¸", "guidance": "è«‹æ”¹ç”¨å…¶ä»–æ›¿ä»£æ–¹æ¡ˆã€‚"}
    def _extract_urls(self, data: Any) -> List[str]:
        """
        [Governance] Extract URLs from search results to build the allowlist.
        Recursively walks through dicts and lists to find URLs.
        """
        urls = set()
        # Pattern to capture clean URLs
        url_pattern = re.compile(r'https?://[^\s<>"\'\(\)\[\]]+')

        def walk(node: Any):
            if isinstance(node, str):
                for match in url_pattern.findall(node):
                    # Basic cleaning: remove trailing punctuation that might be picked up
                    clean_url = match.rstrip('.,;:!?')
                    urls.add(clean_url)
            elif isinstance(node, dict):
                for key, val in node.items():
                    # Optimization: 'url' keys are highly likely to be valid targets
                    if key == "url" and isinstance(val, str) and val.startswith("http"):
                        urls.add(val.rstrip('.,;:!?'))
                    else:
                        walk(val)
            elif isinstance(node, list):
                for item in node:
                    walk(item)

        if data:
            walk(data)
        return list(urls)
