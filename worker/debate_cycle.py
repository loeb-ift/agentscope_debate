from typing import List, Dict, Any
from worker.chairman import Chairman
from agentscope.agent import AgentBase
import json
import re
import os
import sys
import yaml
import asyncio
import resource
import difflib
from datetime import datetime
from worker.llm_utils import call_llm, call_llm_async
from worker.tool_config import get_tools_description, get_tools_examples, STOCK_CODES, CURRENT_DATE
from api.prompt_service import PromptService
from api.database import SessionLocal
from worker.memory import ReMePersonalLongTermMemory, ReMeTaskLongTermMemory, ReMeToolLongTermMemory, ReMeHistoryMemory, HippocampalMemory
from api.tool_registry import tool_registry
from api.toolset_service import ToolSetService
from api.redis_client import get_redis_client
from api import models

class DebateCycle:
    """
    ç®¡ç†æ•´ä¸ªè¾©è®ºå¾ªç¯ï¼ŒåŒ…æ‹¬ä¸»å¸­å¼•å¯¼ã€æ­£åæ–¹å‘è¨€å’Œæ€»ç»“ã€‚
    """

    def __init__(self, debate_id: str, topic: str, chairman: Chairman, teams: List[Dict], rounds: int):
        self.debate_id = debate_id
        self.topic = topic
        self.chairman = chairman
        self.teams = teams # List of dicts: [{"name": "...", "side": "...", "agents": [AgentBase...]}]
        self.rounds = rounds
        self.redis_client = get_redis_client()
        self.evidence_key = f"debate:{self.debate_id}:evidence"
        self.rounds_data = []
        self.analysis_result = {}
        self.history = []
        self.full_history = []  # å®Œæ•´æ­·å²è¨˜éŒ„ï¼ˆä¸å£“ç¸®ï¼Œç”¨æ–¼å ±å‘Šï¼‰
        self.compressed_history = "ç„¡"  # å­˜å„² LLM å£“ç¸®å¾Œçš„æ­·å²æ‘˜è¦ (Legacy)
        self.archived_summaries = [] # List of structured summaries
        self.agent_tools_map = {} # å­˜å„²æ¯å€‹ Agent é¸æ“‡çš„å·¥å…·åˆ—è¡¨
        self.hippocampus = HippocampalMemory(debate_id) # Init Hippocampal Memory

    def _get_memory_usage(self) -> str:
        """ç²å–ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨é‡ (MB)"""
        try:
            usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
            # MacOS: bytes, Linux: KB
            if sys.platform == 'darwin':
                return f"{usage / 1024 / 1024:.2f} MB"
            return f"{usage / 1024:.2f} MB"
        except Exception:
            return "N/A"

    def _publish_log(self, role: str, content: str):
        """
        ç™¼å¸ƒæ—¥èªŒåˆ° Redisï¼Œä¾›å‰ç«¯ SSE è¨‚é–±ã€‚
        """
        message = json.dumps({"role": role, "content": content}, ensure_ascii=False)
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", message)

    def _publish_progress(self, percentage: int, message: str, stage: str = "setup"):
        """
        ç™¼å¸ƒé€²åº¦æ›´æ–°äº‹ä»¶ï¼Œä¾›å‰ç«¯é¡¯ç¤ºé€²åº¦æ¢ã€‚
        """
        event_data = {
            "type": "progress_update",
            "progress": percentage,
            "message": message,
            "stage": stage,
            "timestamp": datetime.now().isoformat()
        }
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", json.dumps(event_data, ensure_ascii=False))

    def _save_report_to_file(self, conclusion: str, jury_report: str = None, start_time: datetime = None, end_time: datetime = None):
        """
        å°‡è¾¯è«–éç¨‹ä¿å­˜ç‚º Markdown æ–‡ä»¶ã€‚
        """
        import re
        from datetime import datetime
        
        report_dir = "data/replays"
        os.makedirs(report_dir, exist_ok=True)
        
        # æ¸…ç†é¡Œç›®ï¼Œç§»é™¤éæ³•æ–‡ä»¶åå­—ç¬¦
        safe_topic = re.sub(r'[<>:"/\\|?*]', '', self.topic)
        safe_topic = safe_topic.replace(' ', '_')[:50]  # é™åˆ¶é•·åº¦
        
        # ç”Ÿæˆæ™‚é–“æˆ³ï¼ˆå¯è®€æ ¼å¼ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # çµ„åˆæª”åï¼šé¡Œç›®_æ™‚é–“.md
        filename = f"{safe_topic}_{timestamp}.md"
        filepath = os.path.join(report_dir, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"# è¾¯è«–å ±å‘Šï¼š{self.topic}\n\n")
            f.write(f"**ID**: {self.debate_id}\n")
            f.write(f"**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ğŸ† æœ€çµ‚çµè«–\n\n")
            f.write(f"{conclusion}\n\n")

            if jury_report:
                f.write("## âš–ï¸ è©•å¯©åœ˜è©•ä¼°å ±å‘Š\n\n")
                f.write(f"{jury_report}\n\n")
            
            f.write("## ğŸ“ è¾¯è«–éç¨‹è¨˜éŒ„\n\n")
            for item in self.full_history:
                role = item.get("role", "Unknown")
                content = item.get("content", "")
                f.write(f"### {role}\n")
                f.write(f"{content}\n\n")
                f.write("---\n\n")
            
            # Duration Stats
            if start_time and end_time:
                duration = end_time - start_time
                f.write("## â±ï¸ çµ±è¨ˆè³‡è¨Š\n")
                f.write(f"- **é–‹å§‹æ™‚é–“**: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- **çµæŸæ™‚é–“**: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- **ç¸½è€—æ™‚**: {str(duration).split('.')[0]}\n")
                
        print(f"Report saved to {filepath}")

    def start(self) -> Dict[str, Any]:
        """
        å¼€å§‹è¾©è®ºå¾ªç¯ (Sync wrapper around async start).
        """
        return asyncio.run(self.start_async())

    async def start_async(self) -> Dict[str, Any]:
        """
        å¼€å§‹è¾©è®ºå¾ªç¯ (Async).
        """
        start_time = datetime.now()
        print(f"Debate '{self.debate_id}' has started. Mem: {self._get_memory_usage()}")
        self._publish_log("System", f"Debate '{self.debate_id}' has started.")
        self._publish_progress(5, "åˆå§‹åŒ–è¾¯è«–ç’°å¢ƒ...", "init")
        
        # 0. è³½å‰åˆ†æ
        # Check Task LTM for similar past debates
        # [OPTIONAL] Disabled to avoid cold-start issues if not required
        # task_mem = ReMeTaskLongTermMemory()
        # similar_tasks = await task_mem.retrieve_similar_tasks_async(self.topic)
        # if similar_tasks:
        #     print(f"DEBUG: Found similar past debates:\n{similar_tasks}")
        #     self._publish_log("System", f"Found similar past debates:\n{similar_tasks}")

        self._publish_progress(10, "ä¸»å¸­æ­£åœ¨é€²è¡Œè³½å‰åˆ†æ...", "analysis")
        
        # Note: Chairman analysis is still sync for now as it's complex, but could be made async too.
        self.analysis_result = self.chairman.pre_debate_analysis(self.topic)
        summary = self.analysis_result.get('step5_summary', 'ç„¡')
        self.chairman.speak(f"è³½å‰åˆ†æå®Œæˆã€‚æˆ°ç•¥æ‘˜è¦ï¼š{summary}")
        self._publish_log("Chairman (Analysis)", f"è³½å‰åˆ†æå®Œæˆã€‚\næˆ°ç•¥æ‘˜è¦ï¼š{summary}")
        
        self._publish_progress(30, "åˆ†æå®Œæˆï¼Œæº–å‚™ Agent å·¥å…·...", "tool_selection")
        
        # 1. Agent å‹•æ…‹é¸æ“‡å·¥å…· (Initialization Phase)
        print("Agents are selecting their tools...")
        self._publish_log("System", "ğŸ¯ è¾¯è«–æº–å‚™éšæ®µï¼šå„ Agent æ­£åœ¨é¸æ“‡æœ€é©åˆçš„å·¥å…·...")
        
        total_agents = sum(len(team['agents']) for team in self.teams)
        if total_agents == 0:
            total_agents = 1 # Avoid division by zero
        
        # Run tool selection sequentially
        self._publish_log("System", f"ğŸš€ å•Ÿå‹• {total_agents} å€‹ Agent é †åºå·¥å…·é¸æ“‡...")
        
        agent_processed_count = 0
        for team in self.teams:
            side = team.get('side', 'neutral')
            for agent in team['agents']:
                 await self._agent_select_tools_async(agent, side)
                 agent_processed_count += 1
                 # Calculate progress from 30% to 90%
                 progress = 30 + int((agent_processed_count / total_agents) * 60)
                 self._publish_progress(progress, f"Agent {agent.name} å·¥å…·é…ç½®å®Œæˆ ({agent_processed_count}/{total_agents})", "tool_selection")

        self._publish_log("System", "âœ… æ‰€æœ‰ Agent å·¥å…·é¸æ“‡å®Œæˆã€‚")
        self._publish_progress(100, "æº–å‚™å°±ç·’ï¼Œè¾¯è«–é–‹å§‹ï¼", "start")

        
        for i in range(1, self.rounds + 1):
            print(f"--- Round {i} --- (Mem: {self._get_memory_usage()})")
            self._publish_log("System", f"--- Round {i} ---")
            round_result = await self._run_round_async(i)
            self.rounds_data.append(round_result)
        
        # 4. æœ€çµ‚ç¸½çµ
        handcard = self.analysis_result.get('step6_handcard') or self.analysis_result.get('step5_summary', 'ç„¡æ‰‹å¡')
        final_conclusion = self.chairman.summarize_debate(self.debate_id, self.topic, self.rounds_data, handcard)
        self._publish_log("Chairman (Conclusion)", final_conclusion)

        # 5. Jury è©•ä¼°
        jury_report = self._run_jury_evaluation(final_conclusion)

        # Record outcome to Task LTM
        # [OPTIONAL] Disabled as debates are independent and history is not required
        # task_mem = ReMeTaskLongTermMemory()
        # await task_mem.record_async(self.topic, final_conclusion)
        
        end_time = datetime.now()
        # Save to File (Markdown Report)
        self._save_report_to_file(final_conclusion, jury_report, start_time, end_time)

        print(f"Debate '{self.debate_id}' has ended.")
        self._publish_log("System", f"Debate '{self.debate_id}' has ended.")
        
        # [CLEANUP] Clear Semantic Cache for this debate
        try:
            from api.vector_store import VectorStore
            await VectorStore.delete_by_filter(
                collection_name="llm_semantic_cache",
                filter_conditions={"context": self.debate_id}
            )
            print(f"DEBUG: Cleared semantic cache for debate {self.debate_id}")
        except Exception as e:
            print(f"WARNING: Failed to clear semantic cache: {e}")

        # Send explicit DONE signal to close the stream
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", "[DONE]")
        
        return {
            "topic": self.topic,
            "rounds_data": self.rounds_data,
            "analysis": self.analysis_result,
            "final_conclusion": final_conclusion,
            "jury_report": jury_report
        }

    def _run_jury_evaluation(self, final_conclusion: str) -> str:
        """
        åŸ·è¡Œè©•å¯©åœ˜ (Jury) è©•ä¼°ï¼Œç”Ÿæˆè©•åˆ†èˆ‡åˆ†æå ±å‘Šã€‚
        """
        print("Jury is evaluating the debate...")
        self._publish_log("System", "è©•å¯©åœ˜æ­£åœ¨é€²è¡Œæœ€çµ‚è©•ä¼°...")

        try:
            # Load Jury System Prompt
            file_system_prompt = "ä½ æ˜¯è¾¯è«–è©•å¯©åœ˜ã€‚"
            try:
                with open("prompts/agents/jury.yaml", "r", encoding="utf-8") as f:
                    jury_config = yaml.safe_load(f)
                    file_system_prompt = jury_config.get("system_prompt", file_system_prompt)
            except Exception as e:
                print(f"Warning: Failed to load jury.yaml: {e}")

            db = SessionLocal()
            try:
                system_prompt = PromptService.get_prompt(db, "jury.system_prompt", default=file_system_prompt)
                
                # Load User Prompt Template (Moved from hardcoded)
                user_template = PromptService.get_prompt(db, "debate.jury_evaluation_user")
                if not user_template:
                    user_template = "è«‹è©•ä¼°ä»¥ä¸‹è¾¯è«–ï¼š\n{debate_log}" # Minimal fallback
            finally:
                db.close()
            
            # æ§‹å»ºå®Œæ•´è¾¯è«–è¨˜éŒ„æ–‡å­—
            debate_log = ""
            for item in self.full_history:
                role = item.get("role", "Unknown")
                content = item.get("content", "")
                debate_log += f"[{role}]: {content}\n\n"
                
            debate_log += f"[Chairman Final Conclusion]: {final_conclusion}\n"

            # Fill template
            user_prompt = user_template.format(topic=self.topic, debate_log=debate_log)

            # Call LLM
            jury_report = call_llm(user_prompt, system_prompt=system_prompt)
            # Note: Sync call_llm doesn't support context_tag yet, but jury uses sync wrapper?
            # Wait, `call_llm` is sync. `_run_jury_evaluation` uses `call_llm` (sync).
            # The async `call_llm_async` supports context_tag.
            # I should update `call_llm` (sync) to support context_tag?
            # Or just update the async calls.
            # `_run_jury_evaluation` is SYNC method.
            
            self._publish_log("Jury", jury_report)
            print("Jury evaluation completed.")
            return jury_report
            
        except Exception as e:
            error_msg = f"Jury evaluation failed: {str(e)}"
            print(error_msg)
            self._publish_log("System", error_msg)
            return error_msg

    def _update_team_score(self, side: str, delta: float, reason: str):
        """
        æ›´æ–°åœ˜éšŠè©•åˆ†ä¸¦æ¨é€é€šçŸ¥ã€‚
        """
        score_key = f"debate:{self.debate_id}:scores"
        # Initial scores if not set (default 100)
        if not self.redis_client.hexists(score_key, side):
            self.redis_client.hset(score_key, side, 100.0)
        
        new_score = self.redis_client.hincrbyfloat(score_key, side, delta)
        
        # Publish score update event
        event_data = {
            "type": "score_update",
            "side": side,
            "new_score": new_score,
            "delta": delta,
            "reason": reason,
            "timestamp": datetime.now().isoformat()
        }
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", json.dumps(event_data, ensure_ascii=False))
        self._publish_log("System (Score)", f"âš–ï¸ ã€{side}ã€‘åˆ†æ•¸è®Šæ›´: {delta} ({reason}) => ç•¶å‰åˆ†æ•¸: {new_score}")

    def _neutral_verification_turn(self, agent: AgentBase, team_name: str, round_num: int) -> str:
        return asyncio.run(self._neutral_verification_turn_async(agent, team_name, round_num))

    async def _neutral_verification_turn_async(self, agent: AgentBase, team_name: str, round_num: int) -> str:
        """
        ä¸­ç«‹æ–¹çš„ç‰¹æ®Šå›åˆï¼šæ ¸å¯¦è­‰æ“šä¸¦é€²è¡Œè©•åˆ† (Async)ã€‚
        """
        print(f"Neutral Agent {agent.name} is verifying evidence...")
        self._publish_log(f"{agent.name} (Verification)", "ğŸ” æ­£åœ¨å¯©æŸ¥å„æ–¹æå‡ºçš„è­‰æ“šé€²è¡Œæ ¸å¯¦...")

        # 1. Fetch unverified evidence from Redis
        all_evidence = [json.loads(e) for e in self.redis_client.lrange(self.evidence_key, 0, -1)]
        # Filter: from current round (or previous), not neutral, not verified
        target_evidence = [e for e in all_evidence if e.get('side') != 'neutral' and not e.get('verified', False)]
        
        verification_report = ""
        
        if not target_evidence:
            return await self._agent_turn_async(agent, 'neutral', round_num) # Fallback to normal turn if no evidence

        # 2. Verify each evidence (Limit to 1-2 to save time/cost)
        for ev in target_evidence[:2]:
            tool_name = ev.get('tool')
            params = ev.get('params')
            original_result = ev.get('result')
            provider_side = ev.get('side', 'Unknown')
            
            self._publish_log(f"{agent.name} (Verification)", f"æ­£åœ¨æ ¸å¯¦ {provider_side} æ–¹ä½¿ç”¨çš„å·¥å…·: {tool_name}...")
            
            try:
                # Re-execute tool
                from worker.tool_invoker import call_tool
                # Execute sync tool in thread pool
                loop = asyncio.get_running_loop()
                verify_result = await loop.run_in_executor(None, call_tool, tool_name, params)
                
                # Construct verification prompt via PromptService
                db = SessionLocal()
                try:
                    comp_template = PromptService.get_prompt(db, "neutral.verification_comparison")
                    if not comp_template:
                        comp_template = "è«‹æ¯”è¼ƒï¼š\nåŸï¼š{original_result_preview}\næ–°ï¼š{verify_result_preview}\nJSON: {{consistent: bool}}"
                finally:
                    db.close()

                comparison_prompt = comp_template.format(
                    tool_name=tool_name,
                    params=params,
                    provider_side=provider_side,
                    original_result_preview=str(original_result)[:1000],
                    verify_result_preview=str(verify_result)[:1000]
                )

                # Call LLM for judgement
                judge_response = await call_llm_async(comparison_prompt, system_prompt="ä½ æ˜¯å…¬æ­£çš„æ•¸æ“šæ ¸å¯¦å“¡ã€‚", context_tag=f"{self.debate_id}:{agent.name}:Verification")
                
                # Parse JSON
                try:
                    # Robust JSON extraction
                    json_match = re.search(r'\{.*\}', judge_response, re.DOTALL)
                    if json_match:
                        judge_json = json.loads(json_match.group(0))
                        
                        consistent = judge_json.get('consistent', True)
                        penalty = judge_json.get('score_penalty', 0)
                        comment = judge_json.get('comment', '')
                        
                        if consistent:
                            verification_report += f"- âœ… æ ¸å¯¦é€šé ({tool_name}): æ•¸æ“šä¸€è‡´ã€‚\n"
                        else:
                            verification_report += f"- âŒ æ ¸å¯¦å¤±æ•— ({tool_name}): {comment} (æ‰£åˆ†: {penalty})\n"
                            if penalty < 0:
                                self._update_team_score(provider_side, float(penalty), f"è­‰æ“šæ ¸å¯¦å¤±æ•—: {comment}")
                    else:
                        verification_report += f"- âš ï¸ ç„¡æ³•åˆ¤æ–· ({tool_name}): {judge_response[:50]}\n"

                except Exception as e:
                    print(f"Verification judgment parsing error: {e}")
                    verification_report += f"- âš ï¸ æ ¸å¯¦åˆ¤è®€éŒ¯èª¤ ({tool_name})\n"

            except Exception as e:
                verification_report += f"- âš ï¸ å·¥å…·é‡è·‘å¤±æ•— ({tool_name}): {e}\n"

        # 3. Generate Speech based on verification
        db = SessionLocal()
        try:
            final_template = PromptService.get_prompt(db, "neutral.verification_speech")
            if not final_template:
                final_template = "ä½ æ˜¯ä¸­ç«‹æ–¹ã€‚è«‹æ ¹æ“šæ ¸å¯¦å ±å‘Šç™¼è¨€ï¼š{verification_report}"
        finally:
            db.close()

        final_prompt = final_template.format(
            agent_name=agent.name,
            round_num=round_num,
            verification_report=verification_report
        )
        
        response = await call_llm_async(final_prompt, system_prompt=f"ä½ æ˜¯ {agent.name}ï¼Œå…¬æ­£çš„ç¬¬ä¸‰æ–¹ã€‚", context_tag=f"{self.debate_id}:{agent.name}:Speech")
        return response

    def _run_round(self, round_num: int) -> Dict[str, Any]:
         """Sync wrapper around async _run_round_async"""
         return asyncio.run(self._run_round_async(round_num))

    async def _run_round_async(self, round_num: int) -> Dict[str, Any]:
        """
        è¿è¡Œä¸€è½®è¾©è®º (Async, Parallel Team Execution).
        åŒ…å«ï¼šå„åœ˜éšŠå…§éƒ¨è¨è«– (Parallel) -> åœ˜éšŠç¸½çµ -> ä¸»å¸­å½™æ•´èˆ‡ä¸‹ä¸€è¼ªå¼•å°
        """
        from worker import tasks # Lazy import to avoid circular dependency
        
        # 1. ä¸»å¸­å¼•å¯¼
        opening = f"ç°åœ¨é–‹å§‹ç¬¬ {round_num} è¼ªè¾¯è«–ã€‚"
        self.chairman.speak(opening)
        self.history.append({"role": "Chairman", "content": opening})
        self.full_history.append({"role": "Chairman", "content": opening})
        self._publish_log("Chairman", opening)

        # 2. å„åœ˜éšŠå…§éƒ¨è¾¯è«–èˆ‡ç¸½çµ (Intra-Team Debate & Summary)
        round_team_summaries = {}
        
        total_teams = len(self.teams)
        
        # Run all teams sequentially
        self._publish_log("System", f"ğŸš€ å•Ÿå‹• {total_teams} éšŠé †åºè¨è«–...")
        team_results = []
        for team in self.teams:
            result = await self._process_team_deliberation(team, round_num)
            team_results.append(result)
        
        # Process results from all teams
        for team_result in team_results:
            team_name = team_result['name']
            team_summary = team_result['summary']
            discussion_log = team_result['log']
            
            round_team_summaries[team_name] = team_summary
            
            # Store history (Note: Order might be mixed in real-time logs, but here we append block by block)
            # Ideally, we want to interleave them in history based on timestamp, but for simplicity:
            for item in discussion_log:
                 self.history.append(item)
                 self.full_history.append(item)
                 # RAG Recording
                 rag = ReMeHistoryMemory(self.debate_id)
                 await rag.add_turn_async(item['role'], str(item['content']), round_num)
            
            self.history.append({"role": f"{team_name} Summary", "content": team_summary})
            self.full_history.append({"role": f"{team_name} Summary", "content": team_summary})
            
            rag = ReMeHistoryMemory(self.debate_id)
            await rag.add_turn_async(f"{team_name} Summary", team_summary, round_num)
            
        # [Hippocampus] Trigger Memory Consolidation
        self._publish_log("System", "ğŸ§  æ­£åœ¨é€²è¡Œæµ·é¦¬é«”è¨˜æ†¶éå›º (Consolidating Working Memory)...")
        await self.hippocampus.consolidate()

        # [Hippocampus] Trigger Memory Consolidation
        self._publish_log("System", "ğŸ§  æ­£åœ¨é€²è¡Œæµ·é¦¬é«”è¨˜æ†¶éå›º (Consolidating Working Memory)...")
        await self.hippocampus.consolidate()

        # 3. ä¸»å¸­å½™æ•´èˆ‡ä¸‹ä¸€è¼ªæ–¹å‘
        handcard = self.analysis_result.get('step6_handcard') or self.analysis_result.get('step5_summary', 'ç„¡æ‰‹å¡')
        
        # è‡¨æ™‚æ–¹æ¡ˆï¼šå°‡ team_summaries å¯«å…¥ Redis evidenceï¼Œè®“ä¸»å¸­è®€å–åˆ°
        for t_name, t_summary in round_team_summaries.items():
            summary_evidence = {
                "role": f"{t_name} Summary",
                "content": t_summary,
                "type": "team_summary"
            }
            self.redis_client.rpush(self.evidence_key, json.dumps(summary_evidence, ensure_ascii=False))
            
        next_direction = self.chairman.summarize_round(self.debate_id, round_num, handcard=handcard)
        self._publish_log("Chairman", f"Round {round_num} summary completed. Next Direction: {next_direction}")
        
        # å°‡ä¸‹ä¸€è¼ªæ–¹å‘åŠ å…¥æ­·å²ï¼Œä¾›ä¸‹ä¸€è¼ª Agent åƒè€ƒ
        self.history.append({"role": "Chairman (Next Direction)", "content": next_direction})
        self.full_history.append({"role": "Chairman (Next Direction)", "content": next_direction})
        
        return {
            "round": round_num,
            "team_summaries": round_team_summaries,
            "next_direction": next_direction
        }
        
    async def _process_team_deliberation(self, team: Dict, round_num: int) -> Dict[str, Any]:
        """
        Process a single team's deliberation asynchronously.
        """
        team_name = team['name']
        team_side = team.get('side', 'neutral')
        team_agents = team['agents']
        total_agents_in_team = len(team_agents)
        
        team_icon = "ğŸŸ¦" if team_side == "pro" else "ğŸŸ¥" if team_side == "con" else "ğŸŸ©"
        self._publish_log("System", f"{team_icon} ã€{team_name}ã€‘é–‹å§‹å…§éƒ¨è¨è«–...")
        
        team_discussion_log_text = [] # For summary generation
        team_history_entries = [] # For returning to main thread
        
        # Within a team, agents might still need to speak in order, OR parallel?
        # Usually debate implies responding to each other.
        # However, "Intra-Team Debate" in this simplified version is just each agent speaking once.
        # We can make agents within a team parallel too!
        
        agent_results = []
        for agent in team_agents:
            if team_side == "neutral":
                 content = await self._neutral_verification_turn_async(agent, team_name, round_num)
            else:
                 content = await self._agent_turn_async(agent, team_name, round_num)
            agent_results.append(content)
        
        for idx, (agent, content) in enumerate(zip(team_agents, agent_results)):
             role_label = f"{team_name} - {agent.name}"
             
             entry = {"role": role_label, "content": content}
             team_history_entries.append(entry)
             team_discussion_log_text.append(f"{agent.name}: {content}")
             
             # Publish individual log (Note: Might arrive out of order visually if not carefully handled on frontend,
             # but here we publish as soon as done)
             self._publish_log(role_label, content)

        # ç”Ÿæˆåœ˜éšŠå…±è­˜èˆ‡åˆ†æ­§ç¸½çµ
        self._publish_log("System", f"ğŸ“Š {team_name} æ­£åœ¨æ•´ç†åœ˜éšŠå…±è­˜...")
        team_summary = await self._generate_team_summary_async(team_name, team_discussion_log_text)
        self._publish_log(f"{team_name} (Summary)", team_summary)
        
        return {
            "name": team_name,
            "summary": team_summary,
            "log": team_history_entries
        }

    def _generate_team_summary(self, team_name: str, discussion_log: List[str]) -> str:
         return asyncio.run(self._generate_team_summary_async(team_name, discussion_log))

    async def _generate_team_summary_async(self, team_name: str, discussion_log: List[str]) -> str:
        """
        ç”Ÿæˆåœ˜éšŠå…§éƒ¨çš„å…±è­˜èˆ‡åˆ†æ­§ç¸½çµ (Async).
        """
        discussion_text = "\n".join(discussion_log)
        
        db = SessionLocal()
        try:
            sys_template = PromptService.get_prompt(db, "debate.team_summary_system")
            if not sys_template: sys_template = "Summarize team discussion."
            system_prompt = sys_template.format(team_name=team_name)

            user_template = PromptService.get_prompt(db, "debate.team_summary_user")
            if not user_template: user_template = "{discussion_text}"
            user_prompt = user_template.format(discussion_text=discussion_text)
        finally:
            db.close()
            
        return await call_llm_async(user_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:TeamSummary:{team_name}")

    def _agent_select_tools(self, agent: AgentBase, side: str):
         """Sync wrapper for backward compatibility"""
         return asyncio.run(self._agent_select_tools_async(agent, side))

    async def _agent_select_tools_async(self, agent: AgentBase, side: str):
        """
        Agent åœ¨è¾¯è«–é–‹å§‹å‰å‹•æ…‹é¸æ“‡æœ€é©åˆçš„å·¥å…· (Async).
        """
        db = SessionLocal()
        try:
            # ç²å–è©² Agent å¯ç”¨çš„å·¥å…·åˆ—è¡¨ (å¾ DB ToolSet)
            agent_id = getattr(agent, 'id', None)
            if not agent_id:
                # å˜—è©¦å¾ DB æŸ¥æ‰¾
                db_agent = db.query(models.Agent).filter(models.Agent.name == agent.name).first()
                if db_agent:
                    agent_id = db_agent.id
            
            if agent_id:
                available_tools_list = ToolSetService.get_agent_available_tools(db, agent_id)
            else:
                # Fallback: å¦‚æœæ‰¾ä¸åˆ° IDï¼Œåˆ—å‡ºæ‰€æœ‰å·¥å…· (æˆ–åƒ… Global)
                all_tools_dict = tool_registry.list()
                available_tools_list = []
                for name, data in all_tools_dict.items():
                    available_tools_list.append({"name": name, "description": data['description']})

            tools_list_text = "\n".join([f"- {t['name']}: {t['description']}" for t in available_tools_list])
        finally:
            db.close()
        
        # DB session for prompt
        db = SessionLocal()
        try:
            sys_template = PromptService.get_prompt(db, "debate.tool_selection_system")
            if not sys_template: sys_template = "You are {agent_name}."
            system_prompt = sys_template.format(agent_name=agent.name, side=side, topic=self.topic)

            user_template = PromptService.get_prompt(db, "debate.tool_selection_user")
            if not user_template: user_template = "Select tools: {tools_list_text}"
            user_prompt = user_template.format(tools_list_text=tools_list_text)
        finally:
            db.close()

        try:
            # Async LLM Call
            response = await call_llm_async(user_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}:ToolSelection")
            
            # å˜—è©¦è§£æ JSON (æ”¯æ´ List æˆ– Dict æ ¼å¼)
            selected_tools = []
            
            # 1. Try List [...]
            list_match = re.search(r'\[.*\]', response, re.DOTALL)
            if list_match:
                try:
                    selected_tools = json.loads(list_match.group(0))
                except:
                    pass

            # 2. Try Dict {"tools": [...]} if list failed
            if not selected_tools:
                dict_match = re.search(r'\{.*\}', response, re.DOTALL)
                if dict_match:
                    try:
                        data = json.loads(dict_match.group(0))
                        if isinstance(data, dict):
                            selected_tools = data.get("tools") or data.get("tool_names") or []
                    except:
                        pass
            
            if selected_tools and isinstance(selected_tools, list):
                self.agent_tools_map[agent.name] = selected_tools
                print(f"Agent {agent.name} selected tools: {selected_tools}")
                
                # æ ¼å¼åŒ–å·¥å…·åˆ—è¡¨é¡¯ç¤º
                tools_display = "\n".join([f"  â€¢ {tool}" for tool in selected_tools])
                self._publish_log(f"{agent.name} (Setup)", f"âœ… å·²é¸æ“‡ {len(selected_tools)} å€‹å·¥å…·ï¼š\n{tools_display}")
            else:
                # Fallback: Auto-equip all available tools if selection fails
                all_available = [t['name'] for t in available_tools_list]
                self.agent_tools_map[agent.name] = all_available
                print(f"Agent {agent.name} failed to select tools. Auto-equipping all: {all_available}")
                
                tools_display = "\n".join([f"  â€¢ {tool}" for tool in all_available])
                self._publish_log(f"{agent.name} (Setup)", f"âš ï¸ å·¥å…·é¸æ“‡å¤±æ•—ï¼Œå·²è‡ªå‹•è£å‚™æ‰€æœ‰å¯ç”¨å·¥å…· ({len(all_available)}å€‹)ï¼š\n{tools_display}")
        except Exception as e:
            print(f"Error in tool selection for {agent.name}: {e}")
            self.agent_tools_map[agent.name] = []
            self._publish_log(f"{agent.name} (Setup)", f"âŒ å·¥å…·é¸æ“‡éŒ¯èª¤: {str(e)}")

    def _summarize_old_turns(self):
        """
        åˆ†å±¤æ‘˜è¦ (Hierarchical Summarization)ï¼š
        å°‡èˆŠçš„å°è©±æ­·å²é€²è¡Œçµæ§‹åŒ–æ‘˜è¦ï¼Œä¿ç•™æ¯å€‹è§’è‰²çš„æ ¸å¿ƒè§€é»ã€‚
        """
        keep_recent = 5 # ä¿ç•™æœ€è¿‘ 5 æ¢ (å¢åŠ ä¸Šä¸‹æ–‡)
        
        if len(self.history) <= keep_recent + 2:
            return

        # æå–éœ€è¦å£“ç¸®çš„èˆŠè¨Šæ¯
        to_compress = self.history[:-keep_recent]
        # æ›´æ–° self.historyï¼Œåªä¿ç•™æœ€è¿‘çš„è¨Šæ¯
        self.history = self.history[-keep_recent:]
        
        # æ§‹å»ºå¾…æ‘˜è¦æ–‡æœ¬
        conversation_text = ""
        for item in to_compress:
            role = item.get('role')
            content = str(item.get('content'))
            if len(content) > 500:
                content = content[:500] + "..."
            conversation_text += f"[{role}]: {content}\n\n"
        
        db = SessionLocal()
        try:
            template = PromptService.get_prompt(db, "debate.hierarchical_summarizer")
            if not template: template = "Summarize: {conversation_text}"
            system_prompt = template
            user_prompt = f"è«‹æ‘˜è¦ä»¥ä¸‹å°è©±ï¼š\n\n{conversation_text}"
        finally:
            db.close()
        
        try:
            summary = call_llm(user_prompt, system_prompt=system_prompt)
            if summary:
                self.archived_summaries.append(summary)
                print(f"DEBUG: Hierarchical summary generated. Length: {len(summary)}")
                self._publish_log("System", "å·²å°èˆŠçš„è¾¯è«–æ­·å²é€²è¡Œåˆ†å±¤æ‘˜è¦è™•ç†ã€‚")
        except Exception as e:
            print(f"WARNING: Hierarchical summarization failed: {e}")
            # Fallback: Just append raw text truncated if summary fails?
            # Or just keep it in history? No, that would lose data or explode context.
            # Let's append a placeholder.
            self.archived_summaries.append(f"(æ‘˜è¦å¤±æ•—: {str(e)})")

    def _get_compact_history(self, max_length=2000) -> str:
        """
        ç²å–å„ªåŒ–å¾Œçš„è¾¯è«–æ­·å² (Hierarchical Summary + Recent History)
        """
        # 1. å˜—è©¦è§¸ç™¼æ‘˜è¦
        self._summarize_old_turns()
        
        # 2. çµ„åˆæ­·å²
        # A. çµæ§‹åŒ–æ‘˜è¦å€
        archived_text = "ã€éå¾€è¾¯è«–æ‘˜è¦ã€‘\n" + "\n".join(self.archived_summaries)
        
        # B. è¿‘æœŸå°è©±å€
        active_history_text = "ã€è¿‘æœŸå°è©±ã€‘\n"
        for item in self.history:
            content = item.get("content", "")
            if len(content) > 800:
                content = content[:300] + "...(ç•¥)..." + content[-300:]
            active_history_text += f"{item.get('role')}: {content}\n\n"
        
        return f"{archived_text}\n\n{active_history_text}"

    def _agent_turn(self, agent: AgentBase, side: str, round_num: int) -> str:
        return asyncio.run(self._agent_turn_async(agent, side, round_num))

    async def _agent_turn_async(self, agent: AgentBase, side: str, round_num: int) -> str:
        """
        åŸ·è¡Œå–®å€‹ Agent çš„å›åˆï¼šæ€è€ƒ -> å·¥å…· -> ç™¼è¨€ (Async)
        """
        print(f"Agent {agent.name} ({side}) is thinking...")
        self._publish_log(f"{agent.name} (Thinking)", f"{agent.name} æ­£åœ¨æ€è€ƒä¸¦æ±ºå®šä½¿ç”¨çš„ç­–ç•¥...")
        
        # æ§‹å»º Prompt - ä½¿ç”¨ Agent è‡ªå·±é¸æ“‡çš„å·¥å…·
        selected_tool_names = self.agent_tools_map.get(agent.name, [])
        
        # å¦‚æœæœ‰é¸æ“‡ï¼Œå‰‡åªé¡¯ç¤ºé¸æ“‡çš„å·¥å…·ï¼›å¦å‰‡é¡¯ç¤ºæ‰€æœ‰ã€Œå¯ç”¨ã€çš„å·¥å…·
        if selected_tool_names:
            filtered_tools = {}
            for name in selected_tool_names:
                try:
                    # Using get_tool_data ensures lazy tools are loaded and schema is available
                    # Assuming version 'v1' for now as selection doesn't specify version
                    tool_data = tool_registry.get_tool_data(name)
                    filtered_tools[name] = tool_data
                except Exception as e:
                    print(f"Warning: Selected tool '{name}' not found or failed to load: {e}")

            if not filtered_tools:
                 # å¦‚æœé¸æ“‡ç„¡æ•ˆï¼Œå›é€€åˆ°é¡¯ç¤ºè©² Agent æ‰€æœ‰å¯ç”¨çš„å·¥å…· (ToolSet)
                 tools_desc = get_tools_description()
            else:
                 tools_desc = "ä½ å·²é¸æ“‡ä¸¦æ¿€æ´»ä»¥ä¸‹å·¥å…·ï¼š\n" + "\n".join([f"### {name}\n{data['description']}\nSchema: {json.dumps(data['schema'], ensure_ascii=False)}" for name, data in filtered_tools.items()])
        else:
            # å¦‚æœæ²’æœ‰é¸æ“‡ï¼ˆä¾‹å¦‚åˆå§‹åŒ–å¤±æ•—ï¼‰ï¼Œé¡¯ç¤ºæ‰€æœ‰å·¥å…·
            tools_desc = get_tools_description()
            
        # Append Meta-Tool Description
        # Dynamically fetch available groups from registry for the hint
        available_groups = set()
        for _, t_data in tool_registry.list().items():
             available_groups.add(t_data.get('group', 'basic'))
        groups_str = " | ".join([f"'{g}'" for g in sorted(available_groups)])
        
        tools_desc += f"\n\n### reset_equipped_tools\nDescription: å‹•æ…‹åˆ‡æ›å·¥å…·çµ„ (active tool group)ã€‚è‹¥ä½ æ‰¾ä¸åˆ°éœ€è¦çš„å·¥å…·ï¼Œè«‹å˜—è©¦åˆ‡æ›ã€‚\nParameters: {{'group': {groups_str}}}"
        
        # Append Chairman Intervention Tool (Virtual)
        tools_desc += "\n\n### call_chairman\nDescription: ç•¶ä½ ç™¼ç¾è¾¯é¡Œè³‡è¨Šåš´é‡ä¸è¶³ï¼ˆå¦‚ç¼ºä¹èƒŒæ™¯ã€å®šç¾©ä¸æ¸…ï¼‰ï¼Œç„¡æ³•é€²è¡Œæœ‰æ•ˆåˆ†ææ™‚ï¼Œè«‹ä½¿ç”¨æ­¤å·¥å…·é€šçŸ¥ä¸»å¸­ä»‹å…¥è™•ç†ã€‚\nParameters: {'reason': 'èªªæ˜å…·é«”ç¼ºå°‘ä»€éº¼è³‡è¨Šæˆ–èƒŒæ™¯'}"

        tools_examples = get_tools_examples() # Examples æš«æ™‚ä¿æŒå…¨é›†ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥éæ¿¾
        
        # Retrieve Tool LTM hints
        tool_hints = ""
        tool_mem = ReMeToolLongTermMemory()
        tool_hints = await tool_mem.retrieve_async(self.topic) # Use topic as context for now
        if tool_hints:
            tools_examples += f"\n\n**éå¾€æˆåŠŸå·¥å…·èª¿ç”¨åƒè€ƒ (ReMe Tool LTM)**:\n{tool_hints}"

        # Retrieve RAG Context (Relevant History)
        rag_context = ""
        rag = ReMeHistoryMemory(self.debate_id)
        # Use current agent role and topic as query
        query = f"{agent.name} {side} {self.topic}"
        relevant_turns = await rag.retrieve_async(query, top_k=2)
        if relevant_turns:
            rag_context = "\n".join([f"> [{t['role']} (Round {t['round']})]: {str(t['content'])[:200]}..." for t in relevant_turns])

        history_text = self._get_compact_history()
        if rag_context:
            history_text += f"\n\nã€ç›¸é—œæ­·å²å›é¡§ (RAG)ã€‘\n{rag_context}"
        
        db = SessionLocal()
        try:
            # 1. System Prompt Construction
            # Strategy: Combine Agent's Custom Persona with System's Operational Rules
            
            # A. Operational Rules (Externalized)
            operational_rules = PromptService.get_prompt(db, "debater.operational_rules")
            if not operational_rules: operational_rules = "System Rules: Use tools first."
            
            # B. Agent Persona (Custom or Default)
            custom_prompt = getattr(agent, 'system_prompt', '').strip()
            if custom_prompt:
                persona_section = f"""
**ä½ çš„è§’è‰²è¨­å®š (Persona)**ï¼š
{custom_prompt}

ä½ æ˜¯ {agent.name}ï¼Œä»£è¡¨ {side} æ–¹ã€‚
è¾¯é¡Œï¼š{self.topic}
"""
            else:
                persona_section = f"""
**ä½ çš„è§’è‰²è¨­å®š (Persona)**ï¼š
ä½ æ˜¯ {agent.name}ï¼Œä»£è¡¨ {side} æ–¹ã€‚
è¾¯é¡Œï¼š{self.topic}
"""

            # Combine
            default_system = f"{persona_section}\n{operational_rules}"
            
            # Try to get override from DB, but prioritize constructing it dynamically if not found
            system_prompt = default_system
            
            # 2. User Prompt (Tool Instruction)
            user_template = PromptService.get_prompt(db, "debater.tool_instruction")
            if not user_template: user_template = "Instructions: {history_text} {tools_desc}"
            
            user_prompt = user_template.format(
                round_num=round_num,
                history_text=history_text,
                chairman_summary=self.analysis_result.get('step5_summary', 'ç„¡'),
                current_date=CURRENT_DATE,
                stock_codes=chr(10).join([f"- {name}: {code}" for name, code in STOCK_CODES.items()]),
                tools_desc=tools_desc,
                tools_examples=tools_examples
            )
        finally:
            db.close()
        
        # === Multi-Step Tool Execution Loop ===
        base_max_steps = int(os.getenv("MAX_AGENT_TOOL_STEPS", 5))
        extension_steps = int(os.getenv("EXTENSION_STEPS", 3))
        max_steps = base_max_steps
        has_extended = False
        
        current_step = 0
        current_prompt = user_prompt
        collected_evidence = [] # Track evidence for fallback report
        
        while True: # Outer Loop for Extension Retry
            while current_step < max_steps:
                current_step += 1
                
                # Async LLM Call
                response = await call_llm_async(current_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}")
                print(f"DEBUG: Agent {agent.name} response (Step {current_step}): {response[:500]}")

                # Retry æ©Ÿåˆ¶ (Only for empty response on first step)
                if not response and current_step == 1:
                    print(f"WARNING: Empty response from {agent.name}, retrying with simple prompt...")
                    retry_prompt = f"è«‹é‡å°è¾¯é¡Œã€Œ{self.topic}ã€ç™¼è¡¨ä½ çš„{side}è«–é»ã€‚è«‹å‹™å¿…ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚"
                    response = await call_llm_async(retry_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}")
                
                # Check for tool call
                try:
                    # å˜—è©¦æå– JSON
                    json_match = re.search(r'\{.*\}', response, re.DOTALL)
                    if not json_match:
                        # No JSON found -> Assume final speech -> Return
                        return response
                    
                    json_str = json_match.group(0)
                    try:
                        tool_call = json.loads(json_str)
                    except json.JSONDecodeError:
                        # JSON parse failed -> Treat as text
                        return response

                    # Check if valid tool call
                    if isinstance(tool_call, dict) and "tool" in tool_call and "params" in tool_call:
                        tool_name = str(tool_call["tool"]).strip()
                        params = tool_call["params"]
                        
                        # --- Meta-Tool: reset_equipped_tools ---
                        if tool_name == "reset_equipped_tools":
                            target_group = params.get("group", "basic")
                            print(f"âš™ï¸ Agent {agent.name} is resetting equipped tools to group: {target_group}")
                            self._publish_log(f"{agent.name} (Meta-Tool)", f"Resetting tools to group: {target_group}")
                            
                            group_tools = tool_registry.list(groups=[target_group])
                            self.agent_tools_map[agent.name] = list(group_tools.keys())
                            
                            # Recursive retry with new tools (Reset steps)
                            return await self._agent_turn_async(agent, side, round_num)

                        # --- Meta-Tool: call_chairman (Intervention) ---
                        if tool_name == "call_chairman":
                            reason = params.get("reason", "æœªèªªæ˜åŸå› ")
                            print(f"ğŸš¨ Agent {agent.name} is calling Chairman for help: {reason}")
                            self._publish_log(f"{agent.name} (SOS)", f"è«‹æ±‚ä¸»å¸­ä»‹å…¥ï¼š{reason}")

                            chairman_prompt = f"Agent {agent.name} ({side}æ–¹) åœ¨åˆ†æè¾¯é¡Œã€Œ{self.topic}ã€æ™‚é‡åˆ°å›°é›£ã€‚\nå›å ±åŸå› ï¼š{reason}\nè«‹æ ¹æ“šä½ çš„è³½å‰åˆ†ææ‰‹å¡ï¼Œæä¾›å¼•å°ã€‚"
                            clarification = await call_llm_async(chairman_prompt, system_prompt="ä½ æ˜¯è¾¯è«–ä¸»å¸­ã€‚è«‹å”åŠ©é‡åˆ°å›°é›£çš„è¾¯æ‰‹ã€‚")
                            
                            self._publish_log("Chairman (Intervention)", f"ä¸»å¸­å›æ‡‰ï¼š{clarification}")
                            
                            intervention_msg = {"role": "Chairman (Intervention)", "content": f"è£œå……èªªæ˜ï¼š\n{clarification}\nè«‹ç¹¼çºŒåˆ†æã€‚"}
                            self.history.append(intervention_msg)
                            
                            # Recursive retry (Reset steps)
                            return await self._agent_turn_async(agent, side, round_num)

                        # --- Meta-Tool: request_extension (Early access check) ---
                        if tool_name == "request_extension":
                             print(f"Agent {agent.name} requested extension prematurely.")
                             self._publish_log(f"{agent.name} (System)", "âš ï¸ ä½ é‚„æœ‰å‰©é¤˜çš„èª¿æŸ¥æ¬¡æ•¸ï¼Œè«‹å„ªå…ˆä½¿ç”¨å·¥å…·é€²è¡Œèª¿æŸ¥ã€‚")
                             current_prompt = "ç³»çµ±æç¤ºï¼šä½ é‚„æœ‰å‰©é¤˜çš„èª¿æŸ¥æ¬¡æ•¸ï¼Œç„¡éœ€ç”³è«‹å»¶é•·ã€‚è«‹ç¹¼çºŒä½¿ç”¨å·¥å…·æœå°‹æ•¸æ“šã€‚"
                             continue
                        
                        # --- Memory Tool Context Injection ---
                        if tool_name == "search_shared_memory":
                            params["debate_id"] = self.debate_id

                        # --- Regular Tool Execution ---
                        
                        # [STRICT TOOL VALIDATION]
                        # Check if the tool is in the equipped list for this agent
                        equipped_tools = self.agent_tools_map.get(agent.name, [])
                        if tool_name not in equipped_tools:
                            # Bypass validation for special meta-tools if needed, but currently only reset_equipped_tools/call_chairman are meta-tools handled above.
                            # So this block is for regular tools.
                            print(f"âŒ Blocked: Agent {agent.name} tried to call unequipped tool: {tool_name}")
                            
                            error_msg = f"Error: Tool '{tool_name}' is not in your equipped list. You can only use: {equipped_tools}. Use 'reset_equipped_tools' if you need to switch toolsets."
                            
                            # Log failure
                            self._publish_log(f"{agent.name} (System)", f"â›” æ‹’çµ•åŸ·è¡Œï¼šå·¥å…· {tool_name} æœªè£å‚™")
                            
                            # Append to evidence for context
                            collected_evidence.append(f"ã€ç³»çµ±éŒ¯èª¤ã€‘èª¿ç”¨å¤±æ•—ï¼š{error_msg}")
                            
                            # Return error to LLM to correct itself
                            current_prompt = f"ç³»çµ±éŒ¯èª¤ï¼š{error_msg}\nè«‹é‡æ–°é¸æ“‡æœ‰æ•ˆçš„å·¥å…·æˆ–ç™¼è¡¨è¨€è«–ã€‚"
                            continue

                        print(f"âœ“ Agent {agent.name} calling {tool_name}")
                        self._publish_log(f"{agent.name} (Tool)", f"Calling {tool_name} with {params}")
                        
                        try:
                            # 1. Check Working Memory (Sensory Gating)
                            cached_result = await self.hippocampus.retrieve_working_memory(tool_name, params)
                            
                            if cached_result:
                                tool_result = cached_result['result']
                                self._publish_log(f"{agent.name} (Memory)", f"ğŸ§  å¾æµ·é¦¬é«”çŸ­æœŸè¨˜æ†¶ä¸­ç²å–äº†çµæœ (Access: {cached_result['access_count']})")
                            else:
                                # 2. Execute Tool (Sensory Input)
                                from worker.tool_invoker import call_tool
                                loop = asyncio.get_running_loop()
                                tool_result = await loop.run_in_executor(None, call_tool, tool_name, params)
                                
                                # 3. Store in Working Memory
                                await self.hippocampus.store(agent.name, tool_name, params, tool_result)
                                self._publish_log(f"{agent.name} (Tool)", f"å·¥å…· {tool_name} åŸ·è¡ŒæˆåŠŸä¸¦å­˜å…¥æµ·é¦¬é«”ã€‚")
                            
                            # Publish Tool Result Preview to Log Stream
                            result_preview_log = str(tool_result)
                            if len(result_preview_log) > 500:
                                result_preview_log = result_preview_log[:500] + "... (é»æ“ŠæŸ¥çœ‹å®Œæ•´æ•¸æ“š)"
                            self._publish_log(f"{agent.name} (Tool Result)", f"ğŸ“Š å·¥å…·åŸ·è¡Œçµæœæ‘˜è¦ï¼š\n{result_preview_log}")
                            
                            # Print full result to backend console for debugging (as requested)
                            print(f"DEBUG: Full tool result for {tool_name}:\n{json.dumps(tool_result, ensure_ascii=False, indent=2, default=str)}")

                            # Record successful tool usage to Tool LTM
                            try:
                                tool_mem = ReMeToolLongTermMemory()
                                await tool_mem.record_async(
                                    intent=f"Debate on {self.topic}",
                                    tool_name=tool_name,
                                    params=params,
                                    result=tool_result,
                                    success=True
                                )
                            except Exception as e:
                                print(f"Warning: Failed to record tool usage to LTM: {e}")

                            # Record Evidence
                            evidence_entry = {
                                "role": f"{agent.name} ({side})",
                                "agent_name": agent.name,
                                "side": side,
                                "tool": tool_name,
                                "params": params,
                                "result": tool_result,
                                "timestamp": datetime.now().isoformat(),
                                "verified": False,
                                "round": round_num
                            }
                            self.redis_client.rpush(self.evidence_key, json.dumps(evidence_entry, ensure_ascii=False))
                            
                            # Add to local collection (Truncated for summary)
                            # Avoid huge context overhead
                            result_str = str(tool_result)
                            if len(result_str) > 200:
                                preview = result_str[:200] + "... (å®Œæ•´å…§å®¹å·²å­˜æª”)"
                            else:
                                preview = result_str
                                
                            collected_evidence.append(f"ã€è­‰æ“š {current_step}ã€‘{tool_name}\nçµæœæ‘˜è¦: {preview}")

                        except Exception as e:
                            error_msg = str(e)
                            
                            # --- Tool Name Correction Logic ---
                            if "not found" in error_msg or "Tool" in error_msg:
                                all_tools = list(tool_registry.list().keys())
                                matches = []
                                
                                # 1. Fuzzy Match (Original)
                                fuzzy = difflib.get_close_matches(tool_name, all_tools, n=3, cutoff=0.4)
                                matches.extend(fuzzy)
                                
                                # 2. Case-Insensitive Substring Match (New)
                                tool_name_lower = tool_name.lower()
                                for t in all_tools:
                                    if tool_name_lower in t.lower() or t.lower() in tool_name_lower:
                                        if t not in matches:
                                            matches.append(t)
                                            
                                # 3. Limit suggestions
                                matches = matches[:5]
                                
                                if matches:
                                    suggestion = f" Did you mean: {', '.join(matches)}?"
                                    error_msg += suggestion
                                else:
                                    # If absolutely no match, list all tools in current group if possible, or top 5 generic
                                    error_msg += f" Available tools: {', '.join(all_tools[:5])}..."
                            # ----------------------------------
                            
                            tool_result = {"error": f"Tool execution error: {error_msg}"}
                            print(f"ERROR: Tool {tool_name} failed: {error_msg}")

                            # Record failed tool usage
                            try:
                                tool_mem = ReMeToolLongTermMemory()
                                await tool_mem.record_async(
                                    intent=f"Debate on {self.topic}",
                                    tool_name=tool_name,
                                    params=params,
                                    result=str(e),
                                    success=False
                                )
                            except Exception as ex:
                                print(f"Warning: Failed to record tool failure to LTM: {ex}")

                            collected_evidence.append(f"ã€è­‰æ“š {current_step}ã€‘{tool_name}\nåŸ·è¡Œå¤±æ•—: {error_msg}")
                        
                        # Update prompt with tool result for NEXT step
                        current_prompt = f"""å·¥å…· {tool_name} çš„åŸ·è¡Œçµæœï¼š
{json.dumps(tool_result, ensure_ascii=False, indent=2)}

è«‹æ ¹æ“šé€™äº›è­‰æ“šé€²è¡Œç™¼è¨€ã€‚å¦‚æœä½ è¦ºå¾—è­‰æ“šä¸è¶³ï¼Œå¯ä»¥å†æ¬¡èª¿ç”¨å…¶ä»–å·¥å…·ï¼ˆè«‹ç¹¼çºŒè¼¸å‡º JSONï¼‰ã€‚
å¦‚æœè­‰æ“šè¶³å¤ ï¼Œè«‹è¼¸å‡ºæœ€çµ‚è«–é»ï¼ˆç´”æ–‡å­—ï¼‰ã€‚"""
                        
                        # Loop continues to next step...
                        continue

                    # Handle Error JSON
                    elif isinstance(tool_call, dict) and "error" in tool_call:
                        # ... (Existing error handling logic) ...
                        # For brevity, if error JSON, we treat as text or retry logic (omitted complex retry for now to fit structure)
                        # Let's just return it or basic text to avoid stuck loop
                        return str(tool_call)
                    
                    else:
                        # JSON found but not a tool call -> Treat as text response
                        return response

                except Exception as e:
                    print(f"Error in agent loop: {e}")
                    return response
            
            # --- Loop Limit Reached ---
            # Allow one-time extension request
            if not has_extended:
                print(f"INFO: Agent {agent.name} reached base limit. Offering extension.")
                self._publish_log(f"{agent.name} (System)", "âš ï¸ åŸºç¤èª¿æŸ¥æ¬¡æ•¸å·²ç”¨ç›¡ã€‚æ­£åœ¨è©¢å•æ˜¯å¦éœ€è¦å»¶é•·èª¿æŸ¥...")
                
                # Externalized Prompt
                db = SessionLocal()
                try:
                    ext_template = PromptService.get_prompt(db, "debate.extension_option")
                    if not ext_template: ext_template = "Max steps reached. 1. Conclude. 2. Extend."
                    extension_option_prompt = ext_template.format(base_max_steps=base_max_steps, extension_steps=extension_steps)
                finally:
                    db.close()

                # Ask Agent
                decision_response = await call_llm_async(extension_option_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}")
                
                # Check for extension request
                json_match = re.search(r'\{.*\}', decision_response, re.DOTALL)
                if json_match:
                    try:
                        req = json.loads(json_match.group(0))
                        if req.get("tool") == "request_extension":
                            reason = req.get("params", {}).get("reason", "ç„¡ç†ç”±")
                            self._publish_log(f"{agent.name} (Request)", f"ç”³è«‹å»¶é•·èª¿æŸ¥ï¼š{reason}")
                            
                            # [Hippocampus] Check Shared Memory before bothering Chairman
                            self._publish_log("System", f"ğŸ§  æ­£åœ¨æŸ¥è©¢æµ·é¦¬é«”è¨˜æ†¶ä»¥é©—è­‰å»¶é•·éœ€æ±‚...")
                            mem_results = await self.hippocampus.search_shared_memory(query=reason, limit=3)
                            
                            # Heuristic: If "No relevant memories" is NOT in the result, it means we found something.
                            # Ideally search_shared_memory should return a list or structured object, but it returns a string currently.
                            # We can check if the result string length implies found content.
                            
                            if "No relevant memories" not in mem_results and len(mem_results) > 50:
                                self._publish_log("System", f"âœ… æµ·é¦¬é«”ä¸­ç™¼ç¾ç›¸é—œè³‡è¨Šï¼Œå»¶é•·ç”³è«‹è‡ªå‹•é§å›ä¸¦æä¾›è³‡è¨Šã€‚")
                                current_prompt = f"ã€ç³»çµ±æç¤ºã€‘å»¶é•·ç”³è«‹å·²è‡ªå‹•é§å›ï¼Œå› ç‚ºåœ¨å…±äº«è¨˜æ†¶ä¸­ç™¼ç¾äº†ç›¸é—œè³‡è¨Šï¼š\n\n{mem_results}\n\nè«‹åˆ©ç”¨é€™äº›è³‡è¨Šç¹¼çºŒä½ çš„è«–è¿°æˆ–ç¸½çµã€‚"
                                continue # Back to agent loop
                            
                            # Call Chairman for Review
                            db = SessionLocal()
                            try:
                                review_template = PromptService.get_prompt(db, "debate.chairman_review_extension")
                                # If template not found (e.g. not init yet), use fallback
                                if not review_template:
                                    review_template = """
ä½ æ˜¯ä¸»å¸­ã€‚Agent {agent_name} ç”³è«‹å»¶é•·èª¿æŸ¥ã€‚
ç†ç”±ï¼š{reason}
è­‰æ“šæ‘˜è¦ï¼š{evidence_summary}
è«‹å›å‚³ JSON: {{"approved": true/false, "reason": "...", "guidance": "..."}}
"""
                                chairman_sys = review_template.format(
                                    agent_name=agent.name, 
                                    side=side, 
                                    topic=self.topic, 
                                    reason=reason,
                                    evidence_summary="\n".join(collected_evidence)[-1000:] # Last 1000 chars
                                )
                            finally:
                                db.close()
                                
                            chairman_res = await call_llm_async("è«‹é€²è¡Œå¯©æ ¸ã€‚", system_prompt=chairman_sys, context_tag=f"{self.debate_id}:Chairman")
                            
                            # Parse Chairman Decision
                            try:
                                res_json = json.loads(re.search(r'\{.*\}', chairman_res, re.DOTALL).group(0))
                                if res_json.get("approved"):
                                    max_steps += extension_steps
                                    has_extended = True
                                    self._publish_log("Chairman (Review)", f"âœ… æ‰¹å‡†å»¶é•·ï¼š{res_json.get('reason')}")
                                    
                                    # Update prompt with guidance
                                    current_prompt = f"ä¸»å¸­å·²æ‰¹å‡†å»¶é•·èª¿æŸ¥ã€‚\næŒ‡å°ï¼š{res_json.get('guidance')}\nè«‹ç¹¼çºŒä½ çš„èª¿æŸ¥æˆ–ç™¼è¨€ã€‚"
                                    continue # Continue Outer Loop (re-enters Inner Loop with higher max_steps)
                                else:
                                    self._publish_log("Chairman (Review)", f"âŒ æ‹’çµ•å»¶é•·ï¼š{res_json.get('reason')}")
                                    current_prompt = f"ä¸»å¸­æ‹’çµ•äº†ä½ çš„ç”³è«‹ã€‚\nç†ç”±ï¼š{res_json.get('reason')}\nè«‹ç«‹å³æ ¹æ“šç¾æœ‰è³‡è¨Šç™¼è¡¨ç¸½çµã€‚"
                                    # Fall through to forced summary (or return text if agent replies text next time)
                                    # Actually, we should force summary NOW or give one last chance?
                                    # Let's give one last chance with text-only constraint.
                                    final_res = await call_llm_async(current_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}")
                                    return final_res
                                    
                            except Exception as e:
                                print(f"Error parsing chairman review: {e}")
                                # Fallback: Deny
                    except:
                        pass
                
                # If not extension request or denied/failed, return the response as text (if it's text)
                # or fallback report if it's still JSON but not extension
                if not json_match:
                    return decision_response
            
            # If reached here, it means extension denied or invalid request, break outer loop to fallback
            break
        
        # Loop ended (either max steps reached again, or denied extension)
        # FORCE A CONCLUSION: Instead of returning a system report, force the LLM to speak based on whatever it has.
        print(f"WARNING: Agent {agent.name} reached max steps ({max_steps}). Forcing conclusion.")
        
        evidence_text = "\n\n".join(collected_evidence)
        self._publish_log(f"{agent.name} (System)", f"âš ï¸ èª¿ç”¨æ¬¡æ•¸è€—ç›¡ï¼Œæ­£åœ¨å¼·åˆ¶ç”Ÿæˆç¸½çµç™¼è¨€...")
        
        force_conclusion_prompt = f"""
ã€ç³»çµ±å¼·åˆ¶æŒ‡ä»¤ã€‘
ä½ å·²ç¶“é”åˆ°å·¥å…·èª¿ç”¨æ¬¡æ•¸ä¸Šé™ï¼Œä¸èƒ½å†ä½¿ç”¨å·¥å…·äº†ã€‚
è«‹æ ¹æ“šä½ ç›®å‰å·²è’é›†åˆ°çš„è­‰æ“šï¼ˆæˆ–è‹¥ç„¡è­‰æ“šï¼Œå‰‡æ ¹æ“šä½ çš„å°ˆæ¥­çŸ¥è­˜èˆ‡é‚è¼¯æ¨æ¼”ï¼‰ï¼Œç«‹å³ç™¼è¡¨ä½ çš„æœ¬è¼ªè«–é»ã€‚

**å·²è’é›†çš„è­‰æ“šæ‘˜è¦**ï¼š
{evidence_text}

è«‹ç›´æ¥è¼¸å‡ºä½ çš„è¾¯è«–ç™¼è¨€ï¼ˆç´”æ–‡å­—ï¼‰ï¼š
"""
        try:
            # Force call without tool capability (modify system prompt? No, just strong instruction)
            # We use the same system prompt but a very strong user instruction.
            final_speech = await call_llm_async(force_conclusion_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}")
            return final_speech
        except Exception as e:
             # If even this fails, then fallback to report
             print(f"Error in forced conclusion: {e}")
             return f"(ç³»çµ±å ±å‘Šï¼šAgent åœ¨å¼·åˆ¶ç¸½çµæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè­‰æ“šå¦‚ä¸‹)\n{evidence_text}"
