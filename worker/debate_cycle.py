from typing import List, Dict, Any
from worker.chairman import Chairman
from worker.guardrail_agent import GuardrailAgent
from agentscope.agent import AgentBase
import json
import re
import os
import sys
import yaml
import asyncio
import resource
import difflib
from datetime import datetime, timezone, timedelta
from worker.llm_utils import call_llm, call_llm_async
from worker.tool_config import get_tools_description, get_tools_examples, STOCK_CODES, CURRENT_DATE
from api.prompt_service import PromptService
from api.database import SessionLocal
import hashlib
from worker.memory import ReMePersonalLongTermMemory, ReMeTaskLongTermMemory, ReMeToolLongTermMemory, ReMeHistoryMemory, HippocampalMemory
from api.tool_registry import tool_registry
from api.toolset_service import ToolSetService
from api.redis_client import get_redis_client
from api import models
from mars.types.errors import ToolError, ToolRecoverableError, ToolTerminalError, ToolFatalError, TejErrorType

class DebateCycle:
    """
    ç®¡ç†æ•´ä¸ªè¾©è®ºå¾ªç¯ï¼ŒåŒ…æ‹¬ä¸»å¸­å¼•å¯¼ã€æ­£åæ–¹å‘è¨€å’Œæ€»ç»“ã€‚
    """

    def __init__(self, debate_id: str, topic: str, chairman: Chairman, teams: List[Dict], rounds: int, enable_cross_examination: bool = True):
        self.debate_id = debate_id
        self.topic = topic
        self.chairman = chairman
        self.teams = teams # List of dicts: [{"name": "...", "side": "...", "agents": [AgentBase...]}]
        self.rounds = rounds
        self.enable_cross_examination = enable_cross_examination
        self.redis_client = get_redis_client()
        self.evidence_key = f"debate:{self.debate_id}:evidence"
        self.rounds_data = []
        self.analysis_result = {}
        self.history = []
        self.full_history = []  # å®Œæ•´æ­·å²è¨˜éŒ„ï¼ˆä¸å£“ç¸®ï¼Œç”¨æ–¼å ±å‘Šï¼‰
        self.compressed_history = "ç„¡"  # å­˜å„² LLM å£“ç¸®å¾Œçš„æ­·å²æ‘˜è¦ (Legacy)
        self.archived_summaries = [] # List of structured summaries
        self.agent_tools_map = {} # å­˜å„²æ¯å€‹ Agent é¸æ“‡çš„å·¥å…·åˆ—è¡¨
        self.hippocampus = HippocampalMemory(debate_id) # Init Hippocampal Memory
        self.latest_db_date = None # [Phase 18] Date Awareness Handshake
        
        # [Optimization] Persistent LTM instances for buffering
        self.history_memory = ReMeHistoryMemory(debate_id)
        self.tool_memory = ReMeToolLongTermMemory()
        
        # [Robustness] Failure Mode Memory
        # Key: f"{agent_name}:{tool_name}:{error_type}" -> Value: {count, last_params_hash}
        self._failure_memory: Dict[str, Dict[str, Any]] = {}
        
        # [Observability] Loop Sentinel
        self._loop_sentinel: Dict[str, int] = {} # Key: signature -> count
        
        # Log de-duplication cache: key -> {"last_ts": datetime, "suppressed": int}
        self._log_dedupe: Dict[str, Dict[str, Any]] = {}
        
        # [Debug] Setup debug log directory
        self.debug_log_enabled = os.getenv("DEBUG_LOG_ENABLE", "false").lower() == "true"
        if self.debug_log_enabled:
            self.debug_log_dir = "debate_logs"
            os.makedirs(self.debug_log_dir, exist_ok=True)
            # [Realtime] Stream log file
            self.stream_log_path = os.path.join(self.debug_log_dir, f"stream_{self.debate_id}.log")
            self._log_to_file(f"=== Debate Stream Started: {self.debate_id} ===")
        
        # [Debug] Full Execution Trace
        self.debug_trace: List[Dict[str, Any]] = []
        
        # [Observability Phase 6] Tool Stats
        self.tool_stats = {
            "count": 0,
            "total_time": 0.0,
            "estimated_cost": 0.0
        }
        
        # [Governance] Guardrail Agent
        self.guardrail_agent = GuardrailAgent()

    def _log_to_file(self, message: str):
        """Append message to the realtime stream log."""
        if not self.debug_log_enabled or not hasattr(self, 'stream_log_path'):
            return
        try:
            with open(self.stream_log_path, "a", encoding="utf-8") as f:
                timestamp = datetime.now().strftime("%H:%M:%S")
                f.write(f"[{timestamp}] {message}\n")
        except Exception as e:
            print(f"Failed to write to stream log: {e}")

    def _get_memory_usage(self) -> str:
        """ç²å–ç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨é‡ (MB)"""
        try:
            usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
            # MacOS: bytes, Linux: KB
            if sys.platform == 'darwin':
                return f"{usage / 1024 / 1024:.2f} MB"
            return f"{usage / 1024:.2f} MB"
        except Exception:
            return "N/A"

    def _publish_log(self, role: str, content: str):
        """
        ç™¼å¸ƒæ—¥èªŒåˆ° Redisï¼Œä¾›å‰ç«¯ SSE è¨‚é–±ã€‚
        å…·å‚™å»é‡èˆ‡ç¯€æµï¼š
        - åŒä¸€ role+content åœ¨ 1 ç§’å…§é‡è¤‡ï¼Œå°‡è¢«æŠ‘åˆ¶ä¸¦ç´¯è¨ˆ suppressed è¨ˆæ•¸ã€‚
        - ä¸‹ä¸€æ¬¡å…è¨±çš„è¼¸å‡ºæœƒé™„å¸¶ "(previous N duplicates suppressed)" è¨»è¨˜ã€‚
        """
        # Ensure timestamp is Asia/Taipei (GMT+8)
        tz_taipei = timezone(timedelta(hours=8))
        now = datetime.now(timezone.utc).astimezone(tz_taipei)
        timestamp = now.strftime("%H:%M:%S")

        # De-duplication key
        key = f"{role}|{content}"
        entry = self._log_dedupe.get(key)
        allow_publish = True
        suppressed_note = ""
        dedupe_window_seconds = 1.0

        if entry:
            last_ts = entry.get("last_ts")
            suppressed = entry.get("suppressed", 0)
            # If within the dedupe window, suppress
            if last_ts and (now - last_ts).total_seconds() < dedupe_window_seconds:
                entry["suppressed"] = suppressed + 1
                entry["last_ts"] = now
                self._log_dedupe[key] = entry
                allow_publish = False
            else:
                # Outside the window: if there were suppressed duplicates, annotate once
                if suppressed:
                    suppressed_note = f" (previous {suppressed} duplicates suppressed)"
                # Reset counter and publish
                entry["suppressed"] = 0
                entry["last_ts"] = now
                self._log_dedupe[key] = entry
        else:
            # First time seeing this message
            self._log_dedupe[key] = {"last_ts": now, "suppressed": 0}

        if not allow_publish:
            return
        
        # Add timestamp to console log
        print(f"[{timestamp}] {role}: {content[:100]}...{suppressed_note}")
        
        # [Realtime] Log to file
        self._log_to_file(f"[{role}] {content}{suppressed_note}")
        
        # Add timestamp to UI content
        ui_content = f"[{timestamp}] {content}{suppressed_note}"
        
        message = json.dumps({"role": role, "content": ui_content}, ensure_ascii=False)
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", message)
        # Persist log for late-joiners
        self.redis_client.rpush(f"debate:{self.debate_id}:log_history", message)

    def _publish_progress(self, percentage: int, message: str, stage: str = "setup"):
        """
        ç™¼å¸ƒé€²åº¦æ›´æ–°äº‹ä»¶ï¼Œä¾›å‰ç«¯é¡¯ç¤ºé€²åº¦æ¢ã€‚
        """
        event_data = {
            "type": "progress_update",
            "progress": percentage,
            "message": message,
            "stage": stage,
            "timestamp": datetime.now().isoformat()
        }
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", json.dumps(event_data, ensure_ascii=False))

    def _save_round_debug_log(self, round_num: int, team_summaries: Dict[str, str]):
        """
        Save detailed debug log for the current round (Appended to single file).
        """
        if not self.debug_log_enabled:
            return

        try:
            # Use single file for the whole debate
            filename = f"debate_debug_{self.debate_id}.txt"
            filepath = os.path.join(self.debug_log_dir, filename)
            
            with open(filepath, "a", encoding="utf-8") as f:
                f.write(f"\n{'='*60}\n")
                f.write(f"=== ç¬¬ {round_num} è¼ªé™¤éŒ¯æ—¥èªŒ (Round {round_num} Debug Log) ===\n")
                f.write(f"{'='*60}\n")
                f.write(f"Debate ID: {self.debate_id}\n")
                f.write(f"Topic: {self.topic}\n")
                f.write(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("--- å„åœ˜éšŠç¸½çµ (Team Summaries) ---\n")
                for team, summary in team_summaries.items():
                    f.write(f"[{team}]:\n{summary}\n\n")
                
                f.write("\n--- è¿‘æœŸå°è©±æ­·å² (Detailed History - Recent) ---\n")
                for item in self.history[-50:]: # Last 50 items
                    f.write(f"[{item.get('role')}]: {str(item.get('content'))[:500]}...\n")
                
                f.write("\n--- å®Œæ•´åŸ·è¡Œè¿½è¹¤ï¼šLLM è¼¸å…¥è¼¸å‡ºèˆ‡å·¥å…·çµæœ (Full Execution Trace) ---\n")
                
                for i, trace in enumerate(self.debug_trace):
                    f.write(f"\n[Trace #{i+1}] {trace.get('timestamp')}\n")
                    f.write(f"Agent: {trace.get('agent')}\n")
                    f.write(f"Step: {trace.get('step')}\n")
                    f.write(f"Event: {trace.get('event')}\n")
                    
                    if "prompt" in trace:
                        f.write(f"Full Prompt:\n{trace['prompt']}\n")
                    if "response" in trace:
                        f.write(f"LLM Response: {trace['response']}\n")
                    if "tool" in trace:
                        f.write(f"Tool Call: {trace['tool']} params={trace.get('params')}\n")
                    if "result" in trace:
                        # Full Result
                        try:
                            res_str = json.dumps(trace['result'], ensure_ascii=False, indent=2, default=str)
                        except:
                            res_str = str(trace['result'])
                        f.write(f"Tool Result: {res_str}\n")
                    f.write("-" * 40 + "\n")

                f.write("\n--- å‰ç«¯èˆ‡ç³»çµ±æ—¥èªŒä¸²æµ (Frontend & System Logs) ---\n")
                try:
                    # Fetch all logs from Redis
                    redis_logs = self.redis_client.lrange(f"debate:{self.debate_id}:log_history", 0, -1)
                    for log_json in redis_logs:
                        try:
                            entry = json.loads(log_json)
                            f.write(f"[{entry.get('role')}]: {entry.get('content')}\n")
                        except:
                            f.write(f"[Raw]: {log_json}\n")
                except Exception as e:
                    f.write(f"[Error fetching system logs]: {e}\n")

            print(f"[Debug] Round {round_num} log saved to {filepath}")
        except Exception as e:
            print(f"[Debug] Failed to save debug log: {e}")

    def _save_report_to_file(self, conclusion: str, jury_report: str = None, start_time: datetime = None, end_time: datetime = None):
        """
        å°‡è¾¯è«–éç¨‹ä¿å­˜ç‚º Markdown æ–‡ä»¶ã€‚
        """
        import re
        from datetime import datetime
        
        report_dir = "data/replays"
        os.makedirs(report_dir, exist_ok=True)
        
        # æ¸…ç†é¡Œç›®ï¼Œç§»é™¤éæ³•æ–‡ä»¶åå­—ç¬¦
        safe_topic = re.sub(r'[<>:"/\\|?*]', '', self.topic)
        safe_topic = safe_topic.replace(' ', '_')[:50]  # é™åˆ¶é•·åº¦
        
        # ç”Ÿæˆæ™‚é–“æˆ³ï¼ˆå¯è®€æ ¼å¼ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # çµ„åˆæª”åï¼šé¡Œç›®_æ™‚é–“.md
        filename = f"{safe_topic}_{timestamp}.md"
        filepath = os.path.join(report_dir, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"# è¾¯è«–å ±å‘Šï¼š{self.topic}\n\n")
            f.write(f"**ID**: {self.debate_id}\n")
            f.write(f"**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ğŸ† æœ€çµ‚çµè«–\n\n")
            f.write(f"{conclusion}\n\n")

            if jury_report:
                f.write("## âš–ï¸ è©•å¯©åœ˜è©•ä¼°å ±å‘Š\n\n")
                f.write(f"{jury_report}\n\n")
            
            f.write("## ğŸ“ è¾¯è«–éç¨‹è¨˜éŒ„\n\n")
            for item in self.full_history:
                role = item.get("role", "Unknown")
                content = item.get("content", "")
                f.write(f"### {role}\n")
                f.write(f"{content}\n\n")
                f.write("---\n\n")
            
            # Duration Stats
            if start_time and end_time:
                duration = end_time - start_time
                f.write("## â±ï¸ çµ±è¨ˆè³‡è¨Š\n")
                f.write(f"- **é–‹å§‹æ™‚é–“**: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- **çµæŸæ™‚é–“**: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"- **ç¸½è€—æ™‚**: {str(duration).split('.')[0]}\n")
                
        print(f"Report saved to {filepath}")

    def start(self) -> Dict[str, Any]:
        """
        å¼€å§‹è¾©è®ºå¾ªç¯ (Sync wrapper around async start).
        """
        return asyncio.run(self.start_async())

    async def start_async(self) -> Dict[str, Any]:
        """
        å¼€å§‹è¾©è®ºå¾ªç¯ (Async).
        """
        start_time = datetime.now()
        print(f"Debate '{self.debate_id}' has started. Mem: {self._get_memory_usage()}")
        self._publish_log("System", f"Debate '{self.debate_id}' has started.")
        self._publish_progress(5, "åˆå§‹åŒ–è¾¯è«–ç’°å¢ƒ...", "init")
        
        # 0.5 [Phase 18] Database Handshake (Date Awareness)
        self._publish_progress(8, "æ­£åœ¨æª¢æ¸¬è³‡æ–™åº«æœ€æ–°æ—¥æœŸ...", "init")
        await self._check_db_date_async()

        # 0. è³½å‰åˆ†æ
        # [Phase 18] Database Handshake
        await self._check_db_date_async()

        # Check Task LTM for similar past debates
        # [OPTIONAL] Disabled to avoid cold-start issues if not required
        # task_mem = ReMeTaskLongTermMemory()
        # similar_tasks = await task_mem.retrieve_similar_tasks_async(self.topic)
        # if similar_tasks:
        #     print(f"DEBUG: Found similar past debates:\n{similar_tasks}")
        #     self._publish_log("System", f"Found similar past debates:\n{similar_tasks}")

        self._publish_progress(10, "ä¸»å¸­æ­£åœ¨é€²è¡Œè³½å‰åˆ†æ...", "analysis")
        
        # Chairman analysis is now fully async
        self.analysis_result = await self.chairman.pre_debate_analysis(self.topic, debate_id=self.debate_id)
        summary = self.analysis_result.get('step5_summary', 'ç„¡')
        self.chairman.speak(f"è³½å‰åˆ†æå®Œæˆã€‚æˆ°ç•¥æ‘˜è¦ï¼š{summary}")
        self._publish_log("Chairman (Analysis)", f"è³½å‰åˆ†æå®Œæˆã€‚\næˆ°ç•¥æ‘˜è¦ï¼š{summary}")
        
        self._publish_progress(30, "åˆ†æå®Œæˆï¼Œæº–å‚™ Agent å·¥å…·...", "tool_selection")
        
        # 1. Agent å‹•æ…‹é¸æ“‡å·¥å…· (Initialization Phase)
        print("Agents are selecting their tools...")
        self._publish_log("System", "ğŸ¯ è¾¯è«–æº–å‚™éšæ®µï¼šå„ Agent æ­£åœ¨é¸æ“‡æœ€é©åˆçš„å·¥å…·...")
        
        total_agents = sum(len(team['agents']) for team in self.teams)
        if total_agents == 0:
            total_agents = 1 # Avoid division by zero
        
        # Run tool selection sequentially
        self._publish_log("System", f"ğŸš€ å•Ÿå‹• {total_agents} å€‹ Agent é †åºå·¥å…·é¸æ“‡...")
        
        agent_processed_count = 0
        for team in self.teams:
            side = team.get('side', 'neutral')
            for agent in team['agents']:
                 await self._agent_select_tools_async(agent, side)
                 agent_processed_count += 1
                 # Calculate progress from 30% to 90%
                 progress = 30 + int((agent_processed_count / total_agents) * 60)
                 self._publish_progress(progress, f"Agent {agent.name} å·¥å…·é…ç½®å®Œæˆ ({agent_processed_count}/{total_agents})", "tool_selection")

        self._publish_log("System", "âœ… æ‰€æœ‰ Agent å·¥å…·é¸æ“‡å®Œæˆã€‚")
        self._publish_progress(100, "æº–å‚™å°±ç·’ï¼Œè¾¯è«–é–‹å§‹ï¼", "start")

        
        for i in range(1, self.rounds + 1):
            print(f"--- Round {i} --- (Mem: {self._get_memory_usage()})")
            self._publish_log("System", f"--- Round {i} ---")
            round_result = await self._run_round_async(i)
            self.rounds_data.append(round_result)
            
            # [Phase 18] Chairman Emergency Mode (After Round 1)
            if i == 1:
                await self._check_and_trigger_emergency_mode(round_result)
        
        # 4. æœ€çµ‚ç¸½çµ
        handcard = self.analysis_result.get('step6_handcard') or self.analysis_result.get('step5_summary', 'ç„¡æ‰‹å¡')
        final_conclusion = self.chairman.summarize_debate(self.debate_id, self.topic, self.rounds_data, handcard)
        self._publish_log("Chairman (Conclusion)", final_conclusion)

        # 5. Jury è©•ä¼°
        jury_report = self._run_jury_evaluation(final_conclusion)

        # Record outcome to Task LTM
        # [OPTIONAL] Disabled as debates are independent and history is not required
        # task_mem = ReMeTaskLongTermMemory()
        # await task_mem.record_async(self.topic, final_conclusion)
        
        end_time = datetime.now()
        # Save to File (Markdown Report)
        self._save_report_to_file(final_conclusion, jury_report, start_time, end_time)

        print(f"Debate '{self.debate_id}' has ended.")
        self._publish_log("System", f"Debate '{self.debate_id}' has ended.")
        
        # [CLEANUP] Clear Semantic Cache for this debate
        try:
            from api.vector_store import VectorStore
            await VectorStore.delete_by_filter(
                collection_name="llm_semantic_cache",
                filter_conditions={"context": self.debate_id}
            )
            print(f"DEBUG: Cleared semantic cache for debate {self.debate_id}")
        except Exception as e:
            print(f"WARNING: Failed to clear semantic cache: {e}")

        # [Duration Stats]
        total_duration = datetime.now() - start_time
        duration_msg = f"ğŸ è¾¯è«–çµæŸã€‚ç¸½è€—æ™‚: {str(total_duration).split('.')[0]}"
        
        # [Phase 6] Cache Stats & Metrics
        cache_stats = self.hippocampus.stats
        total_reqs = cache_stats['wm_hits'] + cache_stats['wm_misses']
        hit_rate = (cache_stats['wm_hits'] / total_reqs * 100) if total_reqs > 0 else 0
        
        # Semantic Cache Stats
        from worker.llm_utils import _semantic_cache_buffer
        sem_hits = _semantic_cache_buffer.stats["hits"]
        sem_misses = _semantic_cache_buffer.stats["misses"]
        sem_total = sem_hits + sem_misses
        sem_hit_rate = (sem_hits / sem_total * 100) if sem_total > 0 else 0
        
        avg_latency = (self.tool_stats["total_time"] / self.tool_stats["count"]) if self.tool_stats["count"] > 0 else 0
        
        stats_msg = f"ğŸ“Š Cache Stats: WM Hit {hit_rate:.1f}% | Sem Hit {sem_hit_rate:.1f}% | Saved Calls: {cache_stats['wm_hits'] + sem_hits}"
        perf_msg = f"âš¡ Perf: Avg Tool Latency {avg_latency:.2f}s | Est Cost: ${self.tool_stats['estimated_cost']:.2f}"
        
        detailed_stats = {
            "hippocampus_hit_rate": hit_rate,
            "semantic_cache_hit_rate": sem_hit_rate,
            "api_calls_saved": cache_stats['wm_hits'] + sem_hits,
            "total_api_cost": self.tool_stats["estimated_cost"],
            "qdrant_writes": cache_stats['ltm_writes'],
            "avg_tool_latency": avg_latency
        }
        
        print(f"[{datetime.now().strftime('%H:%M:%S')}] {duration_msg}")
        print(f"DEBUG: FINAL METRICS: {json.dumps(detailed_stats, indent=2)}")
        
        self._publish_log("System", duration_msg)
        self._publish_log("System", stats_msg)
        self._publish_log("System", perf_msg)

        # Send explicit DONE signal to close the stream
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", "[DONE]")
        
        return {
            "topic": self.topic,
            "rounds_data": self.rounds_data,
            "analysis": self.analysis_result,
            "final_conclusion": final_conclusion,
            "jury_report": jury_report
        }

    async def _check_db_date_async(self):
        """
        [Phase 18] Handshake with DB to find the latest available date.
        Uses TSMC (2330.TW) as a canary to probe database freshness.
        """
        try:
            from worker.tool_invoker import call_tool
            loop = asyncio.get_running_loop()
            
            # Probe recent 60 days
            today = datetime.now()
            start_date = (today - timedelta(days=60)).strftime("%Y-%m-%d")
            end_date = today.strftime("%Y-%m-%d")
            
            params = {
                "coid": "2330.TW",
                "mdate.gte": start_date,
                "mdate.lte": end_date,
                # Fetch all in range to find max date manually (safer than relying on sort param support)
            }
            
            self._publish_log("System", f"ğŸ” æ­£åœ¨æª¢æ¸¬è³‡æ–™åº«æœ€æ–°æ—¥æœŸ (Probe: 2330.TW)...")
            
            result = await loop.run_in_executor(None, call_tool, "tej.stock_price", params)
            
            found_date = None
            if isinstance(result, dict):
                 data = result.get("data") or result.get("results")
                 if isinstance(data, list) and data:
                     # Find max date
                     dates = []
                     for row in data:
                         d = row.get("mdate")
                         if d:
                             dates.append(str(d).split("T")[0])
                     
                     if dates:
                         found_date = max(dates)
            
            # [Fix] Fallback Probe with Multi-Step Query (Chunking)
            # If recent data missing, look back iteratively in 90-day chunks up to 1 year
            if not found_date:
                self._publish_log("System", "âš ï¸ ç„¡è¿‘æœŸæ•¸æ“šï¼Œå•Ÿå‹•é•·é€±æœŸå›æº¯æœç´¢ (Multi-Step Probe)...")
                
                # Try up to 4 quarters back (approx 1 year)
                for i in range(1, 5):
                    # Calculate chunk window (shifting back 90 days each time)
                    # Window: [Today - 90*(i+1), Today - 90*i]
                    # But we want continuous coverage backward.
                    # Previous probe was [Today-60, Today]
                    # Let's do strictly 90-day chunks backward from Today-60
                    
                    chunk_end_dt = today - timedelta(days=60 + (i-1)*90)
                    chunk_start_dt = chunk_end_dt - timedelta(days=90)
                    
                    chunk_start = chunk_start_dt.strftime("%Y-%m-%d")
                    chunk_end = chunk_end_dt.strftime("%Y-%m-%d")
                    
                    self._publish_log("System", f"ğŸ” å›æº¯æ¢æ¸¬ ({i}/4): {chunk_start} ~ {chunk_end}")
                    
                    params_chunk = {
                        "coid": "2330.TW",
                        "mdate.gte": chunk_start,
                        "mdate.lte": chunk_end,
                        "opts.limit": 100,
                        "sort": "mdate.desc"
                    }
                    
                    try:
                        result_chunk = await loop.run_in_executor(None, call_tool, "tej.stock_price", params_chunk)
                        if isinstance(result_chunk, dict):
                             data = result_chunk.get("data") or result_chunk.get("results")
                             if isinstance(data, list) and data:
                                 dates = []
                                 for row in data:
                                     d = row.get("mdate")
                                     if d:
                                         dates.append(str(d).split("T")[0])
                                 if dates:
                                     found_date = max(dates)
                                     self._publish_log("System", f"âœ… åœ¨å›æº¯ä¸­æ‰¾åˆ°æ•¸æ“š: {found_date}")
                                     break # Found it, stop looking back
                    except Exception as ex:
                        print(f"Probe chunk failed: {ex}")
                        continue

            if found_date:
                self.latest_db_date = found_date
                self._publish_log("System", f"ğŸ“… è³‡æ–™åº«æœ€æ–°æ•¸æ“šæ—¥æœŸç¢ºèª: {self.latest_db_date}")
            else:
                self._publish_log("System", f"âš ï¸ ç„¡æ³•ç¢ºèªè³‡æ–™åº«æ—¥æœŸ (å…©æ¬¡æ¢æ¸¬çš†å¤±æ•—)ã€‚")
                # Fallback: Don't set a fake date, just leave as None.
                self.latest_db_date = None

        except Exception as e:
            print(f"DB Handshake Failed: {e}")
            self._publish_log("System", f"âš ï¸ è³‡æ–™åº«é€£ç·šæª¢æŸ¥å¤±æ•—: {e}")

    async def _check_and_trigger_emergency_mode(self, round_result: Dict):
        """
        [Phase 18] Chairman Emergency Research Mode.
        Checks if Round 1 was full of "Insufficient Data" claims.
        """
        team_summaries = round_result.get("team_summaries", {})
        combined_text = " ".join(team_summaries.values())
        
        # Heuristic: Detect keywords implying lack of data
        # Note: Agents might hallucinate, so we also check if Evidence logs were empty?
        # But we only have text summaries here easily.
        # Let's check for specific keywords we injected or standard complaints.
        triggers = ["è³‡æ–™ä¸è¶³", "ç„¡æ³•ç²å–æ•¸æ“š", "ç„¡æ•¸æ“š", "Insufficient Data", "empty result"]
        hit_count = sum(1 for t in triggers if t in combined_text)
        
        if hit_count >= 1: # Low threshold for safety, or check evidence_log directly
            # Check redis evidence for emptiness/errors
            # Implementation detail: fetch recent evidence
            pass # Keep it simple for now based on text
            
            self._publish_log("Chairman", "ğŸš¨ åµæ¸¬åˆ°è³‡æ–™åš´é‡ä¸è¶³ (Emergency Mode Triggered)ã€‚ä¸»å¸­ä»‹å…¥èª¿æŸ¥...")

            # 1. Force enable 'searxng.search' for all agents
            enabled_count = 0
            for agent_name, tools in self.agent_tools_map.items():
                if "searxng.search" not in tools:
                    tools.append("searxng.search")
                    self.agent_tools_map[agent_name] = tools
                    enabled_count += 1
            
            if enabled_count > 0:
                self._publish_log("System", f"ğŸ”§ å·²å¼·åˆ¶ç‚º {enabled_count} ä½ Agent é–‹å•Ÿå¤–éƒ¨æœå°‹å·¥å…· (searxng.search)ã€‚")

            # 2. Chairman performs web search
            from worker.tool_invoker import call_tool
            loop = asyncio.get_running_loop()
            
            search_q = f"{self.topic} news analysis stock price reasons"
            search_res = await loop.run_in_executor(None, call_tool, "searxng.search", {"q": search_q})
            
            context_inject = f"ã€ä¸»å¸­ç·Šæ€¥è£œå……è³‡è¨Šã€‘\nç”±æ–¼å…§éƒ¨è³‡æ–™åº«å›æ‡‰æœ‰é™ï¼Œä¸»å¸­æä¾›äº†å¤–éƒ¨æœå°‹çµæœï¼š\n{str(search_res)[:800]}..."
            
            # Inject into History so all agents see it next
            self.history.append({"role": "Chairman (Intervention)", "content": context_inject})
            self.full_history.append({"role": "Chairman (Intervention)", "content": context_inject})
            
            # Also push to Memory
            await self.history_memory.add_turn_async("Chairman (Intervention)", context_inject, 1)

    def _run_jury_evaluation(self, final_conclusion: str) -> str:
        """
        åŸ·è¡Œè©•å¯©åœ˜ (Jury) è©•ä¼°ï¼Œç”Ÿæˆè©•åˆ†èˆ‡åˆ†æå ±å‘Šã€‚
        """
        print("Jury is evaluating the debate...")
        self._publish_log("System", "è©•å¯©åœ˜æ­£åœ¨é€²è¡Œæœ€çµ‚è©•ä¼°...")

        try:
            # Load Jury System Prompt
            file_system_prompt = "ä½ æ˜¯è¾¯è«–è©•å¯©åœ˜ã€‚"
            try:
                with open("prompts/agents/jury.yaml", "r", encoding="utf-8") as f:
                    jury_config = yaml.safe_load(f)
                    file_system_prompt = jury_config.get("system_prompt", file_system_prompt)
            except Exception as e:
                print(f"Warning: Failed to load jury.yaml: {e}")

            db = SessionLocal()
            try:
                system_prompt = PromptService.get_prompt(db, "jury.system_prompt", default=file_system_prompt)
                
                # Load User Prompt Template (Moved from hardcoded)
                user_template = PromptService.get_prompt(db, "debate.jury_evaluation_user")
                if not user_template:
                    user_template = "è«‹è©•ä¼°ä»¥ä¸‹è¾¯è«–ï¼š\n{debate_log}" # Minimal fallback
            finally:
                db.close()
            
            # æ§‹å»ºå®Œæ•´è¾¯è«–è¨˜éŒ„æ–‡å­—
            debate_log = ""
            for item in self.full_history:
                role = item.get("role", "Unknown")
                content = item.get("content", "")
                debate_log += f"[{role}]: {content}\n\n"
                
            debate_log += f"[Chairman Final Conclusion]: {final_conclusion}\n"

            # Fill template
            user_prompt = user_template.format(topic=self.topic, debate_log=debate_log)

            # Call LLM
            jury_report = call_llm(user_prompt, system_prompt=system_prompt)
            # Note: Sync call_llm doesn't support context_tag yet, but jury uses sync wrapper?
            # Wait, `call_llm` is sync. `_run_jury_evaluation` uses `call_llm` (sync).
            # The async `call_llm_async` supports context_tag.
            # I should update `call_llm` (sync) to support context_tag?
            # Or just update the async calls.
            # `_run_jury_evaluation` is SYNC method.
            
            self._publish_log("Jury", jury_report)
            print("Jury evaluation completed.")
            return jury_report
            
        except Exception as e:
            error_msg = f"Jury evaluation failed: {str(e)}"
            print(error_msg)
            self._publish_log("System", error_msg)
            return error_msg

    def _update_team_score(self, side: str, delta: float, reason: str):
        """
        æ›´æ–°åœ˜éšŠè©•åˆ†ä¸¦æ¨é€é€šçŸ¥ã€‚
        """
        score_key = f"debate:{self.debate_id}:scores"
        # Initial scores if not set (default 100)
        if not self.redis_client.hexists(score_key, side):
            self.redis_client.hset(score_key, side, 100.0)
        
        new_score = self.redis_client.hincrbyfloat(score_key, side, delta)
        
        # Publish score update event
        event_data = {
            "type": "score_update",
            "side": side,
            "new_score": new_score,
            "delta": delta,
            "reason": reason,
            "timestamp": datetime.now().isoformat()
        }
        self.redis_client.publish(f"debate:{self.debate_id}:log_stream", json.dumps(event_data, ensure_ascii=False))
        self._publish_log("System (Score)", f"âš–ï¸ ã€{side}ã€‘åˆ†æ•¸è®Šæ›´: {delta} ({reason}) => ç•¶å‰åˆ†æ•¸: {new_score}")

    def _neutral_verification_turn(self, agent: AgentBase, team_name: str, round_num: int) -> str:
        return asyncio.run(self._neutral_verification_turn_async(agent, team_name, round_num))

    async def _neutral_verification_turn_async(self, agent: AgentBase, team_name: str, round_num: int) -> str:
        """
        ä¸­ç«‹æ–¹çš„ç‰¹æ®Šå›åˆï¼šæ ¸å¯¦è­‰æ“šä¸¦é€²è¡Œè©•åˆ† (Async)ã€‚
        """
        print(f"Neutral Agent {agent.name} is verifying evidence...")
        self._publish_log(f"{agent.name} (Verification)", "ğŸ” æ­£åœ¨å¯©æŸ¥å„æ–¹æå‡ºçš„è­‰æ“šé€²è¡Œæ ¸å¯¦...")

        # 1. Fetch unverified evidence from Redis
        all_evidence = [json.loads(e) for e in self.redis_client.lrange(self.evidence_key, 0, -1)]
        
        # [Governance] Check against Verified Set
        verified_set = self.redis_client.smembers(f"debate:{self.debate_id}:verified_evidence")
        # Redis client returns strings directly due to decode_responses=True
        verified_set = verified_set if verified_set else set()
        
        target_evidence = []
        for e in all_evidence:
            if e.get('side') == 'neutral': continue
            
            # Robust Signature check
            ev_sig = f"{e.get('timestamp')}-{e.get('tool')}"
            if ev_sig in verified_set: continue
            
            target_evidence.append(e)
        
        verification_report = ""
        
        if not target_evidence:
            return await self._agent_turn_async(agent, 'neutral', round_num) # Fallback to normal turn if no evidence

        # 2. Verify each evidence (Limit to 1-2 to save time/cost)
        # Sort by importance? For now, FIFO from the list we filtered.
        for i, ev in enumerate(target_evidence[:2]):
            tool_name = ev.get('tool')
            params = ev.get('params')
            original_result = ev.get('result')
            provider_side = ev.get('side', 'Unknown')
            provider_agent = ev.get('agent_name', 'Unknown')
            
            self._publish_log(f"{agent.name} (Verification)", f"æ­£åœ¨æ ¸å¯¦ {provider_side} æ–¹ ({provider_agent}) ä½¿ç”¨çš„å·¥å…·: {tool_name}...")
            
            try:
                # Re-execute tool (Upgrade: Use Verified Price for stock/index tools)
                from worker.tool_invoker import call_tool
                loop = asyncio.get_running_loop()
                
                # [Governance] Neutral should use the Auditor Tool for price verification
                # Check ALL price-related tools
                price_tools = ["tej.stock_price", "yahoo.stock_price", "twse.stock_day", "financial.get_verified_price"]
                verify_result = None
                is_auditor_check = False
                
                if tool_name in price_tools:
                    # Extract symbol/date from params
                    # Different tools have different param names, so we normalize here
                    v_symbol = params.get("coid") or params.get("symbol")
                    # Try to find a date
                    v_date = params.get("mdate.gte") or params.get("start_date") or params.get("date")
                    
                    if v_symbol and v_date:
                        self._publish_log(f"{agent.name} (Verification)", f"âš¡ åˆ‡æ›è‡³å¯©è¨ˆå·¥å…· (financial.get_verified_price) é€²è¡Œäº¤å‰é©—è­‰...")
                        # Use Auditor Tool
                        # [Fix] Ensure date format is YYYYMMDD for TWSE (financial.get_verified_price)
                        # v_date usually comes as YYYY-MM-DD from TEJ params.
                        clean_date = str(v_date)[:10].replace("-", "")
                        verify_result = await loop.run_in_executor(None, call_tool, "financial.get_verified_price", {"symbol": v_symbol, "date": clean_date})
                        is_auditor_check = True
                
                # If not price tool or param extraction failed, fall back to exact re-execution
                if verify_result is None:
                    # Regular re-execution for other tools (Bypass Cache)
                    params_bypass = params.copy()
                    params_bypass["_bypass_cache"] = True
                    verify_result = await loop.run_in_executor(None, call_tool, tool_name, params_bypass)

                # --- Programmatic Pre-Check ---
                # Check for "Empty vs Non-Empty" discrepancy specifically for Auditor Checks
                programmatic_fail = False
                fail_reason = ""
                
                if is_auditor_check:
                    # Original result empty?
                    orig_empty = False
                    if isinstance(original_result, dict) and (not original_result.get("data") and not original_result.get("results")):
                        orig_empty = True
                    elif isinstance(original_result, list) and not original_result:
                        orig_empty = True
                        
                    # Verify result empty?
                    verify_empty = False
                    if isinstance(verify_result, dict) and (not verify_result.get("data") and not verify_result.get("results")):
                        verify_empty = True
                    elif isinstance(verify_result, list) and not verify_result:
                        verify_empty = True
                        
                    # Case: Agent claimed data but Auditor says empty (Hallucination of Data Existence?)
                    # OR: Agent said empty but Auditor found data (Laziness?) -> Less severe
                    # Most severe: Agent output fabricated numbers (not easy to check programmatically without parsing numbers)
                    pass

                # Construct verification prompt via PromptService
                db = SessionLocal()
                try:
                    comp_template = PromptService.get_prompt(db, "neutral.verification_comparison")
                    if not comp_template:
                        comp_template = """
è«‹æ“”ä»»ã€Œæ•¸æ“šæ ¸å¯¦å“¡ã€ï¼Œæ¯”è¼ƒå…©ä»½å·¥å…·åŸ·è¡Œçµæœä¸¦åˆ¤æ–·æ˜¯å¦ä¸€è‡´ã€‚

ã€å·¥å…·è³‡è¨Šã€‘
å·¥å…·ï¼š{tool_name}
åƒæ•¸ï¼š{params}
ä¾†æºï¼š{provider_side} ({provider_agent})

ã€åŸåŸ·è¡Œçµæœ (Original)ã€‘
{original_result_preview}

ã€æ ¸å¯¦åŸ·è¡Œçµæœ (Auditor Verification)ã€‘
{verify_result_preview}

ã€åˆ¤æ–·æ¨™æº–ã€‘
1. **æ•¸æ“šä¸€è‡´æ€§**: æ•¸å€¼æ˜¯å¦å¤§è‡´ç›¸åŒï¼Ÿï¼ˆå…è¨±å¾®å°èª¤å·®ï¼‰
2. **ç„¡ä¸­ç”Ÿæœ‰ (Hallucination)**: è‹¥åŸçµæœæœ‰æ•¸æ“šï¼Œä½†æ ¸å¯¦çµæœç‚ºã€Œç©º (Empty/No Data)ã€ï¼Œå‰‡è¦–ç‚ºåš´é‡é•è¦ï¼ˆç·¨é€ æ•¸æ“šï¼‰ã€‚
3. **æ ¼å¼å·®ç•°**: è‹¥åƒ…æ˜¯æ ¼å¼ä¸åŒä½†å…§å®¹å¯¦è³ªç›¸åŒï¼Œè¦–ç‚ºä¸€è‡´ã€‚

è«‹è¼¸å‡º JSON æ ¼å¼ï¼š
{{
    "consistent": true/false,
    "score_penalty": 0 åˆ° -10 (è‹¥åš´é‡é•è¦è«‹æ‰£åˆ†),
    "comment": "ç°¡çŸ­è©•èª"
}}
"""
                finally:
                    db.close()

                comparison_prompt = comp_template.format(
                    tool_name=tool_name,
                    params=params,
                    provider_side=provider_side,
                    provider_agent=provider_agent,
                    original_result_preview=str(original_result)[:1500],
                    verify_result_preview=str(verify_result)[:1500]
                )

                # Call LLM for judgement
                judge_response = await call_llm_async(comparison_prompt, system_prompt="ä½ æ˜¯å…¬æ­£çš„æ•¸æ“šæ ¸å¯¦å“¡ã€‚è«‹åš´æ ¼æªå‡ºç·¨é€ æ•¸æ“šçš„è¡Œç‚ºã€‚", context_tag=f"{self.debate_id}:{agent.name}:Verification")
                
                # Parse JSON
                try:
                    # Robust JSON extraction
                    json_match = re.search(r'\{.*\}', judge_response, re.DOTALL)
                    if json_match:
                        judge_json = json.loads(json_match.group(0))
                        
                        consistent = judge_json.get('consistent', True)
                        penalty = judge_json.get('score_penalty', 0)
                        comment = judge_json.get('comment', '')
                        
                        # [Governance] Apply specific penalties for Hallucination
                        if not consistent:
                             # Ensure negative
                             if penalty > 0: penalty = -penalty
                             if penalty == 0: penalty = -5 # Default penalty
                        
                        if consistent:
                            verification_report += f"- âœ… æ ¸å¯¦é€šé ({tool_name}): æ•¸æ“šä¸€è‡´ã€‚\n"
                        else:
                            verification_report += f"- âŒ æ ¸å¯¦å¤±æ•— ({tool_name}): {comment} (æ‰£åˆ†: {penalty})\n"
                            if penalty < 0:
                                self._update_team_score(provider_side, float(penalty), f"è­‰æ“šæ ¸å¯¦å¤±æ•— ({provider_agent}): {comment}")
                    else:
                        verification_report += f"- âš ï¸ ç„¡æ³•åˆ¤æ–· ({tool_name}): {judge_response[:50]}...\n"

                except Exception as e:
                    print(f"Verification judgment parsing error: {e}")
                    verification_report += f"- âš ï¸ æ ¸å¯¦åˆ¤è®€éŒ¯èª¤ ({tool_name})\n"
                
                # [Optimization] Mark evidence as verified in Redis
                ev_sig = f"{ev.get('timestamp')}-{tool_name}"
                self.redis_client.sadd(f"debate:{self.debate_id}:verified_evidence", ev_sig)

            except Exception as e:
                verification_report += f"- âš ï¸ å·¥å…·é‡è·‘å¤±æ•— ({tool_name}): {e}\n"

        # 3. Generate Speech based on verification
        db = SessionLocal()
        try:
            final_template = PromptService.get_prompt(db, "neutral.verification_speech")
            if not final_template:
                final_template = "ä½ æ˜¯ä¸­ç«‹æ–¹ã€‚è«‹æ ¹æ“šæ ¸å¯¦å ±å‘Šç™¼è¨€ï¼š{verification_report}"
        finally:
            db.close()

        final_prompt = final_template.format(
            agent_name=agent.name,
            round_num=round_num,
            verification_report=verification_report
        )
        
        response = await call_llm_async(final_prompt, system_prompt=f"ä½ æ˜¯ {agent.name}ï¼Œå…¬æ­£çš„ç¬¬ä¸‰æ–¹ã€‚", context_tag=f"{self.debate_id}:{agent.name}:Speech")
        return response

    def _run_round(self, round_num: int) -> Dict[str, Any]:
         """Sync wrapper around async _run_round_async"""
         return asyncio.run(self._run_round_async(round_num))

    async def _run_cross_examination_async(self, round_num: int, team_summaries: Dict[str, str]):
        """
        åŸ·è¡Œäº¤å‰è³ªè©¢ç’°ç¯€ (Async)ã€‚
        """
        # ç°¡å–®ç­–ç•¥ï¼šPro è³ªè©¢ Conï¼Œç„¶å¾Œ Con è³ªè©¢ Pro
        # å¦‚æœæœ‰ Neutralï¼Œå‰‡ Neutral å¯ä»¥è³ªè©¢é›™æ–¹
        
        # Identify teams
        pro_team = next((t for t in self.teams if t.get('side') == 'pro'), None)
        con_team = next((t for t in self.teams if t.get('side') == 'con'), None)
        
        if not pro_team or not con_team:
            return

        pairs = [
            (pro_team, con_team), # Pro asks Con
            (con_team, pro_team)  # Con asks Pro
        ]
        
        for attacker, defender in pairs:
            attacker_name = attacker['name']
            defender_name = defender['name']
            defender_summary = team_summaries.get(defender_name, "")
            
            # Select representative agent (e.g., first one)
            attacker_agent = attacker['agents'][0]
            defender_agent = defender['agents'][0]
            
            # 1. Attacker Generates Question
            self._publish_log(attacker_name, f"æ­£åœ¨æ§‹æ€å° {defender_name} çš„è³ªè©¢å•é¡Œ...")
            
            db = SessionLocal()
            try:
                q_template = PromptService.get_prompt(db, "debate.cross_exam_question")
                if not q_template: q_template = "åŸºæ–¼å°æ–¹çš„è«–é»ï¼š{opponent_summary}ï¼Œè«‹æå‡ºä¸€å€‹çŠ€åˆ©çš„åé§å•é¡Œã€‚"
            finally:
                db.close()
                
            q_prompt = q_template.format(opponent_summary=defender_summary)
            question = await call_llm_async(q_prompt, system_prompt=f"ä½ æ˜¯ {attacker_name} çš„è¾¯æ‰‹ã€‚", context_tag=f"{self.debate_id}:CrossExam:Q:{attacker_name}")
            
            self._publish_log(f"{attacker_name} (Q)", f"â“ è³ªè©¢ï¼š{question}")
            self.history.append({"role": f"{attacker_name} (Cross-Exam Q)", "content": question})
            self.full_history.append({"role": f"{attacker_name} (Cross-Exam Q)", "content": question})
            
            # 2. Defender Answers
            self._publish_log(defender_name, f"æ­£åœ¨æ€è€ƒå¦‚ä½•å›ç­” {attacker_name} çš„è³ªè©¢...")
            
            db = SessionLocal()
            try:
                a_template = PromptService.get_prompt(db, "debate.cross_exam_answer")
                if not a_template: a_template = "å°æ–¹å•é¡Œï¼š{question}ã€‚è«‹æ ¹æ“šæˆ‘æ–¹ç«‹å ´é€²è¡Œåé§èˆ‡å›ç­”ã€‚"
            finally:
                db.close()
                
            a_prompt = a_template.format(question=question)
            answer = await call_llm_async(a_prompt, system_prompt=f"ä½ æ˜¯ {defender_name} çš„è¾¯æ‰‹ã€‚", context_tag=f"{self.debate_id}:CrossExam:A:{defender_name}")
            
            self._publish_log(f"{defender_name} (A)", f"ğŸ’¡ å›ç­”ï¼š{answer}")
            self.history.append({"role": f"{defender_name} (Cross-Exam A)", "content": answer})
            self.full_history.append({"role": f"{defender_name} (Cross-Exam A)", "content": answer})

    async def _run_round_async(self, round_num: int) -> Dict[str, Any]:
        """
        è¿è¡Œä¸€è½®è¾©è®º (Async, Parallel Team Execution).
        åŒ…å«ï¼šå„åœ˜éšŠå…§éƒ¨è¨è«– (Parallel) -> åœ˜éšŠç¸½çµ -> ä¸»å¸­å½™æ•´èˆ‡ä¸‹ä¸€è¼ªå¼•å°
        """
        from worker import tasks # Lazy import to avoid circular dependency
        
        # 1. ä¸»å¸­å¼•å¯¼
        opening = f"ç°åœ¨é–‹å§‹ç¬¬ {round_num} è¼ªè¾¯è«–ã€‚"
        self.chairman.speak(opening)
        self.history.append({"role": "Chairman", "content": opening})
        self.full_history.append({"role": "Chairman", "content": opening})
        self._publish_log("Chairman", opening)

        # 2. å„åœ˜éšŠå…§éƒ¨è¾¯è«–èˆ‡ç¸½çµ (Intra-Team Debate & Summary)
        round_team_summaries = {}
        
        total_teams = len(self.teams)
        
        # Run all teams sequentially
        self._publish_log("System", f"ğŸš€ å•Ÿå‹• {total_teams} éšŠé †åºè¨è«–...")
        team_results = []
        for team in self.teams:
            result = await self._process_team_deliberation(team, round_num)
            team_results.append(result)
        
        # Process results from all teams
        for team_result in team_results:
            team_name = team_result['name']
            team_summary = team_result['summary']
            discussion_log = team_result['log']
            
            round_team_summaries[team_name] = team_summary
            
            # Store history (Note: Order might be mixed in real-time logs, but here we append block by block)
            # Ideally, we want to interleave them in history based on timestamp, but for simplicity:
            for item in discussion_log:
                 self.history.append(item)
                 self.full_history.append(item)
                 # RAG Recording (Buffered via self.history_memory)
                 await self.history_memory.add_turn_async(item['role'], str(item['content']), round_num)
            
            self.history.append({"role": f"{team_name} Summary", "content": team_summary})
            self.full_history.append({"role": f"{team_name} Summary", "content": team_summary})
            
            await self.history_memory.add_turn_async(f"{team_name} Summary", team_summary, round_num)
            
        # [Hippocampus] Trigger Memory Consolidation
        self._publish_log("System", "ğŸ§  æ­£åœ¨é€²è¡Œæµ·é¦¬è¿´è¨˜æ†¶éå›º (Consolidating Working Memory)...")
        await self.hippocampus.consolidate()
        
        # [Optimization] Flush LTM buffers
        self._publish_log("System", "ğŸ’¾ æ­£åœ¨åŒæ­¥é•·æœŸè¨˜æ†¶ (Flushing LTM Buffers)...")
        await self.history_memory.flush()
        await self.tool_memory.flush()
        
        # [Phase 18] Chairman Emergency Mode Check (After Round 1)
        if round_num == 1:
            await self._check_and_trigger_emergency_mode(round_team_summaries)

        # 2.5 äº¤å‰è³ªè©¢ (Cross-Examination)
        if self.enable_cross_examination:
            self._publish_log("Chairman", f"é€²å…¥ç¬¬ {round_num} è¼ªäº¤å‰è³ªè©¢ç’°ç¯€ (Cross-Examination)...")
            await self._run_cross_examination_async(round_num, round_team_summaries)

        # 3. ä¸»å¸­å½™æ•´èˆ‡ä¸‹ä¸€è¼ªæ–¹å‘
        handcard = self.analysis_result.get('step6_handcard') or self.analysis_result.get('step5_summary', 'ç„¡æ‰‹å¡')
        
        # è‡¨æ™‚æ–¹æ¡ˆï¼šå°‡ team_summaries å¯«å…¥ Redis evidenceï¼Œè®“ä¸»å¸­è®€å–åˆ°
        for t_name, t_summary in round_team_summaries.items():
            summary_evidence = {
                "role": f"{t_name} Summary",
                "content": t_summary,
                "type": "team_summary"
            }
            self.redis_client.rpush(self.evidence_key, json.dumps(summary_evidence, ensure_ascii=False))
            
        next_direction = self.chairman.summarize_round(self.debate_id, round_num, handcard=handcard)
        self._publish_log("Chairman", f"Round {round_num} summary completed. Next Direction: {next_direction}")
        
        # å°‡ä¸‹ä¸€è¼ªæ–¹å‘åŠ å…¥æ­·å²ï¼Œä¾›ä¸‹ä¸€è¼ª Agent åƒè€ƒ
        self.history.append({"role": "Chairman (Next Direction)", "content": next_direction})
        self.full_history.append({"role": "Chairman (Next Direction)", "content": next_direction})
        
        # [Debug] Save Round Log
        self._save_round_debug_log(round_num, round_team_summaries)
        
        return {
            "round": round_num,
            "team_summaries": round_team_summaries,
            "next_direction": next_direction
        }
        
    async def _check_and_trigger_emergency_mode(self, summaries: Dict[str, str]):
        """
        Check if agents are failing to get data and trigger emergency web search.
        """
        # Heuristic: If summaries contain keywords like "no data", "empty", "lack of evidence"
        failure_signals = ["no data", "empty", "lack of evidence", "æŸ¥ç„¡è³‡æ–™", "æ•¸æ“šä¸è¶³", "ç„¡æ³•é©—è­‰"]
        combined_text = " ".join(summaries.values()).lower()
        
        score = sum(1 for s in failure_signals if s in combined_text)
        
        if score >= 2: # Threshold
            self._publish_log("Chairman (Emergency)", "ğŸš¨ åµæ¸¬åˆ°å¤šæ–¹æ•¸æ“šä¸è¶³ã€‚ä¸»å¸­å•Ÿå‹•ã€Œç·Šæ€¥ç ”ç©¶æ¨¡å¼ (Emergency Research Mode)ã€ï¼")
            self._publish_log("System", "ğŸ”“ å¼·åˆ¶è§£é– Web Search å·¥å…·çµ¦æ‰€æœ‰ Agent...")
            
            # Force enable search tools for everyone
            # This is a bit hacky, we assume agents can use 'searxng.search' if we tell them,
            # or we need to update tool_registry?
            # Actually, agents select tools at start. We can't easily inject new tools into their `agent_tools_map` unless we update it.
            
            for agent_name in self.agent_tools_map:
                if "searxng.search" not in self.agent_tools_map[agent_name]:
                    self.agent_tools_map[agent_name].append("searxng.search")
                    
            # Inject a system note into history
            msg = "ã€ä¸»å¸­æŒ‡ä»¤ã€‘é‘‘æ–¼å…§éƒ¨æ•¸æ“šåº«è³‡æ–™ä¸è¶³ï¼Œç¾å·²é–‹æ”¾ç¶²çµ¡æœç´¢æ¬Šé™ã€‚è«‹å–„ç”¨ `searxng.search` æŸ¥æ‰¾å¤–éƒ¨æ–°èèˆ‡å ±å‘Šä¾†è£œå……è«–é»ã€‚"
            self.history.append({"role": "Chairman (System)", "content": msg})
            self.full_history.append({"role": "Chairman (System)", "content": msg})

    async def _check_and_trigger_emergency_mode(self, round_result: Dict):
        """
        Check if agents are failing to get data and trigger emergency web search.
        """
        # Heuristic: If summaries contain keywords like "no data", "empty", "lack of evidence"
        team_summaries = round_result.get("team_summaries", {})
        combined_text = " ".join(team_summaries.values()).lower()
        
        failure_signals = ["no data", "empty", "lack of evidence", "æŸ¥ç„¡è³‡æ–™", "æ•¸æ“šä¸è¶³", "ç„¡æ³•é©—è­‰"]
        score = sum(1 for s in failure_signals if s in combined_text)
        
        if score >= 2: # Threshold
            self._publish_log("Chairman (Emergency)", "ğŸš¨ åµæ¸¬åˆ°å¤šæ–¹æ•¸æ“šä¸è¶³ã€‚ä¸»å¸­å•Ÿå‹•ã€Œç·Šæ€¥ç ”ç©¶æ¨¡å¼ (Emergency Research Mode)ã€ï¼")
            self._publish_log("System", "ğŸ”“ å¼·åˆ¶è§£é– Web Search å·¥å…·çµ¦æ‰€æœ‰ Agent...")
            
            # Force enable search tools for everyone
            for agent_name in self.agent_tools_map:
                if "searxng.search" not in self.agent_tools_map[agent_name]:
                    self.agent_tools_map[agent_name].append("searxng.search")
                    
            # Inject a system note into history
            msg = "ã€ä¸»å¸­æŒ‡ä»¤ã€‘é‘‘æ–¼å…§éƒ¨æ•¸æ“šåº«è³‡æ–™ä¸è¶³ï¼Œç¾å·²é–‹æ”¾ç¶²çµ¡æœç´¢æ¬Šé™ã€‚è«‹å–„ç”¨ `searxng.search` æŸ¥æ‰¾å¤–éƒ¨æ–°èèˆ‡å ±å‘Šä¾†è£œå……è«–é»ã€‚"
            self.history.append({"role": "Chairman (System)", "content": msg})
            self.full_history.append({"role": "Chairman (System)", "content": msg})

    async def _process_team_deliberation(self, team: Dict, round_num: int) -> Dict[str, Any]:
        """
        Process a single team's deliberation asynchronously.
        """
        team_name = team['name']
        team_side = team.get('side', 'neutral')
        team_agents = team['agents']
        total_agents_in_team = len(team_agents)
        
        team_icon = "ğŸŸ¦" if team_side == "pro" else "ğŸŸ¥" if team_side == "con" else "ğŸŸ©"
        self._publish_log("System", f"{team_icon} ã€{team_name}ã€‘é–‹å§‹å…§éƒ¨è¨è«–...")
        
        team_discussion_log_text = [] # For summary generation
        team_history_entries = [] # For returning to main thread
        
        # Within a team, agents might still need to speak in order, OR parallel?
        # Usually debate implies responding to each other.
        # However, "Intra-Team Debate" in this simplified version is just each agent speaking once.
        # We can make agents within a team parallel too!
        
        agent_results = []
        for agent in team_agents:
            if team_side == "neutral":
                 content = await self._neutral_verification_turn_async(agent, team_name, round_num)
            else:
                 content = await self._agent_turn_async(agent, team_name, round_num)
            agent_results.append(content)
        
        for idx, (agent, content) in enumerate(zip(team_agents, agent_results)):
             role_label = f"{team_name} - {agent.name}"
             
             entry = {"role": role_label, "content": content}
             team_history_entries.append(entry)
             team_discussion_log_text.append(f"{agent.name}: {content}")
             
             # Publish individual log (Note: Might arrive out of order visually if not carefully handled on frontend,
             # but here we publish as soon as done)
             self._publish_log(role_label, content)

        # ç”Ÿæˆåœ˜éšŠå…±è­˜èˆ‡åˆ†æ­§ç¸½çµ
        self._publish_log("System", f"ğŸ“Š {team_name} æ­£åœ¨æ•´ç†åœ˜éšŠå…±è­˜...")
        team_summary = await self._generate_team_summary_async(team_name, team_discussion_log_text)
        self._publish_log(f"{team_name} (Summary)", team_summary)
        
        return {
            "name": team_name,
            "summary": team_summary,
            "log": team_history_entries
        }

    def _generate_team_summary(self, team_name: str, discussion_log: List[str]) -> str:
         return asyncio.run(self._generate_team_summary_async(team_name, discussion_log))

    async def _generate_team_summary_async(self, team_name: str, discussion_log: List[str]) -> str:
        """
        ç”Ÿæˆåœ˜éšŠå…§éƒ¨çš„å…±è­˜èˆ‡åˆ†æ­§ç¸½çµ (Async).
        """
        discussion_text = "\n".join(discussion_log)
        
        db = SessionLocal()
        try:
            sys_template = PromptService.get_prompt(db, "debate.team_summary_system")
            if not sys_template: sys_template = "Summarize team discussion."
            system_prompt = sys_template.format(team_name=team_name)

            user_template = PromptService.get_prompt(db, "debate.team_summary_user")
            if not user_template: user_template = "{discussion_text}"
            user_prompt = user_template.format(discussion_text=discussion_text)
        finally:
            db.close()
            
        return await call_llm_async(user_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:TeamSummary:{team_name}")

    def _agent_select_tools(self, agent: AgentBase, side: str):
         """Sync wrapper for backward compatibility"""
         return asyncio.run(self._agent_select_tools_async(agent, side))

    async def _agent_select_tools_async(self, agent: AgentBase, side: str):
        """
        Agent åœ¨è¾¯è«–é–‹å§‹å‰å‹•æ…‹é¸æ“‡æœ€é©åˆçš„å·¥å…· (Async).
        """
        db = SessionLocal()
        try:
            # ç²å–è©² Agent å¯ç”¨çš„å·¥å…·åˆ—è¡¨ (å¾ DB ToolSet)
            agent_id = getattr(agent, 'id', None)
            if not agent_id:
                # å˜—è©¦å¾ DB æŸ¥æ‰¾
                db_agent = db.query(models.Agent).filter(models.Agent.name == agent.name).first()
                if db_agent:
                    agent_id = db_agent.id
            
            if agent_id:
                available_tools_list = ToolSetService.get_agent_available_tools(db, agent_id)
            else:
                # Fallback: å¦‚æœæ‰¾ä¸åˆ° IDï¼Œåˆ—å‡ºæ‰€æœ‰å·¥å…· (æˆ–åƒ… Global)
                all_tools_dict = tool_registry.list()
                available_tools_list = []
                for name, data in all_tools_dict.items():
                    available_tools_list.append({"name": name, "description": data['description']})

            # [Optimization Phase 7] Role-Based Tool Suggestion
            # Sort/Tag tools based on agent side
            sorted_tools = []
            
            # Define priority sets
            # [Phase 1 Update] Hide raw 'tej.stock_price' to force use of 'financial.get_verified_price'
            # We filter OUT tej.stock_price from the suggestion list, but keep other tej tools (like financial_summary)
            tej_tools = [t for t in available_tools_list if "tej" in t['name'] and t['name'] != "tej.stock_price"]
            
            # 'financial.get_verified_price' is in official_tools
            official_tools = [t for t in available_tools_list if "twse" in t['name'] or "verified" in t['name']]
            backup_tools = [t for t in available_tools_list if "yahoo" in t['name'] or "search" in t['name']]
            other_tools = [t for t in available_tools_list if t not in tej_tools and t not in official_tools and t not in backup_tools and t['name'] != "tej.stock_price"]
            
            if side in ["pro", "con"]:
                # Pro/Con prioritize Verified Price (High Precision + Fallback)
                # Highlight verified tools
                # [Priority Adjustment] TWSE/Official tools first due to TEJ lag
                sorted_tools.extend([{"name": t['name'], "description": f"[æ¨è–¦:2025æœ€æ–°æ•¸æ“š/å®˜æ–¹é©—è­‰] {t['description']}"} for t in official_tools])
                sorted_tools.extend(tej_tools) # Other TEJ tools
                sorted_tools.extend(backup_tools)
                sorted_tools.extend(other_tools)
            elif side == "neutral":
                # Neutral prioritize Official/Verified (Audit)
                sorted_tools.extend([{"name": t['name'], "description": f"[æ¨è–¦:å®˜æ–¹é©—è­‰] {t['description']}"} for t in official_tools])
                sorted_tools.extend(tej_tools)
                sorted_tools.extend(backup_tools)
                sorted_tools.extend(other_tools)
            else:
                # Default mix
                sorted_tools = []
                # Ensure verified price is visible/prioritized even in default
                sorted_tools.extend(official_tools)
                sorted_tools.extend(tej_tools)
                sorted_tools.extend(backup_tools)
                sorted_tools.extend(other_tools)

            tools_list_text = "\n".join([f"- {t['name']}: {t['description']}" for t in sorted_tools])
        finally:
            db.close()
        
        # DB session for prompt
        db = SessionLocal()
        try:
            sys_template = PromptService.get_prompt(db, "debate.tool_selection_system")
            if not sys_template: sys_template = "You are {agent_name}."
            system_prompt = sys_template.format(agent_name=agent.name, side=side, topic=self.topic)

            user_template = PromptService.get_prompt(db, "debate.tool_selection_user")
            if not user_template: user_template = "Select tools: {tools_list_text}"
            user_prompt = user_template.format(tools_list_text=tools_list_text)
        finally:
            db.close()

        try:
            # Async LLM Call
            response = await call_llm_async(user_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}:ToolSelection")
            
            # å˜—è©¦è§£æ JSON (æ”¯æ´ List æˆ– Dict æ ¼å¼)
            selected_tools = []
            
            # [Fix Phase 21] Robust JSON Parsing
            # 1. Clean Markdown code blocks ```json ... ```
            cleaned_response = re.sub(r'```json\s*(.*?)\s*```', r'\1', response, flags=re.DOTALL)
            cleaned_response = re.sub(r'```\s*(.*?)\s*```', r'\1', cleaned_response, flags=re.DOTALL)
            
            # 2. Try List [...]
            list_match = re.search(r'\[.*\]', cleaned_response, re.DOTALL)
            if list_match:
                try:
                    selected_tools = json.loads(list_match.group(0))
                except:
                    pass

            # 3. Try Dict {"tools": [...]} if list failed
            if not selected_tools:
                dict_match = re.search(r'\{.*\}', cleaned_response, re.DOTALL)
                if dict_match:
                    try:
                        data = json.loads(dict_match.group(0))
                        if isinstance(data, dict):
                            selected_tools = data.get("tools") or data.get("tool_names") or []
                    except:
                        pass
            
            if selected_tools and isinstance(selected_tools, list):
                self.agent_tools_map[agent.name] = selected_tools
                print(f"Agent {agent.name} selected tools: {selected_tools}")
                
                # æ ¼å¼åŒ–å·¥å…·åˆ—è¡¨é¡¯ç¤º
                tools_display = "\n".join([f"  â€¢ {tool}" for tool in selected_tools])
                self._publish_log(f"{agent.name} (Setup)", f"âœ… å·²é¸æ“‡ {len(selected_tools)} å€‹å·¥å…·ï¼š\n{tools_display}")
            else:
                # [Fix Phase 21] Improved Fallback Strategy
                # Fallback: Instead of equipping ALL tools (which explodes context), equip a Safe Default Set
                # Role-based fallback
                if side == "neutral":
                    default_tools = ["financial.get_verified_price", "twse.stock_day", "internal.search_company", "searxng.search"]
                else:
                    # Pro/Con: Add fallbacks (TWSE/Yahoo) to default set
                    # [Phase 1 Update] Replace 'tej.stock_price' with 'financial.get_verified_price' in default fallback
                    default_tools = ["financial.get_verified_price", "tej.financial_summary", "internal.search_company", "searxng.search"]
                
                # Filter defaults to ensure they are available to this agent
                available_names = [t['name'] for t in available_tools_list]
                # We need to ensure 'financial.get_verified_price' is in available_tools_list?
                # It should be if it's registered globally or assigned.
                # If not, we might need to add it explicitly to the fallback if we trust it exists.
                safe_fallback = [t for t in default_tools if t in available_names]
                
                # If no safe fallback found (rare), then fall back to all
                if not safe_fallback:
                    safe_fallback = available_names
                
                self.agent_tools_map[agent.name] = safe_fallback
                
                print(f"Agent {agent.name} failed to select tools. Raw response: {response[:100]}... Using fallback: {safe_fallback}")
                
                tools_display = "\n".join([f"  â€¢ {tool}" for tool in safe_fallback])
                self._publish_log(f"{agent.name} (Setup)", f"âš ï¸ å·¥å…·é¸æ“‡è§£æå¤±æ•— (Raw: {response[:50]}...)ï¼Œå·²å•Ÿç”¨å®‰å…¨é è¨­å·¥å…·çµ„ ({len(safe_fallback)}å€‹)ï¼š\n{tools_display}")

        except Exception as e:
            print(f"Error in tool selection for {agent.name}: {e}")
            # Final Fallback
            self.agent_tools_map[agent.name] = ["searxng.search"]
            self._publish_log(f"{agent.name} (Setup)", f"âŒ å·¥å…·é¸æ“‡ç™¼ç”ŸéŒ¯èª¤: {str(e)}ã€‚å·²å•Ÿç”¨åŸºç¤æœå°‹å·¥å…·ã€‚")

    def _summarize_old_turns(self):
        """
        åˆ†å±¤æ‘˜è¦ (Hierarchical Summarization)ï¼š
        å°‡èˆŠçš„å°è©±æ­·å²é€²è¡Œçµæ§‹åŒ–æ‘˜è¦ï¼Œä¿ç•™æ¯å€‹è§’è‰²çš„æ ¸å¿ƒè§€é»ã€‚
        """
        keep_recent = 5 # ä¿ç•™æœ€è¿‘ 5 æ¢ (å¢åŠ ä¸Šä¸‹æ–‡)
        
        if len(self.history) <= keep_recent + 2:
            return

        # æå–éœ€è¦å£“ç¸®çš„èˆŠè¨Šæ¯
        to_compress = self.history[:-keep_recent]
        # æ›´æ–° self.historyï¼Œåªä¿ç•™æœ€è¿‘çš„è¨Šæ¯
        self.history = self.history[-keep_recent:]
        
        # æ§‹å»ºå¾…æ‘˜è¦æ–‡æœ¬
        conversation_text = ""
        for item in to_compress:
            role = item.get('role')
            content = str(item.get('content'))
            if len(content) > 500:
                content = content[:500] + "..."
            conversation_text += f"[{role}]: {content}\n\n"
        
        db = SessionLocal()
        try:
            template = PromptService.get_prompt(db, "debate.hierarchical_summarizer")
            if not template: template = "Summarize: {conversation_text}"
            system_prompt = template
            user_prompt = f"è«‹æ‘˜è¦ä»¥ä¸‹å°è©±ï¼š\n\n{conversation_text}"
        finally:
            db.close()
        
        try:
            summary = call_llm(user_prompt, system_prompt=system_prompt)
            if summary:
                self.archived_summaries.append(summary)
                print(f"DEBUG: Hierarchical summary generated. Length: {len(summary)}")
                self._publish_log("System", "å·²å°èˆŠçš„è¾¯è«–æ­·å²é€²è¡Œåˆ†å±¤æ‘˜è¦è™•ç†ã€‚")
        except Exception as e:
            print(f"WARNING: Hierarchical summarization failed: {e}")
            # Fallback: Just append raw text truncated if summary fails?
            # Or just keep it in history? No, that would lose data or explode context.
            # Let's append a placeholder.
            self.archived_summaries.append(f"(æ‘˜è¦å¤±æ•—: {str(e)})")

    def _get_compact_history(self, max_length=2000) -> str:
        """
        ç²å–å„ªåŒ–å¾Œçš„è¾¯è«–æ­·å² (Hierarchical Summary + Recent History)
        """
        # 1. å˜—è©¦è§¸ç™¼æ‘˜è¦
        self._summarize_old_turns()
        
        # 2. çµ„åˆæ­·å²
        # A. çµæ§‹åŒ–æ‘˜è¦å€
        archived_text = "ã€éå¾€è¾¯è«–æ‘˜è¦ã€‘\n" + "\n".join(self.archived_summaries)
        
        # B. è¿‘æœŸå°è©±å€
        active_history_text = "ã€è¿‘æœŸå°è©±ã€‘\n"
        for item in self.history:
            content = item.get("content", "")
            if len(content) > 800:
                content = content[:300] + "...(ç•¥)..." + content[-300:]
            active_history_text += f"{item.get('role')}: {content}\n\n"
        
        return f"{archived_text}\n\n{active_history_text}"

    def _agent_turn(self, agent: AgentBase, side: str, round_num: int) -> str:
        return asyncio.run(self._agent_turn_async(agent, side, round_num))

    async def _agent_turn_async(self, agent: AgentBase, side: str, round_num: int) -> str:
        """
        åŸ·è¡Œå–®å€‹ Agent çš„å›åˆï¼šæ€è€ƒ -> å·¥å…· -> ç™¼è¨€ (Async)
        """
        print(f"Agent {agent.name} ({side}) is thinking...")
        self._publish_log(f"{agent.name} (Thinking)", f"{agent.name} æ­£åœ¨æ€è€ƒä¸¦æ±ºå®šä½¿ç”¨çš„ç­–ç•¥...")
        
        # æ§‹å»º Prompt - ä½¿ç”¨ Agent è‡ªå·±é¸æ“‡çš„å·¥å…·
        selected_tool_names = self.agent_tools_map.get(agent.name, [])
        ollama_tools = []
        
        # å¦‚æœæœ‰é¸æ“‡ï¼Œå‰‡åªé¡¯ç¤ºé¸æ“‡çš„å·¥å…·ï¼›å¦å‰‡é¡¯ç¤ºæ‰€æœ‰ã€Œå¯ç”¨ã€çš„å·¥å…·
        if selected_tool_names:
            filtered_tools = {}
            for name in selected_tool_names:
                try:
                    # Using get_tool_data ensures lazy tools are loaded and schema is available
                    # Assuming version 'v1' for now as selection doesn't specify version
                    tool_data = tool_registry.get_tool_data(name)
                    filtered_tools[name] = tool_data
                    
                    # Convert to Ollama tool format
                    # Ensure parameters schema is valid and robust
                    params_schema = tool_data.get('schema')
                    if not params_schema:
                        params_schema = {"type": "object", "properties": {}, "required": []}
                    elif isinstance(params_schema, dict):
                        # Ensure 'type' is object
                        if "type" not in params_schema:
                            params_schema["type"] = "object"
                        # Ensure 'properties' exists
                        if "properties" not in params_schema:
                            params_schema["properties"] = {}
                    
                    # Fix: description might be a dict (metadata) or a string
                    desc = tool_data.get('description', '')
                    if isinstance(desc, dict):
                        desc = desc.get('description', '')

                    ollama_tools.append({
                        "type": "function",
                        "function": {
                            "name": name,
                            "description": desc,
                            "parameters": params_schema
                        }
                    })
                except Exception as e:
                    print(f"Warning: Selected tool '{name}' not found or failed to load: {e}")

            if not filtered_tools:
                 # å¦‚æœé¸æ“‡ç„¡æ•ˆï¼Œå›é€€åˆ°é¡¯ç¤ºè©² Agent æ‰€æœ‰å¯ç”¨çš„å·¥å…· (ToolSet)
                 tools_desc = get_tools_description()
            else:
                 tools_desc = "ä½ å·²é¸æ“‡ä¸¦æ¿€æ´»ä»¥ä¸‹å·¥å…·ï¼ˆç³»çµ±å·²è‡ªå‹•æ›è¼‰ï¼‰ï¼š\n" + "\n".join([f"- {name}: {data['description']}" for name, data in filtered_tools.items()])
        else:
            # å¦‚æœæ²’æœ‰é¸æ“‡ï¼ˆä¾‹å¦‚åˆå§‹åŒ–å¤±æ•—ï¼‰ï¼Œé¡¯ç¤ºæ‰€æœ‰å·¥å…·
            tools_desc = get_tools_description()
            
        # Append Meta-Tool Description
        # Dynamically fetch available groups from registry for the hint
        available_groups = set()
        for _, t_data in tool_registry.list().items():
             available_groups.add(t_data.get('group', 'basic'))
        groups_str = " | ".join([f"'{g}'" for g in sorted(available_groups)])
        
        tools_desc += f"\n\n### reset_equipped_tools\nDescription: å‹•æ…‹åˆ‡æ›å·¥å…·çµ„ (active tool group)ã€‚è‹¥ä½ æ‰¾ä¸åˆ°éœ€è¦çš„å·¥å…·ï¼Œè«‹å˜—è©¦åˆ‡æ›ã€‚\nParameters: {{'group': {groups_str}}}"
        
        # Append Chairman Intervention Tool (Virtual)
        tools_desc += "\n\n### call_chairman\nDescription: ç•¶ä½ ç™¼ç¾è¾¯é¡Œè³‡è¨Šåš´é‡ä¸è¶³ï¼ˆå¦‚ç¼ºä¹èƒŒæ™¯ã€å®šç¾©ä¸æ¸…ï¼‰ï¼Œç„¡æ³•é€²è¡Œæœ‰æ•ˆåˆ†ææ™‚ï¼Œè«‹ä½¿ç”¨æ­¤å·¥å…·é€šçŸ¥ä¸»å¸­ä»‹å…¥è™•ç†ã€‚\nParameters: {'reason': 'èªªæ˜å…·é«”ç¼ºå°‘ä»€éº¼è³‡è¨Šæˆ–èƒŒæ™¯'}"

        tools_examples = get_tools_examples() # Examples æš«æ™‚ä¿æŒå…¨é›†ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥éæ¿¾
        
        # Retrieve Tool LTM hints
        tool_hints = ""
        # Use persistent instance
        tool_hints = await self.tool_memory.retrieve_async(self.topic) # Use topic as context for now
        if tool_hints:
            tools_examples += f"\n\n**éå¾€æˆåŠŸå·¥å…·èª¿ç”¨åƒè€ƒ (ReMe Tool LTM)**:\n{tool_hints}"

        # Retrieve RAG Context (Relevant History)
        rag_context = ""
        # Use persistent instance
        # Use current agent role and topic as query
        query = f"{agent.name} {side} {self.topic}"
        relevant_turns = await self.history_memory.retrieve_async(query, top_k=2)
        if relevant_turns:
            rag_context = "\n".join([f"> [{t['role']} (Round {t['round']})]: {str(t['content'])[:200]}..." for t in relevant_turns])

        history_text = self._get_compact_history()
        if rag_context:
            history_text += f"\n\nã€ç›¸é—œæ­·å²å›é¡§ (RAG)ã€‘\n{rag_context}"
        
        db = SessionLocal()
        try:
            # 1. System Prompt Construction
            # [Governance] Use PromptService.compose_system_prompt to inject Base Contract
            
            # A. Prepare Agent Persona
            custom_prompt = getattr(agent, 'system_prompt', '').strip()
            if not custom_prompt:
                custom_prompt = f"ä½ æ˜¯ {agent.name}ï¼Œä»£è¡¨ {side} æ–¹ã€‚"
            
            # Additional Context
            persona_context = f"""
{custom_prompt}

è¾¯é¡Œï¼š{self.topic}
ç«‹å ´ï¼š{side}
"""
            # B. Operational Rules (Externalized)
            operational_rules = PromptService.get_prompt(db, "debater.operational_rules")
            if not operational_rules:
                # Minimal fallback if not found
                operational_rules = "System Rules: Use tools first. Do NOT fabricate data."

            # [Phase 18] Dynamic Data Honesty Rules
            if self.latest_db_date:
                operational_rules += f"\nSystem Note: The database data ends on {self.latest_db_date}. Do not query future dates."

            # C. Compose Final System Prompt
            final_persona = f"{persona_context}\n\n# Operational Rules\n{operational_rules}"
            system_prompt = PromptService.compose_system_prompt(db, override_content=final_persona)
            
            # 2. User Prompt (Tool Instruction)
            user_template = PromptService.get_prompt(db, "debater.tool_instruction")
            if not user_template: user_template = "Instructions: {history_text} {tools_desc}"
            
            # [Phase 18] Dynamic Date Injection
            db_date_info = ""
            if self.latest_db_date:
                db_date_info = f"\n**æ³¨æ„ï¼šè³‡æ–™åº«æœ€æ–°æ•¸æ“šæ—¥æœŸç‚º {self.latest_db_date}ã€‚**"
            
            # [Fix] Stronger instruction for Fallback
            fallback_hint = """

ğŸ’¡ **é‡è¦æç¤º (Fallback Strategy)**ï¼š
1. **æ•¸æ“šç²å–å„ªå…ˆç´š**: `twse.stock_day` (é¦–é¸, 2025å¹´æœ€æ–°æ•¸æ“š) -> `tej.stock_price` (å‚™ç”¨, æ­·å²å›æ¸¬) -> `yahoo.stock_price` (æœ€å¾Œæ‰‹æ®µ)ã€‚
2. **é‡åˆ°ç©ºæ•¸æ“šæ™‚**: è‹¥ `tej` å›å‚³ç©ºåˆ—è¡¨ `[]`ï¼Œé€™é€šå¸¸æ˜¯å› ç‚ºè³‡æ–™åº«å°šæœªæ›´æ–°è‡³ 2025 å¹´ã€‚è«‹ç«‹å³æ”¹ç”¨ `twse.stock_day` æŸ¥è©¢æœ€æ–°æ•¸æ“šã€‚
3. **æœå°‹é—œéµå­—å„ªåŒ–**: è‹¥éœ€ä½¿ç”¨ `searxng` æŸ¥æ‰¾è²¡å ±æˆ–æ–°èï¼Œ**è«‹å‹¿åƒ…æœå°‹ä»£ç¢¼**ã€‚
   - âŒ é¿å…: `"2330"`
   - âœ… æ¨è–¦: `"2330.TW 2024 Q4 ç‡Ÿæ”¶ YoY"` æˆ– `"å°ç©é›» æ³•èªªæœƒ é‡é»"`
"""
            
            user_prompt = user_template.format(
                round_num=round_num,
                history_text=history_text,
                chairman_summary=self.analysis_result.get('step5_summary', 'ç„¡'),
                current_date=f"{CURRENT_DATE} {db_date_info}",
                stock_codes=chr(10).join([f"- {name}: {code}" for name, code in STOCK_CODES.items()]),
                tools_desc=tools_desc,
                tools_examples=tools_examples + fallback_hint
            )
        finally:
            db.close()
        
        # === Multi-Step Tool Execution Loop ===
        base_max_steps = int(os.getenv("MAX_AGENT_TOOL_STEPS", 5))
        extension_steps = int(os.getenv("EXTENSION_STEPS", 3))
        max_steps = base_max_steps
        extensions_used = 0
        last_extension_reason = ""
        
        current_step = 0
        current_prompt = user_prompt
        collected_evidence = [] # Track evidence for fallback report
        tool_call_history = [] # Track last N tool calls to prevent loops (A-B-A patterns)
        
        # [Governance] Retry Loop Context
        guardrail_retries = 0
        MAX_GUARDRAIL_RETRIES = 2
        
        while True: # Outer Loop for Extension Retry
            while current_step < max_steps:
                current_step += 1
                
                # Async LLM Call (Passing tools!)
                response = await call_llm_async(
                    current_prompt,
                    system_prompt=system_prompt,
                    context_tag=f"{self.debate_id}:{agent.name}",
                    tools=ollama_tools if ollama_tools else None
                )
                print(f"DEBUG: Agent {agent.name} response (Step {current_step}): {response[:500]}")
                
                # [Debug] Trace LLM IO
                trace_item = {
                    "timestamp": datetime.now().isoformat(),
                    "agent": agent.name,
                    "step": current_step,
                    "event": "LLM_RESPONSE",
                    "prompt": current_prompt,
                    "response": response
                }
                self.debug_trace.append(trace_item)
                
                # [Realtime] Log trace details
                self._log_to_file(f"--- [LLM IO] {agent.name} Step {current_step} ---\nPrompt Preview: {current_prompt[:200]}...\nResponse Preview: {response[:200]}...")

                # --- [Governance] Guardrail Check ---
                # Check ALL text responses, and potentially Tool Calls (if we want to block dangerous tools)
                # Here we check Text Responses (non-tool calls) primarily to stop Hallucination/Scope Creep
                is_tool_call = False
                json_match = re.search(r'\{.*\}', response, re.DOTALL)
                if json_match:
                    try:
                        tool_call_test = json.loads(json_match.group(0))
                        if isinstance(tool_call_test, dict) and "tool" in tool_call_test:
                            is_tool_call = True
                    except:
                        pass
                
                # Guardrail Logic: Intercept final speech or reasoning steps
                if not is_tool_call:
                    check_context = f"Topic: {self.topic}\nLast Evidence: {str(collected_evidence[-1]) if collected_evidence else 'None'}"
                    audit_result = self.guardrail_agent.check(agent.name, response, check_context)
                    
                    if audit_result["status"] == "REJECTED":
                        self._publish_log("Guardrail", f"â›” æ””æˆªé•è¦ç™¼è¨€ ({audit_result['violation_type']}): {audit_result['reason']}")
                        
                        if guardrail_retries < MAX_GUARDRAIL_RETRIES:
                            guardrail_retries += 1
                            current_prompt = f"ã€Guardrail åˆè¦è­¦å‘Šã€‘\nä½ çš„å›ç­”è¢«æ‹’çµ•ï¼ŒåŸå› ï¼š{audit_result['reason']}ã€‚\nä¿®æ­£æŒ‡ä»¤ï¼š{audit_result['correction_instruction']}\n\nè«‹æ ¹æ“šæŒ‡ä»¤ä¿®æ­£å¾Œé‡æ–°è¼¸å‡ºã€‚"
                            
                            # Log Audit Event
                            self.redis_client.publish("guardrail:audit", json.dumps({
                                "debate_id": self.debate_id,
                                "agent": agent.name,
                                "action": "REJECTED",
                                "reason": audit_result["reason"]
                            }, ensure_ascii=False))
                            
                            # Decrease step count to not penalize retry? Or consume step?
                            # Design: Consume step to force convergence.
                            continue
                        else:
                            self._publish_log("Guardrail", f"âš ï¸ é‡è©¦æ¬¡æ•¸éå¤šï¼Œå¼·åˆ¶æ”¾è¡Œ (æ¨™è¨˜ç‚ºé¢¨éšªå…§å®¹)ã€‚")
                            # Force Pass but Log Warning
                            # (Proceed as normal)
                    elif audit_result["status"] == "WARNING":
                         self._publish_log("Guardrail", f"âš ï¸ åˆè¦è­¦å‘Š: {audit_result['reason']}")

                # ------------------------------------

                # Check for tool call
                try:
                    # å˜—è©¦æå– JSON
                    json_match = re.search(r'\{.*\}', response, re.DOTALL)
                    if not json_match:
                        # No JSON found -> Assume final speech -> Return
                        return response
                    
                    json_str = json_match.group(0)
                    try:
                        tool_call = json.loads(json_str)
                    except json.JSONDecodeError:
                        # JSON parse failed -> Treat as text
                        return response

                    # Check if valid tool call
                    if isinstance(tool_call, dict) and "tool" in tool_call and "params" in tool_call:
                        tool_name = str(tool_call["tool"]).strip()
                        params = tool_call["params"]
                        
                        # --- Check for Duplicate Call (Loop Prevention & Sentinel) ---
                        current_call_signature = f"{tool_name}:{json.dumps(params, sort_keys=True)}"
                        
                        # [Robustness] Enhanced Loop Detection (History Check)
                        # Check against ALL previous calls in this turn to prevent ANY exact repeats
                        if current_call_signature in tool_call_history:
                            print(f"âš ï¸ Loop detected: Agent {agent.name} repeated call {tool_name}")
                            self._publish_log(f"{agent.name} (System)", f"âš ï¸ åµæ¸¬åˆ°é‡è¤‡èª¿ç”¨ ({tool_name})ï¼Œå·²æ””æˆªã€‚")
                            current_prompt = f"ç³»çµ±æç¤ºï¼šä½ åœ¨æœ¬å›åˆå·²ç¶“åŸ·è¡Œéé€™å€‹å·¥å…·ï¼ˆåƒæ•¸ç›¸åŒï¼‰ã€‚è«‹ä¸è¦é‡è¤‡èª¿ç”¨ã€‚è«‹å˜—è©¦ä¿®æ”¹åƒæ•¸ï¼ˆå¦‚æ—¥æœŸç¯„åœï¼‰ã€æ›´æ›å·¥å…·ï¼Œæˆ–ç›´æ¥æ ¹æ“šç¾æœ‰è³‡è¨Šé€²è¡Œåˆ†æã€‚"
                            
                            # [Observability] Log Metric
                            print(f"[LOOP_DETECTED] agent={agent.name} tool={tool_name} type=history_repeat")
                            continue
                        
                        tool_call_history.append(current_call_signature)
                        
                        # Soft loop check (frequency)
                        sentinel_key = f"{agent.name}:{current_call_signature}"
                        self._loop_sentinel[sentinel_key] = self._loop_sentinel.get(sentinel_key, 0) + 1
                        if self._loop_sentinel[sentinel_key] > 2:
                             print(f"[LOOP_DETECTED] agent={agent.name} tool={tool_name} type=frequent_access count={self._loop_sentinel[sentinel_key]}")
                        # --------------------------------------------------

                        # --- Meta-Tool: reset_equipped_tools ---
                        if tool_name == "reset_equipped_tools":
                            target_group = params.get("group", "basic")
                            print(f"âš™ï¸ Agent {agent.name} is resetting equipped tools to group: {target_group}")
                            self._publish_log(f"{agent.name} (Meta-Tool)", f"Resetting tools to group: {target_group}")
                            
                            group_tools = tool_registry.list(groups=[target_group])
                            self.agent_tools_map[agent.name] = list(group_tools.keys())
                            
                            # Recursive retry with new tools (Reset steps)
                            return await self._agent_turn_async(agent, side, round_num)

                        # --- Meta-Tool: call_chairman (Intervention) ---
                        if tool_name == "call_chairman":
                            reason = params.get("reason", "æœªèªªæ˜åŸå› ")
                            print(f"ğŸš¨ Agent {agent.name} is calling Chairman for help: {reason}")
                            self._publish_log(f"{agent.name} (SOS)", f"è«‹æ±‚ä¸»å¸­ä»‹å…¥ï¼š{reason}")

                            # [Loop Fix] Auto-Equip Tools on "Missing Data" complaints
                            # If reason contains "lack", "missing", "data", "price", "stock" -> try to equip fallback tools
                            triggers = ["ç¼º", "miss", "data", "æ•¸æ“š", "è³‡æ–™", "price", "stock", "è‚¡åƒ¹", "2480"]
                            if any(t in reason.lower() for t in triggers):
                                fallback_tools = ["financial.get_verified_price", "tej.stock_price", "yahoo.stock_price"]
                                added_tools = []
                                current_tools = self.agent_tools_map.get(agent.name, [])
                                
                                for ft in fallback_tools:
                                    if ft not in current_tools:
                                        current_tools.append(ft)
                                        added_tools.append(ft)
                                
                                if added_tools:
                                    self.agent_tools_map[agent.name] = current_tools
                                    self._publish_log("System", f"ğŸ› ï¸ [Auto-Fix] åµæ¸¬åˆ° Agent ç¼ºå°‘æ•¸æ“šå·¥å…·ï¼Œå·²è‡ªå‹•ç‚º {agent.name} è£å‚™ï¼š{', '.join(added_tools)}")

                            chairman_prompt = f"Agent {agent.name} ({side}æ–¹) åœ¨åˆ†æè¾¯é¡Œã€Œ{self.topic}ã€æ™‚é‡åˆ°å›°é›£ã€‚\nå›å ±åŸå› ï¼š{reason}\nè«‹æ ¹æ“šä½ çš„è³½å‰åˆ†ææ‰‹å¡ï¼Œæä¾›å¼•å°ã€‚"
                            clarification = await call_llm_async(chairman_prompt, system_prompt="ä½ æ˜¯è¾¯è«–ä¸»å¸­ã€‚è«‹å”åŠ©é‡åˆ°å›°é›£çš„è¾¯æ‰‹ã€‚")
                            
                            self._publish_log("Chairman (Intervention)", f"ä¸»å¸­å›æ‡‰ï¼š{clarification}")
                            
                            intervention_msg = {"role": "Chairman (Intervention)", "content": f"è£œå……èªªæ˜ï¼š\n{clarification}\nè«‹ç¹¼çºŒåˆ†æã€‚"}
                            self.history.append(intervention_msg)
                            
                            # Recursive retry (Reset steps)
                            return await self._agent_turn_async(agent, side, round_num)

                        # --- Meta-Tool: request_extension (Early access check) ---
                        if tool_name == "request_extension":
                             print(f"Agent {agent.name} requested extension prematurely.")
                             self._publish_log(f"{agent.name} (System)", "âš ï¸ ä½ é‚„æœ‰å‰©é¤˜çš„èª¿æŸ¥æ¬¡æ•¸ï¼Œè«‹å„ªå…ˆä½¿ç”¨å·¥å…·é€²è¡Œèª¿æŸ¥ã€‚")
                             current_prompt = "ç³»çµ±æç¤ºï¼šä½ é‚„æœ‰å‰©é¤˜çš„èª¿æŸ¥æ¬¡æ•¸ï¼Œç„¡éœ€ç”³è«‹å»¶é•·ã€‚è«‹ç¹¼çºŒä½¿ç”¨å·¥å…·æœå°‹æ•¸æ“šã€‚"
                             continue
                        
                        # --- Memory Tool Context Injection ---
                        if tool_name == "search_shared_memory":
                            params["debate_id"] = self.debate_id

                        # --- Regular Tool Execution ---
                        
                        # [STRICT TOOL VALIDATION]
                        # Check if the tool is in the equipped list for this agent
                        equipped_tools = self.agent_tools_map.get(agent.name, [])
                        if tool_name not in equipped_tools:
                            # Bypass validation for special meta-tools if needed, but currently only reset_equipped_tools/call_chairman are meta-tools handled above.
                            # So this block is for regular tools.
                            print(f"âŒ Blocked: Agent {agent.name} tried to call unequipped tool: {tool_name}")
                            
                            error_msg = f"Error: Tool '{tool_name}' is not in your equipped list. You can only use: {equipped_tools}. Use 'reset_equipped_tools' if you need to switch toolsets."
                            
                            # Log failure
                            self._publish_log(f"{agent.name} (System)", f"â›” æ‹’çµ•åŸ·è¡Œï¼šå·¥å…· {tool_name} æœªè£å‚™")
                            
                            # Append to evidence for context
                            collected_evidence.append(f"ã€ç³»çµ±éŒ¯èª¤ã€‘èª¿ç”¨å¤±æ•—ï¼š{error_msg}")
                            
                            # Return error to LLM to correct itself
                            current_prompt = f"ç³»çµ±éŒ¯èª¤ï¼š{error_msg}\nè«‹é‡æ–°é¸æ“‡æœ‰æ•ˆçš„å·¥å…·æˆ–ç™¼è¡¨è¨€è«–ã€‚"
                            continue

                        print(f"âœ“ Agent {agent.name} calling {tool_name}")
                        self._publish_log(f"{agent.name} (Tool)", f"Calling {tool_name} with {params}")
                        
                        try:
                            # 1. Check Working Memory (Sensory Gating)
                            cached_result = await self.hippocampus.retrieve_working_memory(tool_name, params)
                            
                            if cached_result:
                                tool_result = cached_result['result']
                                
                                # [Memory Opt] Mark as Adopted since we are using it
                                await self.hippocampus.mark_adopted(tool_name, params)
                                
                                # Create a preview string for debugging
                                try:
                                    result_str = json.dumps(tool_result, ensure_ascii=False)
                                except:
                                    result_str = str(tool_result)
                                # Show FULL content for debugging as requested
                                self._publish_log(f"{agent.name} (Memory)", f"ğŸ§  å¾æµ·é¦¬è¿´çŸ­æœŸè¨˜æ†¶ä¸­ç²å–äº†çµæœ (Access: {cached_result['access_count']}) ã€{result_str}ã€")
                            else:
                                # 2. Execute Tool (Sensory Input)
                                from worker.tool_invoker import call_tool
                                loop = asyncio.get_running_loop()
                                
                                # [Observability] Track Latency & Cost
                                start_tool = datetime.now()
                                tool_result = await loop.run_in_executor(None, call_tool, tool_name, params)
                                tool_duration = (datetime.now() - start_tool).total_seconds()
                                
                                self.tool_stats["count"] += 1
                                self.tool_stats["total_time"] += tool_duration
                                
                                # Simple Cost Model
                                cost = 0.0
                                if tool_name.startswith("tej."): cost = 0.03 # $0.03 per TEJ call
                                elif tool_name.startswith("searxng."): cost = 0.00 # Free
                                elif tool_name.startswith("financial."): cost = 0.01 # Auditor
                                self.tool_stats["estimated_cost"] += cost
                                
                                # 3. Store in Working Memory
                                await self.hippocampus.store(agent.name, tool_name, params, tool_result)
                                self._publish_log(f"{agent.name} (Tool)", f"å·¥å…· {tool_name} åŸ·è¡ŒæˆåŠŸä¸¦å­˜å…¥æµ·é¦¬è¿´ã€‚")
                            
                            # Publish Tool Result Preview to Log Stream
                            result_preview_log = str(tool_result)
                            if len(result_preview_log) > 500:
                                result_preview_log = result_preview_log[:500] + "... (é»æ“ŠæŸ¥çœ‹å®Œæ•´æ•¸æ“š)"
                            self._publish_log(f"{agent.name} (Tool Result)", f"ğŸ“Š å·¥å…·åŸ·è¡Œçµæœæ‘˜è¦ï¼š\n{result_preview_log}")
                            
                            # Print full result to backend console for debugging (as requested)
                            print(f"DEBUG: Full tool result for {tool_name}:\n{json.dumps(tool_result, ensure_ascii=False, indent=2, default=str)}")
                            
                            # [Debug] Trace Tool Result
                            self.debug_trace.append({
                                "timestamp": datetime.now().isoformat(),
                                "agent": agent.name,
                                "step": current_step,
                                "event": "TOOL_RESULT",
                                "tool": tool_name,
                                "params": params,
                                "result": tool_result
                            })
                            
                            # [Realtime] Log trace details
                            self._log_to_file(f"--- [TOOL RESULT] {agent.name} ---\nTool: {tool_name}\nParams: {params}\nResult Preview: {str(tool_result)[:200]}...")

                            # Record successful tool usage to Tool LTM
                            try:
                                # Use persistent instance
                                await self.tool_memory.record_async(
                                    intent=f"Debate on {self.topic}",
                                    tool_name=tool_name,
                                    params=params,
                                    result=tool_result,
                                    success=True
                                )
                            except Exception as e:
                                print(f"Warning: Failed to record tool usage to LTM: {e}")

                            # Record Evidence
                            evidence_entry = {
                                "role": f"{agent.name} ({side})",
                                "agent_name": agent.name,
                                "side": side,
                                "tool": tool_name,
                                "params": params,
                                "result": tool_result,
                                "timestamp": datetime.now().isoformat(),
                                "verified": False,
                                "round": round_num
                            }
                            self.redis_client.rpush(self.evidence_key, json.dumps(evidence_entry, ensure_ascii=False))
                            
                            # [Optimization Phase 18] Data Honesty Check
                            # Check if result is effectively empty
                            is_empty_result = False
                            if isinstance(tool_result, dict):
                                # TEJ standard: {'data': [], ...} or {'results': []}
                                if not tool_result.get("data") and not tool_result.get("results") and not tool_result.get("content"):
                                     # Check specific keys that might contain data
                                     if "data" in tool_result or "results" in tool_result:
                                         is_empty_result = True
                            elif isinstance(tool_result, list) and len(tool_result) == 0:
                                is_empty_result = True
                            
                            # Add to local collection (Truncated for summary)
                            # Avoid huge context overhead
                            result_str = str(tool_result)
                            if len(result_str) > 200:
                                preview = result_str[:200] + "... (å®Œæ•´å…§å®¹å·²å­˜æª”)"
                            else:
                                preview = result_str
                                
                            collected_evidence.append(f"ã€è­‰æ“š {current_step}ã€‘{tool_name}\nçµæœæ‘˜è¦: {preview}")
                            
                            # Prepare prompt for next step
                            next_prompt_suffix = ""
                            if is_empty_result:
                                next_prompt_suffix = "\n\nâš ï¸ **ç³»çµ±è­¦å‘Š (Data Honesty)**ï¼šæ­¤å·¥å…·èª¿ç”¨è¿”å›äº† **ç©ºæ•¸æ“š (Empty)**ã€‚\né€™æ„å‘³è‘— TEJ æ•¸æ“šåº«ä¸­å¯èƒ½æ²’æœ‰é€™æ®µæœŸé–“çš„è³‡æ–™ã€‚\n\n**è«‹ç«‹å³åŸ·è¡Œ Fallback ç­–ç•¥**ï¼š\n1. è‹¥ä½ æ˜¯æŸ¥è©¢è‚¡åƒ¹ï¼Œè«‹æ”¹ç”¨ `twse.stock_day` (åƒæ•¸: symbol, date) æˆ– `yahoo.stock_price`ã€‚\n2. è‹¥ä½ æ˜¯æŸ¥è©¢è²¡å‹™æ•¸æ“šï¼Œè«‹å˜—è©¦èª¿æ•´æ—¥æœŸç¯„åœæˆ–æ”¹ç”¨ `searxng.search` æŸ¥æ‰¾æ–°èå ±å°ã€‚\n3. **çµ•å°ç¦æ­¢**ç·¨é€ æ•¸æ“šã€‚"

                        except Exception as e:
                            # [Error Taxonomy & Failure Mode Handling]
                            error_msg = str(e)
                            is_fatal = False
                            advice = ""
                            
                            # Check for Structured ToolError
                            if isinstance(e, ToolError):
                                error_type = e.error_type
                                meta = e.metadata
                                
                                # Failure Mode Memory Check
                                # Hash params to detect "same error + same params"
                                param_hash = hashlib.md5(json.dumps(params, sort_keys=True).encode()).hexdigest()
                                fm_key = f"{agent.name}:{tool_name}:{error_type.value}"
                                
                                if fm_key not in self._failure_memory:
                                    self._failure_memory[fm_key] = {"count": 0, "hashes": set()}
                                
                                self._failure_memory[fm_key]["count"] += 1
                                self._failure_memory[fm_key]["hashes"].add(param_hash)
                                
                                # Circuit Breaker logic
                                if self._failure_memory[fm_key]["count"] > 3:
                                    advice += "\n\nâš ï¸ ç³»çµ±è­¦å‘Šï¼šä½ å·²é€£çºŒå¤šæ¬¡é­é‡æ­¤é¡å‹éŒ¯èª¤ã€‚è«‹åœæ­¢å˜—è©¦æ­¤è·¯å¾‘ï¼Œæ”¹ç”¨å…¶ä»–åˆ†ææ–¹æ³•ã€‚"
                                
                                if error_type == TejErrorType.RECOVERABLE:
                                    advice = f"\nğŸ’¡ å»ºè­°èª¿æ•´åƒæ•¸ï¼š{meta.get('hint', 'è«‹æª¢æŸ¥åƒæ•¸æ ¼å¼')}ã€‚"
                                    if "retry_after" in meta:
                                        time.sleep(meta["retry_after"]) # Basic backoff
                                        
                                elif error_type == TejErrorType.TERMINAL:
                                    advice = "\nâ›” æ­¤éŒ¯èª¤ç‚ºçµ‚ç«¯éŒ¯èª¤ï¼ˆè³‡æ–™ä¸å­˜åœ¨æˆ–è·¯å¾‘ç„¡æ•ˆï¼‰ã€‚è«‹å‹¿å†é‡è©¦æ­¤å·¥å…·/åƒæ•¸çµ„åˆã€‚"
                                    # We could force stop tool usage here, but prompt guidance is softer first step.
                                    
                                elif error_type == TejErrorType.FATAL:
                                    advice = "\nğŸ”¥ åš´é‡éŒ¯èª¤ã€‚è«‹ç«‹å³åœæ­¢å·¥å…·èª¿ç”¨ï¼Œä¸¦å‘ä¸»å¸­å›å ±ã€‚"
                                    is_fatal = True

                            # --- Tool Name Correction Logic (Legacy Fallback) ---
                            elif "not found" in error_msg or "Tool" in error_msg:
                                all_tools = list(tool_registry.list().keys())
                                matches = []
                                fuzzy = difflib.get_close_matches(tool_name, all_tools, n=3, cutoff=0.4)
                                matches.extend(fuzzy)
                                tool_name_lower = tool_name.lower()
                                for t in all_tools:
                                    if tool_name_lower in t.lower() or t.lower() in tool_name_lower:
                                        if t not in matches: matches.append(t)
                                matches = matches[:5]
                                if matches: error_msg += f" Did you mean: {', '.join(matches)}?"
                                else: error_msg += f" Available tools: {', '.join(all_tools[:5])}..."
                            # ----------------------------------
                            
                            final_msg = f"Tool execution error: {error_msg}{advice}"
                            tool_result = {"error": final_msg}
                            print(f"ERROR: Tool {tool_name} failed: {final_msg}")
                            
                            # [Debug] Trace Tool Failure
                            self.debug_trace.append({
                                "timestamp": datetime.now().isoformat(),
                                "agent": agent.name,
                                "step": current_step,
                                "event": "TOOL_FAILURE",
                                "tool": tool_name,
                                "params": params,
                                "result": tool_result
                            })

                            # Record failed tool usage
                            try:
                                await self.tool_memory.record_async(
                                    intent=f"Debate on {self.topic}",
                                    tool_name=tool_name,
                                    params=params,
                                    result=final_msg,
                                    success=False
                                )
                            except Exception as ex:
                                print(f"Warning: Failed to record tool failure to LTM: {ex}")

                            collected_evidence.append(f"ã€è­‰æ“š {current_step}ã€‘{tool_name}\nåŸ·è¡Œå¤±æ•—: {final_msg}")
                            
                            if is_fatal:
                                # Break inner loop to force conclusion or chairman call
                                current_prompt = f"ç³»çµ±ç™¼ç”Ÿåš´é‡éŒ¯èª¤ ({error_msg})ï¼Œè«‹ç«‹å³çµ‚æ­¢èª¿æŸ¥ä¸¦å›å ±ã€‚"
                                # Force next step to be text response (conclusion)
                                # But we continue loop to let agent explain.
                        
                        # Update prompt with tool result for NEXT step
                        # Use variable next_prompt_suffix if defined (from Data Honesty Check)
                        if 'next_prompt_suffix' not in locals():
                            next_prompt_suffix = ""

                        current_prompt = f"""å·¥å…· {tool_name} çš„åŸ·è¡Œçµæœï¼š
{json.dumps(tool_result, ensure_ascii=False, indent=2)}

ã€ç³»çµ±æç¤ºã€‘
1. è«‹æª¢æŸ¥ä¸Šè¿°çµæœä¸­çš„ system_hint (è‹¥æœ‰)ã€‚
2. è‹¥ç²å¾—äº†å…¬å¸ ID/Tickerï¼Œè«‹å‹™å¿…ç¹¼çºŒèª¿ç”¨è²¡å‹™æˆ–è‚¡åƒ¹å·¥å…· (å¦‚ tej.stock_price, tej.financial_summary) ä»¥ç²å–æ·±åº¦æ•¸æ“šã€‚
3. ä¸è¦åªåœç•™åœ¨æœå°‹çµæœï¼Œè«‹æŒ–æ˜æ•¸æ“šèƒŒå¾Œçš„è¶¨å‹¢ã€‚
4. å¦‚æœè­‰æ“šå·²è¶³å¤ æ”¯æŒä½ çš„è«–é»ï¼Œè«‹è¼¸å‡ºæœ€çµ‚ç™¼è¨€ï¼ˆç´”æ–‡å­—ï¼‰ã€‚{next_prompt_suffix}
"""
                        
                        # Loop continues to next step...
                        continue

                    # Handle Error JSON
                    elif isinstance(tool_call, dict) and "error" in tool_call:
                        # ... (Existing error handling logic) ...
                        # For brevity, if error JSON, we treat as text or retry logic (omitted complex retry for now to fit structure)
                        # Let's just return it or basic text to avoid stuck loop
                        return str(tool_call)
                    
                    else:
                        # JSON found but not a tool call -> Treat as text response
                        return response

                except Exception as e:
                    print(f"Error in agent loop: {e}")
                    return response
            
            # --- Loop Limit Reached ---
            # Allow multiple extension requests (Auto-Approve first 2, then Chairman Review)
            # Limit total extensions to prevent infinite loop (e.g., max 3 times total)
            if extensions_used < 3:
                print(f"INFO: Agent {agent.name} reached step limit ({max_steps}). Offering extension ({extensions_used+1}/3).")
                self._publish_log(f"{agent.name} (System)", "âš ï¸ èª¿æŸ¥æ¬¡æ•¸å·²ç”¨ç›¡ã€‚æ­£åœ¨è©¢å•æ˜¯å¦éœ€è¦å»¶é•·èª¿æŸ¥...")
                
                # Externalized Prompt
                db = SessionLocal()
                try:
                    ext_template = PromptService.get_prompt(db, "debate.extension_option")
                    if not ext_template: ext_template = "Max steps reached. 1. Conclude. 2. Extend."
                    extension_option_prompt = ext_template.format(base_max_steps=base_max_steps, extension_steps=extension_steps)
                finally:
                    db.close()

                # Ask Agent
                decision_response = await call_llm_async(extension_option_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}")
                
                # Check for extension request
                json_match = re.search(r'\{.*\}', decision_response, re.DOTALL)
                if json_match:
                    try:
                        req = json.loads(json_match.group(0))
                        if req.get("tool") == "request_extension":
                            reason = req.get("params", {}).get("reason", "ç„¡ç†ç”±")
                            self._publish_log(f"{agent.name} (Request)", f"ç”³è«‹å»¶é•·èª¿æŸ¥ ({extensions_used+1}/3)ï¼š{reason}")
                            
                            # [Hippocampus] Check Shared Memory first
                            self._publish_log("System", f"ğŸ§  æ­£åœ¨æŸ¥è©¢æµ·é¦¬è¿´è¨˜æ†¶ä»¥é©—è­‰å»¶é•·éœ€æ±‚...")
                            mem_results = await self.hippocampus.search_shared_memory(query=reason, limit=3)
                            
                            if "No relevant memories" not in mem_results and len(mem_results) > 50:
                                self._publish_log("System", f"âœ… æµ·é¦¬è¿´ä¸­ç™¼ç¾ç›¸é—œè³‡è¨Šï¼Œå»¶é•·ç”³è«‹è‡ªå‹•é§å›ä¸¦æä¾›è³‡è¨Šã€‚")
                                current_prompt = f"ã€ç³»çµ±æç¤ºã€‘å»¶é•·ç”³è«‹å·²è‡ªå‹•é§å›ï¼Œå› ç‚ºåœ¨å…±äº«è¨˜æ†¶ä¸­ç™¼ç¾äº†ç›¸é—œè³‡è¨Šï¼š\n\n{mem_results}\n\nè«‹åˆ©ç”¨é€™äº›è³‡è¨Šç¹¼çºŒä½ çš„è«–è¿°æˆ–ç¸½çµã€‚"
                                continue # Back to agent loop
                            
                            # --- [Optimization Phase 1] Auto-Approve Logic ---
                            should_auto_approve = False
                            deny_reason_auto = ""
                            
                            # Only auto-approve first 2 times
                            if extensions_used < 2:
                                # 1. Substantiality Check
                                filler_words = ["need time", "more steps", "process", "thinking", "continue", "investigate", "research"]
                                is_only_filler = any(w in reason.lower() for w in filler_words) and len(reason) < 25
                                has_specifics = any(c.isupper() for c in reason) or any(c.isdigit() for c in reason)
                                
                                # 2. Repetition Check
                                is_repeated = (reason.strip() == last_extension_reason.strip())
                                
                                if len(reason) < 10:
                                    deny_reason_auto = "ç†ç”±éçŸ­"
                                elif is_repeated:
                                    deny_reason_auto = "ç†ç”±é‡è¤‡"
                                elif is_only_filler and not has_specifics:
                                    deny_reason_auto = "ç¼ºä¹å…·é«”ç´°ç¯€ (éœ€åŒ…å«å¯¦é«”æˆ–æ•¸æ“š)"
                                else:
                                    should_auto_approve = True
                            
                            if should_auto_approve:
                                self._publish_log("System (Auto-Approve)", f"âœ… ç³»çµ±è‡ªå‹•æ‰¹å‡†å»¶é•· (ç¬¦åˆè‡ªå‹•æ”¾è¡Œæ¨™æº–)ã€‚")
                                max_steps += extension_steps
                                extensions_used += 1
                                last_extension_reason = reason
                                current_prompt = f"ç³»çµ±å·²è‡ªå‹•æ‰¹å‡†ä½ çš„å»¶é•·ç”³è«‹ã€‚\nå¢åŠ äº† {extension_steps} æ¬¡èª¿ç”¨æ©Ÿæœƒã€‚\nè«‹ç¹¼çºŒèª¿æŸ¥ã€‚"
                                continue # Back to agent loop
                            
                            if extensions_used < 2 and not should_auto_approve:
                                self._publish_log("System (Auto-Approve)", f"âš ï¸ è‡ªå‹•æ‰¹å‡†æ‹’çµ• ({deny_reason_auto})ï¼Œè½‰äº¤ä¸»å¸­å¯©æ ¸...")

                            # --- End Auto-Approve ---

                            # Call Chairman for Review (Fallback)
                            db = SessionLocal()
                            try:
                                review_template = PromptService.get_prompt(db, "debate.chairman_review_extension")
                                # If template not found (e.g. not init yet), use fallback
                                if not review_template:
                                    review_template = """
ä½ æ˜¯ä¸»å¸­ã€‚Agent {agent_name} ç”³è«‹å»¶é•·èª¿æŸ¥ã€‚
ç†ç”±ï¼š{reason}
è­‰æ“šæ‘˜è¦ï¼š{evidence_summary}
è«‹å›å‚³ JSON: {{"approved": true/false, "reason": "...", "guidance": "..."}}
"""
                                chairman_sys = review_template.format(
                                    agent_name=agent.name, 
                                    side=side, 
                                    topic=self.topic, 
                                    reason=reason,
                                    evidence_summary="\n".join(collected_evidence)[-1000:] # Last 1000 chars
                                )
                            finally:
                                db.close()
                                
                            chairman_res = await call_llm_async("è«‹é€²è¡Œå¯©æ ¸ã€‚", system_prompt=chairman_sys, context_tag=f"{self.debate_id}:Chairman")
                            
                            # Parse Chairman Decision
                            try:
                                res_json = json.loads(re.search(r'\{.*\}', chairman_res, re.DOTALL).group(0))
                                if res_json.get("approved"):
                                    max_steps += extension_steps
                                    extensions_used += 1
                                    last_extension_reason = reason
                                    self._publish_log("Chairman (Review)", f"âœ… æ‰¹å‡†å»¶é•·ï¼š{res_json.get('reason')}")
                                    
                                    # Update prompt with guidance
                                    current_prompt = f"ä¸»å¸­å·²æ‰¹å‡†å»¶é•·èª¿æŸ¥ã€‚\næŒ‡å°ï¼š{res_json.get('guidance')}\nè«‹ç¹¼çºŒä½ çš„èª¿æŸ¥æˆ–ç™¼è¨€ã€‚"
                                    continue # Continue Outer Loop (re-enters Inner Loop with higher max_steps)
                                else:
                                    self._publish_log("Chairman (Review)", f"âŒ æ‹’çµ•å»¶é•·ï¼š{res_json.get('reason')}")
                                    current_prompt = f"ä¸»å¸­æ‹’çµ•äº†ä½ çš„ç”³è«‹ã€‚\nç†ç”±ï¼š{res_json.get('reason')}\nè«‹ç«‹å³æ ¹æ“šç¾æœ‰è³‡è¨Šç™¼è¡¨ç¸½çµã€‚"
                                    # Fall through to forced summary (or return text if agent replies text next time)
                                    # Actually, we should force summary NOW or give one last chance?
                                    # Let's give one last chance with text-only constraint.
                                    final_res = await call_llm_async(current_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}")
                                    return final_res
                                    
                            except Exception as e:
                                print(f"Error parsing chairman review: {e}")
                                # Fallback: Deny
                    except:
                        pass
                
                # If not extension request or denied/failed, return the response as text (if it's text)
                # or fallback report if it's still JSON but not extension
                if not json_match:
                    return decision_response
            
            # If reached here, it means extension denied or invalid request, break outer loop to fallback
            break
        
        # Loop ended (either max steps reached again, or denied extension)
        # FORCE A CONCLUSION: Instead of returning a system report, force the LLM to speak based on whatever it has.
        print(f"WARNING: Agent {agent.name} reached max steps ({max_steps}). Forcing conclusion.")
        
        evidence_text = "\n\n".join(collected_evidence)
        self._publish_log(f"{agent.name} (System)", f"âš ï¸ èª¿ç”¨æ¬¡æ•¸è€—ç›¡ï¼Œæ­£åœ¨å¼·åˆ¶ç”Ÿæˆç¸½çµç™¼è¨€...")
        
        force_conclusion_prompt = f"""
ã€ç³»çµ±å¼·åˆ¶æŒ‡ä»¤ã€‘
ä½ å·²ç¶“é”åˆ°å·¥å…·èª¿ç”¨æ¬¡æ•¸ä¸Šé™ï¼Œä¸èƒ½å†ä½¿ç”¨å·¥å…·äº†ã€‚
è«‹æ ¹æ“šä½ ç›®å‰å·²è’é›†åˆ°çš„è­‰æ“šï¼ˆæˆ–è‹¥ç„¡è­‰æ“šï¼Œå‰‡æ ¹æ“šä½ çš„å°ˆæ¥­çŸ¥è­˜èˆ‡é‚è¼¯æ¨æ¼”ï¼‰ï¼Œç«‹å³ç™¼è¡¨ä½ çš„æœ¬è¼ªè«–é»ã€‚

**å·²è’é›†çš„è­‰æ“šæ‘˜è¦**ï¼š
{evidence_text}

è«‹ç›´æ¥è¼¸å‡ºä½ çš„è¾¯è«–ç™¼è¨€ï¼ˆç´”æ–‡å­—ï¼‰ï¼š
"""
        try:
            # Force call without tool capability (modify system prompt? No, just strong instruction)
            # We use the same system prompt but a very strong user instruction.
            final_speech = await call_llm_async(force_conclusion_prompt, system_prompt=system_prompt, context_tag=f"{self.debate_id}:{agent.name}")
            return final_speech
        except Exception as e:
             # If even this fails, then fallback to report
             print(f"Error in forced conclusion: {e}")
             return f"(ç³»çµ±å ±å‘Šï¼šAgent åœ¨å¼·åˆ¶ç¸½çµæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè­‰æ“šå¦‚ä¸‹)\n{evidence_text}"